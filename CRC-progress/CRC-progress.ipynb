{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed to get more reproducible result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(2)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from expert.src.utils import read_genus_abu, read_labels, load_otlg, zero_weight_unk, parse_otlg, get_dmax\n",
    "from expert.src.preprocessing import *\n",
    "from expert.src.model import *\n",
    "from expert.CLI.CLI_utils import find_pkg_resource as find_expert_resource\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, AlphaDropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy\n",
    "from tensorflow.keras.initializers import HeUniform, GlorotUniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROC-AUC_3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics =[pd.read_csv('../Disease-diagnosis/experiments/exp_{}/EvalResult_{}/overall.csv'.format(i, 'Train'), index_col=0)[['ROC-AUC']].rename(columns=lambda x: x + '_' + str(i))\n",
    "        for i in range(5)]\n",
    "overall = pd.concat(metrics, axis=1)\n",
    "#avg = overall.T.groupby(by=overall.columns.to_series().apply(lambda x: '-'.join(x.split('-')[0:2]) + '(' + x.split('-')[3] + ')')).mean().T\n",
    "#avg = avg.reset_index()\n",
    "overall.mean().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct ontology using mapper file of source samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:CRC (stage 0)\n",
      "root:CRC (stage I)\n",
      "root:CRC (stage II)\n",
      "root:CRC (stage III)\n",
      "root:CRC (stage IV)\n",
      "Reading microbiome structure...\n",
      "Generating Ontology...\n",
      "100%|██████████████████████████████████████████| 5/5 [00:00<00:00, 41282.52it/s]\n",
      "root\n",
      "├── root:CRC (stage 0)\n",
      "├── root:CRC (stage I)\n",
      "├── root:CRC (stage II)\n",
      "├── root:CRC (stage III)\n",
      "└── root:CRC (stage IV)\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!awk -F ',' '{print $5}' dataFiles/CRC_samples_stages.csv | grep -v \"Env\" | sort | uniq  > microbiomes.txt\n",
    "!cat microbiomes.txt\n",
    "!expert construct -i microbiomes.txt -o ontology.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper-parameters for training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = HeUniform(seed=2)\n",
    "sig_init = GlorotUniform(seed=2)\n",
    "phylogeny_path = find_expert_resource('resources/phylogeny.csv')\n",
    "ontology = load_otlg('ontology.pkl')\n",
    "phylogeny = pd.read_csv(phylogeny_path, index_col=0)\n",
    "lrreducer = ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=1e-5, verbose=5, factor=0.1)\n",
    "stopper = EarlyStopping(monitor='val_loss', patience=15, verbose=5, restore_best_weights=True)\n",
    "callbacks = [lrreducer, stopper]\n",
    "phylogeny = pd.read_csv(find_expert_resource('resources/phylogeny.csv'), index_col=0)\n",
    "optimizer = Adam(lr=1e-4)\n",
    "metrics = [BinaryAccuracy(name='acc'), AUC(name='AUC')]\n",
    "loss = BinaryCrossentropy()\n",
    "epochs = 2000\n",
    "batch_size = 32\n",
    "validation_split = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data, using EXPERT's command-line API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping sources to microbiome ontology...\n",
      "The ontology contains 2 layers.\n",
      "Saving labels for each ontology layer...\n",
      "root       571\n",
      "Unknown      0\n",
      "dtype: int64\n",
      "root:CRC (stage 0)       15\n",
      "root:CRC (stage I)      177\n",
      "root:CRC (stage II)     117\n",
      "root:CRC (stage III)     84\n",
      "root:CRC (stage IV)     178\n",
      "Unknown                   0\n",
      "dtype: int64\n",
      "Mapping sources to microbiome ontology...\n",
      "The ontology contains 2 layers.\n",
      "Saving labels for each ontology layer...\n",
      "root       64\n",
      "Unknown     0\n",
      "dtype: int64\n",
      "root:CRC (stage 0)       1\n",
      "root:CRC (stage I)      19\n",
      "root:CRC (stage II)      9\n",
      "root:CRC (stage III)     9\n",
      "root:CRC (stage IV)     26\n",
      "Unknown                  0\n",
      "dtype: int64\n",
      "Mapping sources to microbiome ontology...\n",
      "The ontology contains 2 layers.\n",
      "Saving labels for each ontology layer...\n",
      "root       571\n",
      "Unknown      0\n",
      "dtype: int64\n",
      "root:CRC (stage 0)       13\n",
      "root:CRC (stage I)      180\n",
      "root:CRC (stage II)     114\n",
      "root:CRC (stage III)     80\n",
      "root:CRC (stage IV)     184\n",
      "Unknown                   0\n",
      "dtype: int64\n",
      "Mapping sources to microbiome ontology...\n",
      "The ontology contains 2 layers.\n",
      "Saving labels for each ontology layer...\n",
      "root       64\n",
      "Unknown     0\n",
      "dtype: int64\n",
      "root:CRC (stage 0)       3\n",
      "root:CRC (stage I)      16\n",
      "root:CRC (stage II)     12\n",
      "root:CRC (stage III)    13\n",
      "root:CRC (stage IV)     20\n",
      "Unknown                  0\n",
      "dtype: int64\n",
      "Mapping sources to microbiome ontology...\n",
      "The ontology contains 2 layers.\n",
      "Saving labels for each ontology layer...\n",
      "root       571\n",
      "Unknown      0\n",
      "dtype: int64\n",
      "root:CRC (stage 0)       15\n",
      "root:CRC (stage I)      175\n",
      "root:CRC (stage II)     111\n",
      "root:CRC (stage III)     86\n",
      "root:CRC (stage IV)     184\n",
      "Unknown                   0\n",
      "dtype: int64\n",
      "Mapping sources to microbiome ontology...\n",
      "The ontology contains 2 layers.\n",
      "Saving labels for each ontology layer...\n",
      "root       64\n",
      "Unknown     0\n",
      "dtype: int64\n",
      "root:CRC (stage 0)       1\n",
      "root:CRC (stage I)      21\n",
      "root:CRC (stage II)     15\n",
      "root:CRC (stage III)     7\n",
      "root:CRC (stage IV)     20\n",
      "Unknown                  0\n",
      "dtype: int64\n",
      "Mapping sources to microbiome ontology...\n",
      "The ontology contains 2 layers.\n",
      "Saving labels for each ontology layer...\n",
      "root       571\n",
      "Unknown      0\n",
      "dtype: int64\n",
      "root:CRC (stage 0)       14\n",
      "root:CRC (stage I)      180\n",
      "root:CRC (stage II)     117\n",
      "root:CRC (stage III)     84\n",
      "root:CRC (stage IV)     176\n",
      "Unknown                   0\n",
      "dtype: int64\n",
      "Mapping sources to microbiome ontology...\n",
      "The ontology contains 2 layers.\n",
      "Saving labels for each ontology layer...\n",
      "root       64\n",
      "Unknown     0\n",
      "dtype: int64\n",
      "root:CRC (stage 0)       2\n",
      "root:CRC (stage I)      16\n",
      "root:CRC (stage II)      9\n",
      "root:CRC (stage III)     9\n",
      "root:CRC (stage IV)     28\n",
      "Unknown                  0\n",
      "dtype: int64\n",
      "Mapping sources to microbiome ontology...\n",
      "The ontology contains 2 layers.\n",
      "Saving labels for each ontology layer...\n",
      "root       571\n",
      "Unknown      0\n",
      "dtype: int64\n",
      "root:CRC (stage 0)       15\n",
      "root:CRC (stage I)      174\n",
      "root:CRC (stage II)     112\n",
      "root:CRC (stage III)     86\n",
      "root:CRC (stage IV)     184\n",
      "Unknown                   0\n",
      "dtype: int64\n",
      "Mapping sources to microbiome ontology...\n",
      "The ontology contains 2 layers.\n",
      "Saving labels for each ontology layer...\n",
      "root       64\n",
      "Unknown     0\n",
      "dtype: int64\n",
      "root:CRC (stage 0)       1\n",
      "root:CRC (stage I)      22\n",
      "root:CRC (stage II)     14\n",
      "root:CRC (stage III)     7\n",
      "root:CRC (stage IV)     20\n",
      "Unknown                  0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 215.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 26.42it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 271.19it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 34.45it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 300.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 36.42it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 287.14it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 36.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 279.61it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 34.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 309.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 39.18it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 268.67it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 35.11it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 280.41it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 36.29it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 293.87it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 35.33it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 270.73it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 28.92it/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "for((i=0; i<5; i++)); do \\\n",
    "ls experiments/exp_$i/QueryCM.tsv.gz > tmp; expert convert -i tmp --in-cm -o experiments/exp_$i/QueryCM.h5; \\\n",
    "ls experiments/exp_$i/SourceCM.tsv.gz > tmp; expert convert -i tmp --in-cm -o experiments/exp_$i/SourceCM.h5; \\\n",
    "expert map --to-otlg -t ontology.pkl -i experiments/exp_$i/SourceMapper.csv.gz -o experiments/exp_$i/SourceLabels.h5; \\\n",
    "expert map --to-otlg -t ontology.pkl -i experiments/exp_$i/QueryMapper.csv.gz -o experiments/exp_$i/QueryLabels.h5; \\\n",
    "done\n",
    "#rm tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering labels and samples...\n",
      "Total matched samples: 571\n",
      "N. NaN in input features: 0\n",
      "           mean       std\n",
      "0      0.000000  0.000000\n",
      "1      0.000000  0.000000\n",
      "2      0.000000  0.000000\n",
      "3      0.015062  0.041284\n",
      "4      0.015041  0.041268\n",
      "...         ...       ...\n",
      "18013  0.000061  0.000243\n",
      "18014  0.000000  0.000000\n",
      "18015  0.002382  0.011947\n",
      "18016  0.002317  0.011715\n",
      "18017  0.000000  0.000000\n",
      "\n",
      "[18018 rows x 2 columns]\n",
      "Pre-training using Adam with lr=1e-05...\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.7021 - acc: 0.4877 - val_loss: 0.7029 - val_acc: 0.5069\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6914 - acc: 0.5099 - val_loss: 0.6967 - val_acc: 0.5448\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 18018)]           0         \n",
      "_________________________________________________________________\n",
      "base (Sequential)            (None, 512)               18976256  \n",
      "_________________________________________________________________\n",
      "l2_inter (Sequential)        (None, 10)                21550     \n",
      "_________________________________________________________________\n",
      "l2_integration (Sequential)  (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "l2o (Sequential)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 18,998,051\n",
      "Trainable params: 18,998,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training using Adam with lr=0.001...\n",
      "Epoch 3/1002\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 0.6823 - acc: 0.5279 - auROC: 0.4625 - val_loss: 0.6941 - val_acc: 0.6379 - val_auROC: 0.4617\n",
      "Epoch 4/1002\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6688 - acc: 0.6363 - auROC: 0.5201 - val_loss: 0.6735 - val_acc: 0.6345 - val_auROC: 0.5097\n",
      "Epoch 5/1002\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6355 - acc: 0.6542 - auROC: 0.5638 - val_loss: 0.6531 - val_acc: 0.6552 - val_auROC: 0.5166\n",
      "Epoch 6/1002\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6104 - acc: 0.6854 - auROC: 0.5948 - val_loss: 0.6269 - val_acc: 0.6931 - val_auROC: 0.5285\n",
      "Epoch 7/1002\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5873 - acc: 0.6947 - auROC: 0.5983 - val_loss: 0.6222 - val_acc: 0.6655 - val_auROC: 0.5337\n",
      "Epoch 8/1002\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5709 - acc: 0.6858 - auROC: 0.6302 - val_loss: 0.6046 - val_acc: 0.6966 - val_auROC: 0.5516\n",
      "Epoch 9/1002\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5535 - acc: 0.7298 - auROC: 0.6523 - val_loss: 0.5951 - val_acc: 0.6621 - val_auROC: 0.5532\n",
      "Epoch 10/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5477 - acc: 0.6951 - auROC: 0.6486 - val_loss: 0.5898 - val_acc: 0.7345 - val_auROC: 0.5855\n",
      "Epoch 11/1002\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5368 - acc: 0.7454 - auROC: 0.6779 - val_loss: 0.5720 - val_acc: 0.7034 - val_auROC: 0.5977\n",
      "Epoch 12/1002\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5226 - acc: 0.7341 - auROC: 0.6920 - val_loss: 0.5651 - val_acc: 0.7345 - val_auROC: 0.6020\n",
      "Epoch 13/1002\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5156 - acc: 0.7669 - auROC: 0.6999 - val_loss: 0.5588 - val_acc: 0.7345 - val_auROC: 0.6096\n",
      "Epoch 14/1002\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5075 - acc: 0.7743 - auROC: 0.7094 - val_loss: 0.5575 - val_acc: 0.7414 - val_auROC: 0.6151\n",
      "Epoch 15/1002\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5008 - acc: 0.7778 - auROC: 0.7237 - val_loss: 0.5433 - val_acc: 0.7345 - val_auROC: 0.6479\n",
      "Epoch 16/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4924 - acc: 0.7864 - auROC: 0.7431 - val_loss: 0.5418 - val_acc: 0.7655 - val_auROC: 0.6700\n",
      "Epoch 17/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4885 - acc: 0.7805 - auROC: 0.7566 - val_loss: 0.5363 - val_acc: 0.7448 - val_auROC: 0.6580\n",
      "Epoch 18/1002\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.4834 - acc: 0.7840 - auROC: 0.7564 - val_loss: 0.5318 - val_acc: 0.7517 - val_auROC: 0.6544\n",
      "Epoch 19/1002\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4776 - acc: 0.7957 - auROC: 0.7520 - val_loss: 0.5237 - val_acc: 0.7448 - val_auROC: 0.6796\n",
      "Epoch 20/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4699 - acc: 0.8156 - auROC: 0.7786 - val_loss: 0.5195 - val_acc: 0.7483 - val_auROC: 0.6879\n",
      "Epoch 21/1002\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4652 - acc: 0.8226 - auROC: 0.7955 - val_loss: 0.5148 - val_acc: 0.7379 - val_auROC: 0.6976\n",
      "Epoch 22/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4606 - acc: 0.8140 - auROC: 0.8010 - val_loss: 0.5151 - val_acc: 0.7517 - val_auROC: 0.6921\n",
      "Epoch 23/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4559 - acc: 0.8101 - auROC: 0.8072 - val_loss: 0.5050 - val_acc: 0.7517 - val_auROC: 0.7146\n",
      "Epoch 24/1002\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4489 - acc: 0.8234 - auROC: 0.8213 - val_loss: 0.5010 - val_acc: 0.7655 - val_auROC: 0.7158\n",
      "Epoch 25/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4443 - acc: 0.8292 - auROC: 0.8227 - val_loss: 0.5010 - val_acc: 0.7655 - val_auROC: 0.7131\n",
      "Epoch 26/1002\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4405 - acc: 0.8347 - auROC: 0.8291 - val_loss: 0.4977 - val_acc: 0.7586 - val_auROC: 0.7142\n",
      "Epoch 27/1002\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4368 - acc: 0.8257 - auROC: 0.8233 - val_loss: 0.4946 - val_acc: 0.7724 - val_auROC: 0.7295\n",
      "Epoch 28/1002\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4353 - acc: 0.8448 - auROC: 0.8393 - val_loss: 0.4900 - val_acc: 0.7793 - val_auROC: 0.7326\n",
      "Epoch 29/1002\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4303 - acc: 0.8402 - auROC: 0.8429 - val_loss: 0.4817 - val_acc: 0.7897 - val_auROC: 0.7520\n",
      "Epoch 30/1002\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4234 - acc: 0.8441 - auROC: 0.8542 - val_loss: 0.4762 - val_acc: 0.7897 - val_auROC: 0.7551\n",
      "Epoch 31/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4222 - acc: 0.8468 - auROC: 0.8484 - val_loss: 0.4772 - val_acc: 0.7759 - val_auROC: 0.7419\n",
      "Epoch 32/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4173 - acc: 0.8448 - auROC: 0.8508 - val_loss: 0.4743 - val_acc: 0.7793 - val_auROC: 0.7575\n",
      "Epoch 33/1002\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4137 - acc: 0.8596 - auROC: 0.8641 - val_loss: 0.4741 - val_acc: 0.7966 - val_auROC: 0.7587\n",
      "Epoch 34/1002\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4093 - acc: 0.8647 - auROC: 0.8718 - val_loss: 0.4719 - val_acc: 0.7759 - val_auROC: 0.7465\n",
      "Epoch 35/1002\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4089 - acc: 0.8437 - auROC: 0.8499 - val_loss: 0.4669 - val_acc: 0.8034 - val_auROC: 0.7723\n",
      "Epoch 36/1002\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4055 - acc: 0.8741 - auROC: 0.8764 - val_loss: 0.4661 - val_acc: 0.7897 - val_auROC: 0.7718\n",
      "Epoch 37/1002\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4023 - acc: 0.8577 - auROC: 0.8715 - val_loss: 0.4601 - val_acc: 0.8000 - val_auROC: 0.7764\n",
      "Epoch 38/1002\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3982 - acc: 0.8643 - auROC: 0.8761 - val_loss: 0.4552 - val_acc: 0.8069 - val_auROC: 0.7826\n",
      "Epoch 39/1002\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3945 - acc: 0.8635 - auROC: 0.8785 - val_loss: 0.4562 - val_acc: 0.8034 - val_auROC: 0.7952\n",
      "Epoch 40/1002\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3928 - acc: 0.8628 - auROC: 0.8859 - val_loss: 0.4536 - val_acc: 0.8034 - val_auROC: 0.7798\n",
      "Epoch 41/1002\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3911 - acc: 0.8710 - auROC: 0.8823 - val_loss: 0.4513 - val_acc: 0.8034 - val_auROC: 0.7784\n",
      "Epoch 42/1002\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3866 - acc: 0.8698 - auROC: 0.8819 - val_loss: 0.4492 - val_acc: 0.8241 - val_auROC: 0.7888\n",
      "Epoch 43/1002\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3856 - acc: 0.8671 - auROC: 0.8853 - val_loss: 0.4479 - val_acc: 0.8241 - val_auROC: 0.7915\n",
      "Epoch 44/1002\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3836 - acc: 0.8780 - auROC: 0.8930 - val_loss: 0.4498 - val_acc: 0.8103 - val_auROC: 0.7813\n",
      "Epoch 45/1002\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3816 - acc: 0.8702 - auROC: 0.8867 - val_loss: 0.4460 - val_acc: 0.8172 - val_auROC: 0.7921\n",
      "Epoch 46/1002\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3786 - acc: 0.8702 - auROC: 0.8916 - val_loss: 0.4405 - val_acc: 0.8172 - val_auROC: 0.7903\n",
      "Epoch 47/1002\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3748 - acc: 0.8846 - auROC: 0.8963 - val_loss: 0.4412 - val_acc: 0.8103 - val_auROC: 0.7828\n",
      "Epoch 48/1002\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3745 - acc: 0.8760 - auROC: 0.8893 - val_loss: 0.4416 - val_acc: 0.8207 - val_auROC: 0.8011\n",
      "Epoch 49/1002\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3709 - acc: 0.8834 - auROC: 0.9044 - val_loss: 0.4380 - val_acc: 0.8000 - val_auROC: 0.7862\n",
      "Epoch 50/1002\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3689 - acc: 0.8690 - auROC: 0.8932 - val_loss: 0.4348 - val_acc: 0.8103 - val_auROC: 0.7958\n",
      "Epoch 51/1002\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3672 - acc: 0.8768 - auROC: 0.8990 - val_loss: 0.4311 - val_acc: 0.8138 - val_auROC: 0.8021\n",
      "Epoch 52/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3645 - acc: 0.8807 - auROC: 0.9043 - val_loss: 0.4327 - val_acc: 0.8379 - val_auROC: 0.8082\n",
      "Epoch 53/1002\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3628 - acc: 0.8842 - auROC: 0.9071 - val_loss: 0.4311 - val_acc: 0.8276 - val_auROC: 0.7996\n",
      "Epoch 54/1002\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3606 - acc: 0.8838 - auROC: 0.9045 - val_loss: 0.4296 - val_acc: 0.8241 - val_auROC: 0.7989\n",
      "Epoch 55/1002\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3586 - acc: 0.8862 - auROC: 0.9043 - val_loss: 0.4268 - val_acc: 0.8241 - val_auROC: 0.8058\n",
      "Epoch 56/1002\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3565 - acc: 0.8862 - auROC: 0.9096 - val_loss: 0.4281 - val_acc: 0.8379 - val_auROC: 0.8158\n",
      "Epoch 57/1002\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3556 - acc: 0.8908 - auROC: 0.9144 - val_loss: 0.4238 - val_acc: 0.8310 - val_auROC: 0.8053\n",
      "Epoch 58/1002\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3539 - acc: 0.8823 - auROC: 0.9082 - val_loss: 0.4224 - val_acc: 0.8414 - val_auROC: 0.8092\n",
      "Epoch 59/1002\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3517 - acc: 0.8889 - auROC: 0.9118 - val_loss: 0.4233 - val_acc: 0.8483 - val_auROC: 0.8152\n",
      "Epoch 60/1002\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3494 - acc: 0.8943 - auROC: 0.9168 - val_loss: 0.4214 - val_acc: 0.8345 - val_auROC: 0.8092\n",
      "Epoch 61/1002\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3486 - acc: 0.8932 - auROC: 0.9137 - val_loss: 0.4203 - val_acc: 0.8517 - val_auROC: 0.8199\n",
      "Epoch 62/1002\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3471 - acc: 0.8998 - auROC: 0.9211 - val_loss: 0.4172 - val_acc: 0.8345 - val_auROC: 0.8071\n",
      "Epoch 63/1002\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.3451 - acc: 0.8963 - auROC: 0.9138 - val_loss: 0.4160 - val_acc: 0.8276 - val_auROC: 0.8094\n",
      "Epoch 64/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3434 - acc: 0.8943 - auROC: 0.9165 - val_loss: 0.4163 - val_acc: 0.8621 - val_auROC: 0.8226\n",
      "Epoch 65/1002\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3416 - acc: 0.9115 - auROC: 0.9258 - val_loss: 0.4133 - val_acc: 0.8552 - val_auROC: 0.8164\n",
      "Epoch 66/1002\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3399 - acc: 0.9080 - auROC: 0.9210 - val_loss: 0.4117 - val_acc: 0.8448 - val_auROC: 0.8146\n",
      "Epoch 67/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3397 - acc: 0.8986 - auROC: 0.9180 - val_loss: 0.4121 - val_acc: 0.8655 - val_auROC: 0.8313\n",
      "Epoch 68/1002\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3378 - acc: 0.9060 - auROC: 0.9280 - val_loss: 0.4075 - val_acc: 0.8448 - val_auROC: 0.8238\n",
      "Epoch 69/1002\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.3359 - acc: 0.9010 - auROC: 0.9220 - val_loss: 0.4058 - val_acc: 0.8448 - val_auROC: 0.8229\n",
      "Epoch 70/1002\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3343 - acc: 0.9014 - auROC: 0.9229 - val_loss: 0.4050 - val_acc: 0.8552 - val_auROC: 0.8349\n",
      "Epoch 71/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3327 - acc: 0.9099 - auROC: 0.9319 - val_loss: 0.4058 - val_acc: 0.8448 - val_auROC: 0.8183\n",
      "Epoch 72/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3308 - acc: 0.9021 - auROC: 0.9234 - val_loss: 0.4059 - val_acc: 0.8448 - val_auROC: 0.8151\n",
      "Epoch 73/1002\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3296 - acc: 0.9014 - auROC: 0.9228 - val_loss: 0.4017 - val_acc: 0.8552 - val_auROC: 0.8332\n",
      "Epoch 74/1002\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3276 - acc: 0.9111 - auROC: 0.9315 - val_loss: 0.3974 - val_acc: 0.8621 - val_auROC: 0.8345\n",
      "Epoch 75/1002\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3257 - acc: 0.9096 - auROC: 0.9306 - val_loss: 0.3967 - val_acc: 0.8552 - val_auROC: 0.8272\n",
      "Epoch 76/1002\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3241 - acc: 0.9057 - auROC: 0.9295 - val_loss: 0.3971 - val_acc: 0.8621 - val_auROC: 0.8323\n",
      "Epoch 77/1002\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3229 - acc: 0.9111 - auROC: 0.9333 - val_loss: 0.3954 - val_acc: 0.8552 - val_auROC: 0.8301\n",
      "Epoch 78/1002\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3203 - acc: 0.9072 - auROC: 0.9324 - val_loss: 0.3918 - val_acc: 0.8621 - val_auROC: 0.8359\n",
      "Epoch 79/1002\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.3194 - acc: 0.9080 - auROC: 0.9332 - val_loss: 0.3906 - val_acc: 0.8655 - val_auROC: 0.8429\n",
      "Epoch 80/1002\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3184 - acc: 0.9099 - auROC: 0.9358 - val_loss: 0.3892 - val_acc: 0.8586 - val_auROC: 0.8346\n",
      "Epoch 81/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3165 - acc: 0.9072 - auROC: 0.9329 - val_loss: 0.3893 - val_acc: 0.8552 - val_auROC: 0.8352\n",
      "Epoch 82/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3151 - acc: 0.9088 - auROC: 0.9334 - val_loss: 0.3896 - val_acc: 0.8724 - val_auROC: 0.8394\n",
      "Epoch 83/1002\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3150 - acc: 0.9127 - auROC: 0.9360 - val_loss: 0.3893 - val_acc: 0.8621 - val_auROC: 0.8371\n",
      "Epoch 84/1002\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3139 - acc: 0.9099 - auROC: 0.9346 - val_loss: 0.3878 - val_acc: 0.8621 - val_auROC: 0.8393\n",
      "Epoch 85/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3119 - acc: 0.9111 - auROC: 0.9364 - val_loss: 0.3887 - val_acc: 0.8759 - val_auROC: 0.8381\n",
      "Epoch 86/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3113 - acc: 0.9131 - auROC: 0.9368 - val_loss: 0.3882 - val_acc: 0.8586 - val_auROC: 0.8334\n",
      "Epoch 87/1002\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3096 - acc: 0.9103 - auROC: 0.9358 - val_loss: 0.3869 - val_acc: 0.8655 - val_auROC: 0.8346\n",
      "Epoch 88/1002\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3080 - acc: 0.9142 - auROC: 0.9376 - val_loss: 0.3861 - val_acc: 0.8793 - val_auROC: 0.8370\n",
      "Epoch 89/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3071 - acc: 0.9216 - auROC: 0.9397 - val_loss: 0.3867 - val_acc: 0.8724 - val_auROC: 0.8315\n",
      "Epoch 90/1002\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3050 - acc: 0.9158 - auROC: 0.9378 - val_loss: 0.3837 - val_acc: 0.8828 - val_auROC: 0.8381\n",
      "Epoch 91/1002\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3040 - acc: 0.9216 - auROC: 0.9372 - val_loss: 0.3812 - val_acc: 0.8897 - val_auROC: 0.8495\n",
      "Epoch 92/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3020 - acc: 0.9279 - auROC: 0.9401 - val_loss: 0.3816 - val_acc: 0.8897 - val_auROC: 0.8434\n",
      "Epoch 93/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.3011 - acc: 0.9279 - auROC: 0.9387 - val_loss: 0.3792 - val_acc: 0.8897 - val_auROC: 0.8440\n",
      "Epoch 94/1002\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.2994 - acc: 0.9302 - auROC: 0.9388 - val_loss: 0.3776 - val_acc: 0.8931 - val_auROC: 0.8488\n",
      "Epoch 95/1002\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2984 - acc: 0.9294 - auROC: 0.9408 - val_loss: 0.3779 - val_acc: 0.8793 - val_auROC: 0.8439\n",
      "Epoch 96/1002\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2979 - acc: 0.9279 - auROC: 0.9383 - val_loss: 0.3819 - val_acc: 0.8793 - val_auROC: 0.8417\n",
      "Epoch 97/1002\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2962 - acc: 0.9310 - auROC: 0.9399 - val_loss: 0.3839 - val_acc: 0.8793 - val_auROC: 0.8383\n",
      "Epoch 98/1002\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2951 - acc: 0.9314 - auROC: 0.9410 - val_loss: 0.3852 - val_acc: 0.8862 - val_auROC: 0.8350\n",
      "Epoch 99/1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2959 - acc: 0.9318 - auROC: 0.9394\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2959 - acc: 0.9318 - auROC: 0.9394 - val_loss: 0.3854 - val_acc: 0.8828 - val_auROC: 0.8364\n",
      "Epoch 100/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2943 - acc: 0.9329 - auROC: 0.9415 - val_loss: 0.3854 - val_acc: 0.8828 - val_auROC: 0.8356\n",
      "Epoch 101/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2937 - acc: 0.9333 - auROC: 0.9418 - val_loss: 0.3848 - val_acc: 0.8828 - val_auROC: 0.8356\n",
      "Epoch 102/1002\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2930 - acc: 0.9329 - auROC: 0.9419 - val_loss: 0.3840 - val_acc: 0.8828 - val_auROC: 0.8364\n",
      "Epoch 103/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2925 - acc: 0.9326 - auROC: 0.9419 - val_loss: 0.3848 - val_acc: 0.8828 - val_auROC: 0.8338\n",
      "Epoch 104/1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2923 - acc: 0.9329 - auROC: 0.9413\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2923 - acc: 0.9329 - auROC: 0.9413 - val_loss: 0.3852 - val_acc: 0.8862 - val_auROC: 0.8319\n",
      "Epoch 105/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2922 - acc: 0.9329 - auROC: 0.9409 - val_loss: 0.3852 - val_acc: 0.8862 - val_auROC: 0.8319\n",
      "Epoch 106/1002\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2922 - acc: 0.9329 - auROC: 0.9409 - val_loss: 0.3852 - val_acc: 0.8862 - val_auROC: 0.8320\n",
      "Epoch 107/1002\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2922 - acc: 0.9329 - auROC: 0.9409 - val_loss: 0.3852 - val_acc: 0.8862 - val_auROC: 0.8320\n",
      "Epoch 108/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2922 - acc: 0.9326 - auROC: 0.9409 - val_loss: 0.3852 - val_acc: 0.8862 - val_auROC: 0.8320\n",
      "Epoch 109/1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2922 - acc: 0.9326 - auROC: 0.9409\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2922 - acc: 0.9326 - auROC: 0.9409 - val_loss: 0.3852 - val_acc: 0.8862 - val_auROC: 0.8318\n",
      "Epoch 00109: early stopping\n",
      "    0      1      2         3      ...  18014     18015     18016  18017\n",
      "0     0.0    0.0    0.0 -0.364832  ...    0.0 -0.199372 -0.197762    0.0\n",
      "1     0.0    0.0    0.0 -0.207833  ...    0.0 -0.199372 -0.197762    0.0\n",
      "2     0.0    0.0    0.0 -0.330822  ...    0.0 -0.199372 -0.197762    0.0\n",
      "3     0.0    0.0    0.0 -0.364268  ...    0.0  2.631308  2.667556    0.0\n",
      "4     0.0    0.0    0.0  1.188823  ...    0.0 -0.199372 -0.197762    0.0\n",
      "..    ...    ...    ...       ...  ...    ...       ...       ...    ...\n",
      "59    0.0    0.0    0.0 -0.265638  ...    0.0 -0.199372 -0.197762    0.0\n",
      "60    0.0    0.0    0.0 -0.364832  ...    0.0 -0.199372 -0.197762    0.0\n",
      "61    0.0    0.0    0.0 -0.364832  ...    0.0 -0.199372 -0.197762    0.0\n",
      "62    0.0    0.0    0.0 -0.364832  ...    0.0 -0.199372 -0.197762    0.0\n",
      "63    0.0    0.0    0.0 -0.364832  ...    0.0 -0.199372 -0.197762    0.0\n",
      "\n",
      "[64 rows x 18018 columns]\n",
      "Total NANs in input samples: 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "18013    0\n",
      "18014    0\n",
      "18015    0\n",
      "18016    0\n",
      "18017    0\n",
      "Length: 18018, dtype: int64\n",
      "Reordering labels and prediction result\n",
      "Reordering labels and prediction result for samples\n",
      "Running evaluation...\n",
      "Evaluating biome source: root:CRC (stage 0)\n",
      "      TN  FP  FN  TP  Acc   Sn   Sp  TPR  FPR   Rc   Pr  F1  ROC-AUC  F-max\n",
      "t                                                                          \n",
      "0.00   0  62   0   0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.01   0  62   0   0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.02   0  62   0   0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.03   0  62   0   0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.04   0  62   0   0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 NaN      0.0    NaN\n",
      "...   ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...  ..      ...    ...\n",
      "0.97  62   0   0   0  1.0  0.0  1.0  0.0  0.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.98  62   0   0   0  1.0  0.0  1.0  0.0  0.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.99  62   0   0   0  1.0  0.0  1.0  0.0  0.0  0.0  0.0 NaN      0.0    NaN\n",
      "1.00  62   0   0   0  1.0  0.0  1.0  0.0  0.0  0.0  0.0 NaN      0.0    NaN\n",
      "1.01  62   0   0   0  1.0  0.0  1.0  0.0  0.0  0.0  0.0 NaN      0.0    NaN\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage I)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                           \n",
      "0.00   0  42   0  20  0.3226  1.0  ...  1.0  1.0  0.3226  0.4878    0.932  0.8085\n",
      "0.01   0  42   0  20  0.3226  1.0  ...  1.0  1.0  0.3226  0.4878    0.932  0.8085\n",
      "0.02   0  42   0  20  0.3226  1.0  ...  1.0  1.0  0.3226  0.4878    0.932  0.8085\n",
      "0.03   0  42   0  20  0.3226  1.0  ...  1.0  1.0  0.3226  0.4878    0.932  0.8085\n",
      "0.04   0  42   0  20  0.3226  1.0  ...  1.0  1.0  0.3226  0.4878    0.932  0.8085\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...     ...\n",
      "0.97  42   0  20   0  0.6774  0.0  ...  0.0  0.0  0.0000     NaN    0.932  0.8085\n",
      "0.98  42   0  20   0  0.6774  0.0  ...  0.0  0.0  0.0000     NaN    0.932  0.8085\n",
      "0.99  42   0  20   0  0.6774  0.0  ...  0.0  0.0  0.0000     NaN    0.932  0.8085\n",
      "1.00  42   0  20   0  0.6774  0.0  ...  0.0  0.0  0.0000     NaN    0.932  0.8085\n",
      "1.01  42   0  20   0  0.6774  0.0  ...  0.0  0.0  0.0000     NaN    0.932  0.8085\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage II)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                          \n",
      "0.00   0  48   0  14  0.2258  1.0  ...  1.0  1.0  0.2258  0.3684    0.982  0.963\n",
      "0.01   0  48   0  14  0.2258  1.0  ...  1.0  1.0  0.2258  0.3684    0.982  0.963\n",
      "0.02   0  48   0  14  0.2258  1.0  ...  1.0  1.0  0.2258  0.3684    0.982  0.963\n",
      "0.03   0  48   0  14  0.2258  1.0  ...  1.0  1.0  0.2258  0.3684    0.982  0.963\n",
      "0.04   0  48   0  14  0.2258  1.0  ...  1.0  1.0  0.2258  0.3684    0.982  0.963\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...    ...\n",
      "0.97  48   0  14   0  0.7742  0.0  ...  0.0  0.0  0.0000     NaN    0.982  0.963\n",
      "0.98  48   0  14   0  0.7742  0.0  ...  0.0  0.0  0.0000     NaN    0.982  0.963\n",
      "0.99  48   0  14   0  0.7742  0.0  ...  0.0  0.0  0.0000     NaN    0.982  0.963\n",
      "1.00  48   0  14   0  0.7742  0.0  ...  0.0  0.0  0.0000     NaN    0.982  0.963\n",
      "1.01  48   0  14   0  0.7742  0.0  ...  0.0  0.0  0.0000     NaN    0.982  0.963\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage III)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                              \n",
      "0.00   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765     0.88  0.8889\n",
      "0.01   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765     0.88  0.8889\n",
      "0.02   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765     0.88  0.8889\n",
      "0.03   7  48   0   6  0.2131  1.0  ...  0.8727  1.0  0.1111  0.2000     0.88  0.8889\n",
      "0.04  14  41   0   6  0.3279  1.0  ...  0.7455  1.0  0.1277  0.2264     0.88  0.8889\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...     ...\n",
      "0.97  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN     0.88  0.8889\n",
      "0.98  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN     0.88  0.8889\n",
      "0.99  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN     0.88  0.8889\n",
      "1.00  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN     0.88  0.8889\n",
      "1.01  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN     0.88  0.8889\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage IV)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                           \n",
      "0.00   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9888  0.9444\n",
      "0.01   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9888  0.9444\n",
      "0.02   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9888  0.9444\n",
      "0.03   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9888  0.9444\n",
      "0.04   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9888  0.9444\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...     ...\n",
      "0.97  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9888  0.9444\n",
      "0.98  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9888  0.9444\n",
      "0.99  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9888  0.9444\n",
      "1.00  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9888  0.9444\n",
      "1.01  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9888  0.9444\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Saving evaluation results...\n",
      "Reordering labels and samples...\n",
      "Total matched samples: 571\n",
      "Total correct samples: 571?571\n",
      "           mean       std\n",
      "0      0.000000  0.000000\n",
      "1      0.000000  0.000000\n",
      "2      0.000000  0.000000\n",
      "3      0.015062  0.041284\n",
      "4      0.015041  0.041268\n",
      "...         ...       ...\n",
      "18013  0.000061  0.000243\n",
      "18014  0.000000  0.000000\n",
      "18015  0.002382  0.011947\n",
      "18016  0.002317  0.011715\n",
      "18017  0.000000  0.000000\n",
      "\n",
      "[18018 rows x 2 columns]\n",
      "Training using optimizer with lr=0.001...\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.6981 - acc: 0.5797 - auROC: 0.4507 - val_loss: 0.6006 - val_acc: 0.6586 - val_auROC: 0.5480\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.5981 - acc: 0.6803 - auROC: 0.5276 - val_loss: 0.5534 - val_acc: 0.7241 - val_auROC: 0.5964\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.5471 - acc: 0.7474 - auROC: 0.6079 - val_loss: 0.5179 - val_acc: 0.7793 - val_auROC: 0.6923\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.5269 - acc: 0.7708 - auROC: 0.6520 - val_loss: 0.4984 - val_acc: 0.7966 - val_auROC: 0.7096\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5182 - acc: 0.7801 - auROC: 0.6441 - val_loss: 0.5027 - val_acc: 0.7759 - val_auROC: 0.6680\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.4993 - acc: 0.7903 - auROC: 0.6873 - val_loss: 0.4908 - val_acc: 0.7724 - val_auROC: 0.7085\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4781 - acc: 0.7899 - auROC: 0.7397 - val_loss: 0.4576 - val_acc: 0.8069 - val_auROC: 0.7842\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4574 - acc: 0.8066 - auROC: 0.7805 - val_loss: 0.4377 - val_acc: 0.8103 - val_auROC: 0.8158\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4400 - acc: 0.8105 - auROC: 0.8045 - val_loss: 0.4257 - val_acc: 0.8241 - val_auROC: 0.8241\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4271 - acc: 0.8265 - auROC: 0.8150 - val_loss: 0.4185 - val_acc: 0.8207 - val_auROC: 0.8190\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4187 - acc: 0.8304 - auROC: 0.8332 - val_loss: 0.4048 - val_acc: 0.8379 - val_auROC: 0.8475\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4190 - acc: 0.8253 - auROC: 0.8287 - val_loss: 0.3923 - val_acc: 0.8310 - val_auROC: 0.8631\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4053 - acc: 0.8288 - auROC: 0.8421 - val_loss: 0.3894 - val_acc: 0.8414 - val_auROC: 0.8682\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3990 - acc: 0.8394 - auROC: 0.8493 - val_loss: 0.3810 - val_acc: 0.8483 - val_auROC: 0.8732\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3890 - acc: 0.8491 - auROC: 0.8618 - val_loss: 0.3744 - val_acc: 0.8552 - val_auROC: 0.8758\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3783 - acc: 0.8515 - auROC: 0.8751 - val_loss: 0.3623 - val_acc: 0.8517 - val_auROC: 0.8902\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3715 - acc: 0.8577 - auROC: 0.8794 - val_loss: 0.3597 - val_acc: 0.8517 - val_auROC: 0.8892\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3721 - acc: 0.8577 - auROC: 0.8750 - val_loss: 0.3470 - val_acc: 0.8586 - val_auROC: 0.9196\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3636 - acc: 0.8565 - auROC: 0.8856 - val_loss: 0.3465 - val_acc: 0.8655 - val_auROC: 0.9080\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3621 - acc: 0.8569 - auROC: 0.8868 - val_loss: 0.3668 - val_acc: 0.8552 - val_auROC: 0.8730\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3642 - acc: 0.8616 - auROC: 0.8834 - val_loss: 0.3503 - val_acc: 0.8552 - val_auROC: 0.8968\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3524 - acc: 0.8624 - auROC: 0.8932 - val_loss: 0.3397 - val_acc: 0.8690 - val_auROC: 0.9095\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3475 - acc: 0.8620 - auROC: 0.8963 - val_loss: 0.3396 - val_acc: 0.8655 - val_auROC: 0.9114\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3430 - acc: 0.8678 - auROC: 0.9029 - val_loss: 0.3259 - val_acc: 0.8759 - val_auROC: 0.9246\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3371 - acc: 0.8710 - auROC: 0.9085 - val_loss: 0.3230 - val_acc: 0.8759 - val_auROC: 0.9376\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3345 - acc: 0.8698 - auROC: 0.9117 - val_loss: 0.3287 - val_acc: 0.8724 - val_auROC: 0.9138\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3379 - acc: 0.8686 - auROC: 0.9005 - val_loss: 0.3371 - val_acc: 0.8724 - val_auROC: 0.8986\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3416 - acc: 0.8577 - auROC: 0.8936 - val_loss: 0.3436 - val_acc: 0.8759 - val_auROC: 0.8751\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3317 - acc: 0.8710 - auROC: 0.9021 - val_loss: 0.3278 - val_acc: 0.8828 - val_auROC: 0.8983\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3234 - acc: 0.8795 - auROC: 0.9111 - val_loss: 0.3123 - val_acc: 0.8966 - val_auROC: 0.9158\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3133 - acc: 0.8920 - auROC: 0.9237 - val_loss: 0.3030 - val_acc: 0.8966 - val_auROC: 0.9327\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3060 - acc: 0.8920 - auROC: 0.9311 - val_loss: 0.2975 - val_acc: 0.9000 - val_auROC: 0.9352\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3018 - acc: 0.9002 - auROC: 0.9340 - val_loss: 0.2936 - val_acc: 0.9000 - val_auROC: 0.9408\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2963 - acc: 0.9018 - auROC: 0.9398 - val_loss: 0.2786 - val_acc: 0.9103 - val_auROC: 0.9567\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2895 - acc: 0.9096 - auROC: 0.9452 - val_loss: 0.2764 - val_acc: 0.9138 - val_auROC: 0.9559\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2845 - acc: 0.9103 - auROC: 0.9467 - val_loss: 0.2683 - val_acc: 0.9207 - val_auROC: 0.9601\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2783 - acc: 0.9142 - auROC: 0.9526 - val_loss: 0.2642 - val_acc: 0.9241 - val_auROC: 0.9634\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2766 - acc: 0.9162 - auROC: 0.9534 - val_loss: 0.2618 - val_acc: 0.9345 - val_auROC: 0.9679\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2740 - acc: 0.9119 - auROC: 0.9536 - val_loss: 0.2591 - val_acc: 0.9241 - val_auROC: 0.9689\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2722 - acc: 0.9142 - auROC: 0.9526 - val_loss: 0.2635 - val_acc: 0.9138 - val_auROC: 0.9598\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2817 - acc: 0.9049 - auROC: 0.9419 - val_loss: 0.2652 - val_acc: 0.9138 - val_auROC: 0.9628\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2691 - acc: 0.9181 - auROC: 0.9530 - val_loss: 0.2830 - val_acc: 0.8966 - val_auROC: 0.9464\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3079 - acc: 0.8955 - auROC: 0.9097 - val_loss: 0.2889 - val_acc: 0.8966 - val_auROC: 0.9358\n",
      "Epoch 44/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.2863 - acc: 0.9012 - auROC: 0.9363\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2861 - acc: 0.9014 - auROC: 0.9365 - val_loss: 0.2616 - val_acc: 0.9138 - val_auROC: 0.9581\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2696 - acc: 0.9127 - auROC: 0.9493 - val_loss: 0.2533 - val_acc: 0.9207 - val_auROC: 0.9657\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2643 - acc: 0.9158 - auROC: 0.9537 - val_loss: 0.2500 - val_acc: 0.9207 - val_auROC: 0.9682\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2617 - acc: 0.9177 - auROC: 0.9568 - val_loss: 0.2504 - val_acc: 0.9172 - val_auROC: 0.9702\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2586 - acc: 0.9197 - auROC: 0.9595 - val_loss: 0.2388 - val_acc: 0.9241 - val_auROC: 0.9781\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2550 - acc: 0.9240 - auROC: 0.9604 - val_loss: 0.2330 - val_acc: 0.9310 - val_auROC: 0.9807\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2560 - acc: 0.9209 - auROC: 0.9609 - val_loss: 0.2435 - val_acc: 0.9241 - val_auROC: 0.9722\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2589 - acc: 0.9189 - auROC: 0.9583 - val_loss: 0.2362 - val_acc: 0.9345 - val_auROC: 0.9761\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2536 - acc: 0.9244 - auROC: 0.9632 - val_loss: 0.2268 - val_acc: 0.9414 - val_auROC: 0.9821\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2481 - acc: 0.9290 - auROC: 0.9670 - val_loss: 0.2240 - val_acc: 0.9414 - val_auROC: 0.9841\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2466 - acc: 0.9318 - auROC: 0.9674 - val_loss: 0.2236 - val_acc: 0.9483 - val_auROC: 0.9839\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2449 - acc: 0.9326 - auROC: 0.9684 - val_loss: 0.2231 - val_acc: 0.9483 - val_auROC: 0.9840\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2437 - acc: 0.9329 - auROC: 0.9689 - val_loss: 0.2227 - val_acc: 0.9483 - val_auROC: 0.9844\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2427 - acc: 0.9318 - auROC: 0.9694 - val_loss: 0.2218 - val_acc: 0.9483 - val_auROC: 0.9847\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2418 - acc: 0.9337 - auROC: 0.9699 - val_loss: 0.2215 - val_acc: 0.9483 - val_auROC: 0.9843\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2411 - acc: 0.9337 - auROC: 0.9704 - val_loss: 0.2200 - val_acc: 0.9483 - val_auROC: 0.9851\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2404 - acc: 0.9333 - auROC: 0.9708 - val_loss: 0.2190 - val_acc: 0.9448 - val_auROC: 0.9858\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2397 - acc: 0.9337 - auROC: 0.9708 - val_loss: 0.2197 - val_acc: 0.9448 - val_auROC: 0.9852\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2391 - acc: 0.9345 - auROC: 0.9709 - val_loss: 0.2204 - val_acc: 0.9483 - val_auROC: 0.9841\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2383 - acc: 0.9349 - auROC: 0.9715 - val_loss: 0.2179 - val_acc: 0.9483 - val_auROC: 0.9855\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2378 - acc: 0.9345 - auROC: 0.9718 - val_loss: 0.2163 - val_acc: 0.9483 - val_auROC: 0.9865\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2373 - acc: 0.9337 - auROC: 0.9723 - val_loss: 0.2160 - val_acc: 0.9448 - val_auROC: 0.9865\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2363 - acc: 0.9345 - auROC: 0.9730 - val_loss: 0.2155 - val_acc: 0.9448 - val_auROC: 0.9867\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2353 - acc: 0.9349 - auROC: 0.9741 - val_loss: 0.2156 - val_acc: 0.9448 - val_auROC: 0.9868\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2344 - acc: 0.9353 - auROC: 0.9747 - val_loss: 0.2167 - val_acc: 0.9448 - val_auROC: 0.9852\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2336 - acc: 0.9357 - auROC: 0.9747 - val_loss: 0.2162 - val_acc: 0.9448 - val_auROC: 0.9854\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2329 - acc: 0.9372 - auROC: 0.9749 - val_loss: 0.2162 - val_acc: 0.9448 - val_auROC: 0.9854\n",
      "Epoch 71/300\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.2312 - acc: 0.9406 - auROC: 0.9750\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2326 - acc: 0.9388 - auROC: 0.9747 - val_loss: 0.2157 - val_acc: 0.9448 - val_auROC: 0.9860\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2320 - acc: 0.9388 - auROC: 0.9749 - val_loss: 0.2158 - val_acc: 0.9448 - val_auROC: 0.9855\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2319 - acc: 0.9392 - auROC: 0.9750 - val_loss: 0.2160 - val_acc: 0.9448 - val_auROC: 0.9855\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2318 - acc: 0.9384 - auROC: 0.9752 - val_loss: 0.2160 - val_acc: 0.9448 - val_auROC: 0.9854\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2316 - acc: 0.9388 - auROC: 0.9753 - val_loss: 0.2158 - val_acc: 0.9448 - val_auROC: 0.9855\n",
      "Epoch 76/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.2315 - acc: 0.9387 - auROC: 0.9753\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2315 - acc: 0.9388 - auROC: 0.9753 - val_loss: 0.2157 - val_acc: 0.9448 - val_auROC: 0.9855\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2313 - acc: 0.9388 - auROC: 0.9754 - val_loss: 0.2156 - val_acc: 0.9448 - val_auROC: 0.9856\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2312 - acc: 0.9388 - auROC: 0.9754 - val_loss: 0.2154 - val_acc: 0.9448 - val_auROC: 0.9856\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2311 - acc: 0.9384 - auROC: 0.9754 - val_loss: 0.2153 - val_acc: 0.9448 - val_auROC: 0.9856\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2310 - acc: 0.9384 - auROC: 0.9755 - val_loss: 0.2151 - val_acc: 0.9448 - val_auROC: 0.9856\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2310 - acc: 0.9384 - auROC: 0.9756 - val_loss: 0.2149 - val_acc: 0.9448 - val_auROC: 0.9858\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2309 - acc: 0.9384 - auROC: 0.9756 - val_loss: 0.2148 - val_acc: 0.9448 - val_auROC: 0.9860\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2308 - acc: 0.9384 - auROC: 0.9756 - val_loss: 0.2147 - val_acc: 0.9448 - val_auROC: 0.9860\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2308 - acc: 0.9384 - auROC: 0.9756 - val_loss: 0.2148 - val_acc: 0.9448 - val_auROC: 0.9857\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2307 - acc: 0.9384 - auROC: 0.9757 - val_loss: 0.2147 - val_acc: 0.9448 - val_auROC: 0.9857\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2307 - acc: 0.9384 - auROC: 0.9757 - val_loss: 0.2145 - val_acc: 0.9448 - val_auROC: 0.9861\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2306 - acc: 0.9384 - auROC: 0.9757 - val_loss: 0.2144 - val_acc: 0.9448 - val_auROC: 0.9862\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2305 - acc: 0.9384 - auROC: 0.9758 - val_loss: 0.2141 - val_acc: 0.9448 - val_auROC: 0.9865\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2304 - acc: 0.9384 - auROC: 0.9758 - val_loss: 0.2140 - val_acc: 0.9448 - val_auROC: 0.9864\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2304 - acc: 0.9384 - auROC: 0.9758 - val_loss: 0.2139 - val_acc: 0.9448 - val_auROC: 0.9865\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2303 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2137 - val_acc: 0.9448 - val_auROC: 0.9865\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2302 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2135 - val_acc: 0.9448 - val_auROC: 0.9866\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2302 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2135 - val_acc: 0.9448 - val_auROC: 0.9864\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2301 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2134 - val_acc: 0.9448 - val_auROC: 0.9866\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2301 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2134 - val_acc: 0.9448 - val_auROC: 0.9866\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2300 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2134 - val_acc: 0.9448 - val_auROC: 0.9866\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2300 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2134 - val_acc: 0.9448 - val_auROC: 0.9864\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2299 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2134 - val_acc: 0.9448 - val_auROC: 0.9864\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2299 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2134 - val_acc: 0.9448 - val_auROC: 0.9863\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2298 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2133 - val_acc: 0.9448 - val_auROC: 0.9865\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2298 - acc: 0.9384 - auROC: 0.9759 - val_loss: 0.2132 - val_acc: 0.9448 - val_auROC: 0.9865\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2297 - acc: 0.9384 - auROC: 0.9760 - val_loss: 0.2132 - val_acc: 0.9448 - val_auROC: 0.9865\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2296 - acc: 0.9384 - auROC: 0.9760 - val_loss: 0.2131 - val_acc: 0.9448 - val_auROC: 0.9865\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2296 - acc: 0.9384 - auROC: 0.9760 - val_loss: 0.2132 - val_acc: 0.9448 - val_auROC: 0.9865\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2296 - acc: 0.9384 - auROC: 0.9760 - val_loss: 0.2131 - val_acc: 0.9448 - val_auROC: 0.9866\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2296 - acc: 0.9388 - auROC: 0.9760 - val_loss: 0.2130 - val_acc: 0.9448 - val_auROC: 0.9868\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2295 - acc: 0.9388 - auROC: 0.9760 - val_loss: 0.2128 - val_acc: 0.9448 - val_auROC: 0.9868\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2294 - acc: 0.9388 - auROC: 0.9760 - val_loss: 0.2128 - val_acc: 0.9448 - val_auROC: 0.9868\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2294 - acc: 0.9388 - auROC: 0.9761 - val_loss: 0.2127 - val_acc: 0.9448 - val_auROC: 0.9868\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2293 - acc: 0.9388 - auROC: 0.9761 - val_loss: 0.2126 - val_acc: 0.9448 - val_auROC: 0.9868\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2293 - acc: 0.9388 - auROC: 0.9761 - val_loss: 0.2127 - val_acc: 0.9448 - val_auROC: 0.9868\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2292 - acc: 0.9388 - auROC: 0.9761 - val_loss: 0.2133 - val_acc: 0.9448 - val_auROC: 0.9860\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2292 - acc: 0.9384 - auROC: 0.9761 - val_loss: 0.2134 - val_acc: 0.9448 - val_auROC: 0.9857\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2292 - acc: 0.9388 - auROC: 0.9761 - val_loss: 0.2133 - val_acc: 0.9448 - val_auROC: 0.9859\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2291 - acc: 0.9392 - auROC: 0.9761 - val_loss: 0.2130 - val_acc: 0.9448 - val_auROC: 0.9863\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2290 - acc: 0.9388 - auROC: 0.9761 - val_loss: 0.2127 - val_acc: 0.9448 - val_auROC: 0.9864\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2291 - acc: 0.9388 - auROC: 0.9761 - val_loss: 0.2123 - val_acc: 0.9483 - val_auROC: 0.9861\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2290 - acc: 0.9388 - auROC: 0.9762 - val_loss: 0.2122 - val_acc: 0.9483 - val_auROC: 0.9863\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2290 - acc: 0.9388 - auROC: 0.9762 - val_loss: 0.2121 - val_acc: 0.9483 - val_auROC: 0.9863\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2290 - acc: 0.9388 - auROC: 0.9763 - val_loss: 0.2121 - val_acc: 0.9483 - val_auROC: 0.9861\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2289 - acc: 0.9388 - auROC: 0.9763 - val_loss: 0.2119 - val_acc: 0.9483 - val_auROC: 0.9864\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2288 - acc: 0.9384 - auROC: 0.9762 - val_loss: 0.2114 - val_acc: 0.9517 - val_auROC: 0.9865\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2288 - acc: 0.9384 - auROC: 0.9762 - val_loss: 0.2113 - val_acc: 0.9517 - val_auROC: 0.9867\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2288 - acc: 0.9384 - auROC: 0.9762 - val_loss: 0.2114 - val_acc: 0.9517 - val_auROC: 0.9867\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2287 - acc: 0.9384 - auROC: 0.9762 - val_loss: 0.2114 - val_acc: 0.9517 - val_auROC: 0.9866\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2287 - acc: 0.9384 - auROC: 0.9763 - val_loss: 0.2112 - val_acc: 0.9517 - val_auROC: 0.9866\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2286 - acc: 0.9384 - auROC: 0.9763 - val_loss: 0.2113 - val_acc: 0.9517 - val_auROC: 0.9866\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2285 - acc: 0.9384 - auROC: 0.9763 - val_loss: 0.2113 - val_acc: 0.9517 - val_auROC: 0.9866\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2285 - acc: 0.9384 - auROC: 0.9763 - val_loss: 0.2113 - val_acc: 0.9517 - val_auROC: 0.9864\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2284 - acc: 0.9384 - auROC: 0.9764 - val_loss: 0.2112 - val_acc: 0.9517 - val_auROC: 0.9865\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2284 - acc: 0.9384 - auROC: 0.9764 - val_loss: 0.2111 - val_acc: 0.9517 - val_auROC: 0.9866\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2283 - acc: 0.9384 - auROC: 0.9765 - val_loss: 0.2112 - val_acc: 0.9517 - val_auROC: 0.9868\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2283 - acc: 0.9384 - auROC: 0.9765 - val_loss: 0.2122 - val_acc: 0.9483 - val_auROC: 0.9860\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2287 - acc: 0.9380 - auROC: 0.9764 - val_loss: 0.2124 - val_acc: 0.9483 - val_auROC: 0.9858\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2286 - acc: 0.9380 - auROC: 0.9762 - val_loss: 0.2120 - val_acc: 0.9517 - val_auROC: 0.9860\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2284 - acc: 0.9380 - auROC: 0.9762 - val_loss: 0.2116 - val_acc: 0.9517 - val_auROC: 0.9862\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2282 - acc: 0.9380 - auROC: 0.9763 - val_loss: 0.2112 - val_acc: 0.9517 - val_auROC: 0.9869\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2281 - acc: 0.9380 - auROC: 0.9764 - val_loss: 0.2110 - val_acc: 0.9517 - val_auROC: 0.9868\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2280 - acc: 0.9380 - auROC: 0.9764 - val_loss: 0.2109 - val_acc: 0.9517 - val_auROC: 0.9869\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2279 - acc: 0.9380 - auROC: 0.9764 - val_loss: 0.2108 - val_acc: 0.9517 - val_auROC: 0.9869\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2279 - acc: 0.9384 - auROC: 0.9763 - val_loss: 0.2106 - val_acc: 0.9483 - val_auROC: 0.9871\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2278 - acc: 0.9384 - auROC: 0.9763 - val_loss: 0.2105 - val_acc: 0.9483 - val_auROC: 0.9871\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2278 - acc: 0.9388 - auROC: 0.9763 - val_loss: 0.2103 - val_acc: 0.9483 - val_auROC: 0.9873\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2277 - acc: 0.9388 - auROC: 0.9764 - val_loss: 0.2102 - val_acc: 0.9483 - val_auROC: 0.9873\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2276 - acc: 0.9388 - auROC: 0.9764 - val_loss: 0.2100 - val_acc: 0.9517 - val_auROC: 0.9873\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2276 - acc: 0.9388 - auROC: 0.9764 - val_loss: 0.2098 - val_acc: 0.9517 - val_auROC: 0.9874\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2275 - acc: 0.9392 - auROC: 0.9764 - val_loss: 0.2100 - val_acc: 0.9517 - val_auROC: 0.9875\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2274 - acc: 0.9392 - auROC: 0.9764 - val_loss: 0.2101 - val_acc: 0.9483 - val_auROC: 0.9876\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2274 - acc: 0.9392 - auROC: 0.9764 - val_loss: 0.2102 - val_acc: 0.9483 - val_auROC: 0.9876\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2274 - acc: 0.9392 - auROC: 0.9764 - val_loss: 0.2102 - val_acc: 0.9483 - val_auROC: 0.9876\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2273 - acc: 0.9392 - auROC: 0.9764 - val_loss: 0.2101 - val_acc: 0.9483 - val_auROC: 0.9876\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2273 - acc: 0.9392 - auROC: 0.9764 - val_loss: 0.2101 - val_acc: 0.9483 - val_auROC: 0.9876\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2272 - acc: 0.9392 - auROC: 0.9764 - val_loss: 0.2101 - val_acc: 0.9483 - val_auROC: 0.9876\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2272 - acc: 0.9392 - auROC: 0.9764 - val_loss: 0.2100 - val_acc: 0.9483 - val_auROC: 0.9876\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2271 - acc: 0.9392 - auROC: 0.9764 - val_loss: 0.2098 - val_acc: 0.9483 - val_auROC: 0.9877\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2270 - acc: 0.9392 - auROC: 0.9764 - val_loss: 0.2097 - val_acc: 0.9483 - val_auROC: 0.9876\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2270 - acc: 0.9396 - auROC: 0.9764 - val_loss: 0.2097 - val_acc: 0.9483 - val_auROC: 0.9877\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2270 - acc: 0.9396 - auROC: 0.9765 - val_loss: 0.2096 - val_acc: 0.9483 - val_auROC: 0.9877\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2269 - acc: 0.9392 - auROC: 0.9765 - val_loss: 0.2096 - val_acc: 0.9483 - val_auROC: 0.9877\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2268 - acc: 0.9392 - auROC: 0.9765 - val_loss: 0.2096 - val_acc: 0.9483 - val_auROC: 0.9877\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2268 - acc: 0.9392 - auROC: 0.9766 - val_loss: 0.2096 - val_acc: 0.9483 - val_auROC: 0.9877\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2267 - acc: 0.9392 - auROC: 0.9766 - val_loss: 0.2092 - val_acc: 0.9483 - val_auROC: 0.9877\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2269 - acc: 0.9392 - auROC: 0.9765 - val_loss: 0.2080 - val_acc: 0.9483 - val_auROC: 0.9884\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2271 - acc: 0.9392 - auROC: 0.9766 - val_loss: 0.2079 - val_acc: 0.9517 - val_auROC: 0.9884\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2270 - acc: 0.9392 - auROC: 0.9766 - val_loss: 0.2079 - val_acc: 0.9448 - val_auROC: 0.9883\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2268 - acc: 0.9392 - auROC: 0.9768 - val_loss: 0.2080 - val_acc: 0.9448 - val_auROC: 0.9883\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2267 - acc: 0.9392 - auROC: 0.9768 - val_loss: 0.2081 - val_acc: 0.9448 - val_auROC: 0.9883\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2266 - acc: 0.9396 - auROC: 0.9768 - val_loss: 0.2083 - val_acc: 0.9448 - val_auROC: 0.9882\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2265 - acc: 0.9396 - auROC: 0.9768 - val_loss: 0.2084 - val_acc: 0.9448 - val_auROC: 0.9881\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2264 - acc: 0.9396 - auROC: 0.9769 - val_loss: 0.2086 - val_acc: 0.9448 - val_auROC: 0.9881\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2263 - acc: 0.9396 - auROC: 0.9769 - val_loss: 0.2086 - val_acc: 0.9448 - val_auROC: 0.9881\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2262 - acc: 0.9396 - auROC: 0.9769 - val_loss: 0.2087 - val_acc: 0.9448 - val_auROC: 0.9880\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2262 - acc: 0.9396 - auROC: 0.9769 - val_loss: 0.2086 - val_acc: 0.9448 - val_auROC: 0.9880\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2261 - acc: 0.9396 - auROC: 0.9769 - val_loss: 0.2086 - val_acc: 0.9448 - val_auROC: 0.9880\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2261 - acc: 0.9396 - auROC: 0.9769 - val_loss: 0.2086 - val_acc: 0.9483 - val_auROC: 0.9880\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2260 - acc: 0.9396 - auROC: 0.9769 - val_loss: 0.2086 - val_acc: 0.9483 - val_auROC: 0.9878\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2260 - acc: 0.9396 - auROC: 0.9769 - val_loss: 0.2086 - val_acc: 0.9483 - val_auROC: 0.9879\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2260 - acc: 0.9396 - auROC: 0.9769 - val_loss: 0.2085 - val_acc: 0.9483 - val_auROC: 0.9880\n",
      "Epoch 179/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.2260 - acc: 0.9395 - auROC: 0.9769Restoring model weights from the end of the best epoch.\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2259 - acc: 0.9396 - auROC: 0.9770 - val_loss: 0.2084 - val_acc: 0.9448 - val_auROC: 0.9880\n",
      "Epoch 00179: early stopping\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 18018)]           0         \n",
      "_________________________________________________________________\n",
      "base (Sequential)            (None, 512)               18976256  \n",
      "_________________________________________________________________\n",
      "l2_inter (Sequential)        (None, 10)                21550     \n",
      "_________________________________________________________________\n",
      "l2_integration (Sequential)  (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "l2o (Sequential)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 18,998,051\n",
      "Trainable params: 21,795\n",
      "Non-trainable params: 18,976,256\n",
      "_________________________________________________________________\n",
      "Fine-tuning using optimizer with lr=1e-05...\n",
      "Epoch 179/478\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 0.2269 - acc: 0.9384 - auROC: 0.9766 - val_loss: 0.2092 - val_acc: 0.9517 - val_auROC: 0.9873\n",
      "Epoch 180/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2255 - acc: 0.9388 - auROC: 0.9770 - val_loss: 0.2086 - val_acc: 0.9448 - val_auROC: 0.9876\n",
      "Epoch 181/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2243 - acc: 0.9392 - auROC: 0.9775 - val_loss: 0.2061 - val_acc: 0.9517 - val_auROC: 0.9886\n",
      "Epoch 182/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2234 - acc: 0.9392 - auROC: 0.9778 - val_loss: 0.2061 - val_acc: 0.9483 - val_auROC: 0.9881\n",
      "Epoch 183/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2226 - acc: 0.9392 - auROC: 0.9782 - val_loss: 0.2053 - val_acc: 0.9517 - val_auROC: 0.9887\n",
      "Epoch 184/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2217 - acc: 0.9400 - auROC: 0.9784 - val_loss: 0.2047 - val_acc: 0.9517 - val_auROC: 0.9889\n",
      "Epoch 185/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2210 - acc: 0.9404 - auROC: 0.9788 - val_loss: 0.2039 - val_acc: 0.9517 - val_auROC: 0.9890\n",
      "Epoch 186/478\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2204 - acc: 0.9411 - auROC: 0.9790 - val_loss: 0.2033 - val_acc: 0.9552 - val_auROC: 0.9892\n",
      "Epoch 187/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2199 - acc: 0.9407 - auROC: 0.9791 - val_loss: 0.2032 - val_acc: 0.9552 - val_auROC: 0.9890\n",
      "Epoch 188/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2191 - acc: 0.9407 - auROC: 0.9794 - val_loss: 0.2026 - val_acc: 0.9517 - val_auROC: 0.9890\n",
      "Epoch 189/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2186 - acc: 0.9415 - auROC: 0.9795 - val_loss: 0.2026 - val_acc: 0.9517 - val_auROC: 0.9894\n",
      "Epoch 190/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2180 - acc: 0.9427 - auROC: 0.9797 - val_loss: 0.2020 - val_acc: 0.9552 - val_auROC: 0.9895\n",
      "Epoch 191/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2175 - acc: 0.9427 - auROC: 0.9799 - val_loss: 0.2015 - val_acc: 0.9552 - val_auROC: 0.9895\n",
      "Epoch 192/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2170 - acc: 0.9427 - auROC: 0.9800 - val_loss: 0.2012 - val_acc: 0.9517 - val_auROC: 0.9895\n",
      "Epoch 193/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2165 - acc: 0.9431 - auROC: 0.9802 - val_loss: 0.2013 - val_acc: 0.9517 - val_auROC: 0.9896\n",
      "Epoch 194/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2166 - acc: 0.9423 - auROC: 0.9802 - val_loss: 0.2053 - val_acc: 0.9517 - val_auROC: 0.9871\n",
      "Epoch 195/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2167 - acc: 0.9419 - auROC: 0.9801 - val_loss: 0.2033 - val_acc: 0.9517 - val_auROC: 0.9881\n",
      "Epoch 196/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2154 - acc: 0.9423 - auROC: 0.9808 - val_loss: 0.2010 - val_acc: 0.9517 - val_auROC: 0.9891\n",
      "Epoch 197/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2146 - acc: 0.9435 - auROC: 0.9809 - val_loss: 0.1996 - val_acc: 0.9552 - val_auROC: 0.9897\n",
      "Epoch 198/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2142 - acc: 0.9439 - auROC: 0.9811 - val_loss: 0.1986 - val_acc: 0.9586 - val_auROC: 0.9899\n",
      "Epoch 199/478\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2138 - acc: 0.9446 - auROC: 0.9812 - val_loss: 0.1981 - val_acc: 0.9586 - val_auROC: 0.9900\n",
      "Epoch 200/478\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2134 - acc: 0.9450 - auROC: 0.9814 - val_loss: 0.1975 - val_acc: 0.9586 - val_auROC: 0.9902\n",
      "Epoch 201/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2131 - acc: 0.9454 - auROC: 0.9814 - val_loss: 0.1971 - val_acc: 0.9586 - val_auROC: 0.9903\n",
      "Epoch 202/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2128 - acc: 0.9454 - auROC: 0.9814 - val_loss: 0.1967 - val_acc: 0.9621 - val_auROC: 0.9903\n",
      "Epoch 203/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2126 - acc: 0.9458 - auROC: 0.9815 - val_loss: 0.1962 - val_acc: 0.9621 - val_auROC: 0.9905\n",
      "Epoch 204/478\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2123 - acc: 0.9458 - auROC: 0.9816 - val_loss: 0.1959 - val_acc: 0.9621 - val_auROC: 0.9905\n",
      "Epoch 205/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2121 - acc: 0.9458 - auROC: 0.9816 - val_loss: 0.1957 - val_acc: 0.9621 - val_auROC: 0.9906\n",
      "Epoch 206/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2119 - acc: 0.9462 - auROC: 0.9816 - val_loss: 0.1954 - val_acc: 0.9621 - val_auROC: 0.9906\n",
      "Epoch 207/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2117 - acc: 0.9462 - auROC: 0.9817 - val_loss: 0.1951 - val_acc: 0.9621 - val_auROC: 0.9906\n",
      "Epoch 208/478\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2115 - acc: 0.9462 - auROC: 0.9818 - val_loss: 0.1949 - val_acc: 0.9621 - val_auROC: 0.9906\n",
      "Epoch 209/478\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2114 - acc: 0.9462 - auROC: 0.9818 - val_loss: 0.1951 - val_acc: 0.9621 - val_auROC: 0.9905\n",
      "Epoch 210/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2112 - acc: 0.9462 - auROC: 0.9818 - val_loss: 0.1944 - val_acc: 0.9621 - val_auROC: 0.9905\n",
      "Epoch 211/478\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2109 - acc: 0.9462 - auROC: 0.9819 - val_loss: 0.1940 - val_acc: 0.9621 - val_auROC: 0.9907\n",
      "Epoch 212/478\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2106 - acc: 0.9466 - auROC: 0.9818 - val_loss: 0.1939 - val_acc: 0.9621 - val_auROC: 0.9910\n",
      "Epoch 213/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2104 - acc: 0.9466 - auROC: 0.9819 - val_loss: 0.1937 - val_acc: 0.9621 - val_auROC: 0.9909\n",
      "Epoch 214/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2101 - acc: 0.9466 - auROC: 0.9819 - val_loss: 0.1935 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 215/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2099 - acc: 0.9466 - auROC: 0.9821 - val_loss: 0.1934 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 216/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2095 - acc: 0.9466 - auROC: 0.9826 - val_loss: 0.1932 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 217/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2093 - acc: 0.9462 - auROC: 0.9829 - val_loss: 0.1931 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 218/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2089 - acc: 0.9466 - auROC: 0.9831 - val_loss: 0.1929 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 219/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2086 - acc: 0.9466 - auROC: 0.9833 - val_loss: 0.1929 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 220/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2082 - acc: 0.9466 - auROC: 0.9836 - val_loss: 0.1927 - val_acc: 0.9552 - val_auROC: 0.9910\n",
      "Epoch 221/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2081 - acc: 0.9462 - auROC: 0.9836 - val_loss: 0.1929 - val_acc: 0.9552 - val_auROC: 0.9908\n",
      "Epoch 222/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2079 - acc: 0.9466 - auROC: 0.9838 - val_loss: 0.1924 - val_acc: 0.9552 - val_auROC: 0.9910\n",
      "Epoch 223/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2076 - acc: 0.9466 - auROC: 0.9838 - val_loss: 0.1922 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 224/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2074 - acc: 0.9470 - auROC: 0.9840 - val_loss: 0.1919 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 225/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2074 - acc: 0.9470 - auROC: 0.9841 - val_loss: 0.1916 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 226/478\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2071 - acc: 0.9470 - auROC: 0.9841 - val_loss: 0.1916 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 227/478\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2068 - acc: 0.9474 - auROC: 0.9842 - val_loss: 0.1916 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 228/478\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2066 - acc: 0.9474 - auROC: 0.9842 - val_loss: 0.1913 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 229/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2064 - acc: 0.9478 - auROC: 0.9843 - val_loss: 0.1912 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 230/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2062 - acc: 0.9478 - auROC: 0.9843 - val_loss: 0.1910 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 231/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2060 - acc: 0.9478 - auROC: 0.9844 - val_loss: 0.1907 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 232/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2058 - acc: 0.9478 - auROC: 0.9844 - val_loss: 0.1905 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 233/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2056 - acc: 0.9478 - auROC: 0.9844 - val_loss: 0.1903 - val_acc: 0.9586 - val_auROC: 0.9913\n",
      "Epoch 234/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2054 - acc: 0.9478 - auROC: 0.9843 - val_loss: 0.1901 - val_acc: 0.9586 - val_auROC: 0.9913\n",
      "Epoch 235/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2053 - acc: 0.9478 - auROC: 0.9844 - val_loss: 0.1900 - val_acc: 0.9586 - val_auROC: 0.9912\n",
      "Epoch 236/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2051 - acc: 0.9478 - auROC: 0.9844 - val_loss: 0.1900 - val_acc: 0.9552 - val_auROC: 0.9911\n",
      "Epoch 237/478\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2052 - acc: 0.9478 - auROC: 0.9843 - val_loss: 0.1907 - val_acc: 0.9552 - val_auROC: 0.9909\n",
      "Epoch 238/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2053 - acc: 0.9481 - auROC: 0.9842 - val_loss: 0.1900 - val_acc: 0.9552 - val_auROC: 0.9912\n",
      "Epoch 239/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2052 - acc: 0.9478 - auROC: 0.9845 - val_loss: 0.1943 - val_acc: 0.9552 - val_auROC: 0.9901\n",
      "Epoch 240/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2057 - acc: 0.9481 - auROC: 0.9844 - val_loss: 0.1952 - val_acc: 0.9552 - val_auROC: 0.9896\n",
      "Epoch 241/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2055 - acc: 0.9481 - auROC: 0.9844 - val_loss: 0.1949 - val_acc: 0.9552 - val_auROC: 0.9897\n",
      "Epoch 242/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2050 - acc: 0.9481 - auROC: 0.9845 - val_loss: 0.1942 - val_acc: 0.9552 - val_auROC: 0.9897\n",
      "Epoch 243/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2047 - acc: 0.9481 - auROC: 0.9843 - val_loss: 0.1933 - val_acc: 0.9552 - val_auROC: 0.9903\n",
      "Epoch 244/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2044 - acc: 0.9481 - auROC: 0.9843 - val_loss: 0.1924 - val_acc: 0.9552 - val_auROC: 0.9906\n",
      "Epoch 245/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2042 - acc: 0.9481 - auROC: 0.9843 - val_loss: 0.1915 - val_acc: 0.9552 - val_auROC: 0.9908\n",
      "Epoch 246/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2040 - acc: 0.9481 - auROC: 0.9844 - val_loss: 0.1904 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 247/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2038 - acc: 0.9481 - auROC: 0.9845 - val_loss: 0.1896 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 248/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2036 - acc: 0.9481 - auROC: 0.9845 - val_loss: 0.1891 - val_acc: 0.9586 - val_auROC: 0.9912\n",
      "Epoch 249/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2034 - acc: 0.9481 - auROC: 0.9846 - val_loss: 0.1887 - val_acc: 0.9586 - val_auROC: 0.9913\n",
      "Epoch 250/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2034 - acc: 0.9485 - auROC: 0.9846 - val_loss: 0.1901 - val_acc: 0.9586 - val_auROC: 0.9912\n",
      "Epoch 251/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2038 - acc: 0.9485 - auROC: 0.9844 - val_loss: 0.1901 - val_acc: 0.9586 - val_auROC: 0.9912\n",
      "Epoch 252/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2035 - acc: 0.9485 - auROC: 0.9846 - val_loss: 0.1895 - val_acc: 0.9586 - val_auROC: 0.9914\n",
      "Epoch 253/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2032 - acc: 0.9485 - auROC: 0.9846 - val_loss: 0.1892 - val_acc: 0.9586 - val_auROC: 0.9914\n",
      "Epoch 254/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2030 - acc: 0.9485 - auROC: 0.9846 - val_loss: 0.1889 - val_acc: 0.9586 - val_auROC: 0.9915\n",
      "Epoch 255/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2028 - acc: 0.9485 - auROC: 0.9847 - val_loss: 0.1886 - val_acc: 0.9586 - val_auROC: 0.9915\n",
      "Epoch 256/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2027 - acc: 0.9485 - auROC: 0.9847 - val_loss: 0.1884 - val_acc: 0.9586 - val_auROC: 0.9915\n",
      "Epoch 257/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2027 - acc: 0.9485 - auROC: 0.9848 - val_loss: 0.1882 - val_acc: 0.9586 - val_auROC: 0.9916\n",
      "Epoch 258/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2026 - acc: 0.9485 - auROC: 0.9847 - val_loss: 0.1882 - val_acc: 0.9586 - val_auROC: 0.9916\n",
      "Epoch 259/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2024 - acc: 0.9485 - auROC: 0.9848 - val_loss: 0.1881 - val_acc: 0.9586 - val_auROC: 0.9916\n",
      "Epoch 260/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2023 - acc: 0.9485 - auROC: 0.9848 - val_loss: 0.1879 - val_acc: 0.9586 - val_auROC: 0.9916\n",
      "Epoch 261/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2022 - acc: 0.9485 - auROC: 0.9848 - val_loss: 0.1878 - val_acc: 0.9586 - val_auROC: 0.9915\n",
      "Epoch 262/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2022 - acc: 0.9485 - auROC: 0.9848 - val_loss: 0.1880 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 263/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2018 - acc: 0.9485 - auROC: 0.9848 - val_loss: 0.1886 - val_acc: 0.9586 - val_auROC: 0.9904\n",
      "Epoch 264/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2014 - acc: 0.9489 - auROC: 0.9850 - val_loss: 0.1889 - val_acc: 0.9586 - val_auROC: 0.9902\n",
      "Epoch 265/478\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2012 - acc: 0.9489 - auROC: 0.9850 - val_loss: 0.1891 - val_acc: 0.9586 - val_auROC: 0.9902\n",
      "Epoch 266/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2009 - acc: 0.9493 - auROC: 0.9852 - val_loss: 0.1894 - val_acc: 0.9586 - val_auROC: 0.9897\n",
      "Epoch 267/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2008 - acc: 0.9493 - auROC: 0.9852 - val_loss: 0.1892 - val_acc: 0.9586 - val_auROC: 0.9897\n",
      "Epoch 268/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2006 - acc: 0.9493 - auROC: 0.9852 - val_loss: 0.1886 - val_acc: 0.9586 - val_auROC: 0.9902\n",
      "Epoch 269/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2004 - acc: 0.9493 - auROC: 0.9853 - val_loss: 0.1882 - val_acc: 0.9586 - val_auROC: 0.9904\n",
      "Epoch 270/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2001 - acc: 0.9497 - auROC: 0.9853 - val_loss: 0.1879 - val_acc: 0.9586 - val_auROC: 0.9906\n",
      "Epoch 271/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1999 - acc: 0.9505 - auROC: 0.9854 - val_loss: 0.1878 - val_acc: 0.9586 - val_auROC: 0.9906\n",
      "Epoch 272/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1995 - acc: 0.9509 - auROC: 0.9854 - val_loss: 0.1879 - val_acc: 0.9586 - val_auROC: 0.9906\n",
      "Epoch 273/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1992 - acc: 0.9509 - auROC: 0.9856 - val_loss: 0.1879 - val_acc: 0.9552 - val_auROC: 0.9906\n",
      "Epoch 274/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1989 - acc: 0.9509 - auROC: 0.9857 - val_loss: 0.1877 - val_acc: 0.9552 - val_auROC: 0.9906\n",
      "Epoch 275/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1988 - acc: 0.9509 - auROC: 0.9857 - val_loss: 0.1876 - val_acc: 0.9586 - val_auROC: 0.9907\n",
      "Epoch 276/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1987 - acc: 0.9509 - auROC: 0.9857 - val_loss: 0.1874 - val_acc: 0.9586 - val_auROC: 0.9907\n",
      "Epoch 277/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1986 - acc: 0.9509 - auROC: 0.9858 - val_loss: 0.1873 - val_acc: 0.9586 - val_auROC: 0.9907\n",
      "Epoch 278/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1985 - acc: 0.9509 - auROC: 0.9858 - val_loss: 0.1873 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 279/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1984 - acc: 0.9509 - auROC: 0.9858 - val_loss: 0.1874 - val_acc: 0.9586 - val_auROC: 0.9906\n",
      "Epoch 280/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1983 - acc: 0.9509 - auROC: 0.9858 - val_loss: 0.1871 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 281/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1983 - acc: 0.9509 - auROC: 0.9858 - val_loss: 0.1870 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 282/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1984 - acc: 0.9509 - auROC: 0.9858 - val_loss: 0.1866 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 283/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1983 - acc: 0.9509 - auROC: 0.9858 - val_loss: 0.1864 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 284/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1981 - acc: 0.9509 - auROC: 0.9859 - val_loss: 0.1863 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 285/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1980 - acc: 0.9509 - auROC: 0.9859 - val_loss: 0.1864 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 286/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1979 - acc: 0.9509 - auROC: 0.9859 - val_loss: 0.1863 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 287/478\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1979 - acc: 0.9509 - auROC: 0.9859 - val_loss: 0.1863 - val_acc: 0.9586 - val_auROC: 0.9913\n",
      "Epoch 288/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1978 - acc: 0.9509 - auROC: 0.9858 - val_loss: 0.1861 - val_acc: 0.9586 - val_auROC: 0.9912\n",
      "Epoch 289/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1977 - acc: 0.9509 - auROC: 0.9859 - val_loss: 0.1861 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 290/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1976 - acc: 0.9509 - auROC: 0.9860 - val_loss: 0.1862 - val_acc: 0.9586 - val_auROC: 0.9908\n",
      "Epoch 291/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1975 - acc: 0.9509 - auROC: 0.9860 - val_loss: 0.1863 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 292/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1974 - acc: 0.9509 - auROC: 0.9859 - val_loss: 0.1862 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 293/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1973 - acc: 0.9509 - auROC: 0.9860 - val_loss: 0.1860 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 294/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1972 - acc: 0.9509 - auROC: 0.9860 - val_loss: 0.1859 - val_acc: 0.9586 - val_auROC: 0.9906\n",
      "Epoch 295/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1973 - acc: 0.9509 - auROC: 0.9860 - val_loss: 0.1860 - val_acc: 0.9586 - val_auROC: 0.9907\n",
      "Epoch 296/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1974 - acc: 0.9509 - auROC: 0.9860 - val_loss: 0.1856 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 297/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1971 - acc: 0.9513 - auROC: 0.9861 - val_loss: 0.1855 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 298/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1970 - acc: 0.9513 - auROC: 0.9862 - val_loss: 0.1857 - val_acc: 0.9586 - val_auROC: 0.9910\n",
      "Epoch 299/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1968 - acc: 0.9513 - auROC: 0.9861 - val_loss: 0.1856 - val_acc: 0.9586 - val_auROC: 0.9909\n",
      "Epoch 300/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1967 - acc: 0.9513 - auROC: 0.9862 - val_loss: 0.1854 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 301/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1985 - acc: 0.9497 - auROC: 0.9857 - val_loss: 0.1900 - val_acc: 0.9586 - val_auROC: 0.9887\n",
      "Epoch 302/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1974 - acc: 0.9513 - auROC: 0.9859 - val_loss: 0.1869 - val_acc: 0.9586 - val_auROC: 0.9902\n",
      "Epoch 303/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1959 - acc: 0.9524 - auROC: 0.9863 - val_loss: 0.1861 - val_acc: 0.9621 - val_auROC: 0.9905\n",
      "Epoch 304/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1956 - acc: 0.9536 - auROC: 0.9864 - val_loss: 0.1853 - val_acc: 0.9621 - val_auROC: 0.9910\n",
      "Epoch 305/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1952 - acc: 0.9536 - auROC: 0.9865 - val_loss: 0.1849 - val_acc: 0.9586 - val_auROC: 0.9913\n",
      "Epoch 306/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1949 - acc: 0.9540 - auROC: 0.9865 - val_loss: 0.1849 - val_acc: 0.9586 - val_auROC: 0.9916\n",
      "Epoch 307/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1948 - acc: 0.9540 - auROC: 0.9866 - val_loss: 0.1849 - val_acc: 0.9586 - val_auROC: 0.9915\n",
      "Epoch 308/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1947 - acc: 0.9540 - auROC: 0.9866 - val_loss: 0.1847 - val_acc: 0.9586 - val_auROC: 0.9916\n",
      "Epoch 309/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1946 - acc: 0.9540 - auROC: 0.9866 - val_loss: 0.1846 - val_acc: 0.9586 - val_auROC: 0.9919\n",
      "Epoch 310/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1945 - acc: 0.9540 - auROC: 0.9866 - val_loss: 0.1845 - val_acc: 0.9586 - val_auROC: 0.9916\n",
      "Epoch 311/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1944 - acc: 0.9540 - auROC: 0.9866 - val_loss: 0.1844 - val_acc: 0.9586 - val_auROC: 0.9918\n",
      "Epoch 312/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1943 - acc: 0.9540 - auROC: 0.9867 - val_loss: 0.1843 - val_acc: 0.9586 - val_auROC: 0.9919\n",
      "Epoch 313/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1943 - acc: 0.9540 - auROC: 0.9867 - val_loss: 0.1841 - val_acc: 0.9586 - val_auROC: 0.9919\n",
      "Epoch 314/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1942 - acc: 0.9540 - auROC: 0.9867 - val_loss: 0.1839 - val_acc: 0.9586 - val_auROC: 0.9921\n",
      "Epoch 315/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1940 - acc: 0.9540 - auROC: 0.9867 - val_loss: 0.1836 - val_acc: 0.9586 - val_auROC: 0.9920\n",
      "Epoch 316/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1939 - acc: 0.9540 - auROC: 0.9868 - val_loss: 0.1833 - val_acc: 0.9586 - val_auROC: 0.9918\n",
      "Epoch 317/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1938 - acc: 0.9540 - auROC: 0.9868 - val_loss: 0.1829 - val_acc: 0.9586 - val_auROC: 0.9917\n",
      "Epoch 318/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1936 - acc: 0.9544 - auROC: 0.9868 - val_loss: 0.1826 - val_acc: 0.9586 - val_auROC: 0.9918\n",
      "Epoch 319/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1934 - acc: 0.9548 - auROC: 0.9868 - val_loss: 0.1823 - val_acc: 0.9586 - val_auROC: 0.9919\n",
      "Epoch 320/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1932 - acc: 0.9548 - auROC: 0.9869 - val_loss: 0.1820 - val_acc: 0.9621 - val_auROC: 0.9921\n",
      "Epoch 321/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1930 - acc: 0.9556 - auROC: 0.9869 - val_loss: 0.1819 - val_acc: 0.9621 - val_auROC: 0.9920\n",
      "Epoch 322/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1929 - acc: 0.9556 - auROC: 0.9869 - val_loss: 0.1819 - val_acc: 0.9621 - val_auROC: 0.9919\n",
      "Epoch 323/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1928 - acc: 0.9556 - auROC: 0.9869 - val_loss: 0.1817 - val_acc: 0.9621 - val_auROC: 0.9920\n",
      "Epoch 324/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1927 - acc: 0.9556 - auROC: 0.9869 - val_loss: 0.1817 - val_acc: 0.9621 - val_auROC: 0.9921\n",
      "Epoch 325/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1926 - acc: 0.9552 - auROC: 0.9869 - val_loss: 0.1841 - val_acc: 0.9586 - val_auROC: 0.9911\n",
      "Epoch 326/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1926 - acc: 0.9548 - auROC: 0.9868 - val_loss: 0.1833 - val_acc: 0.9586 - val_auROC: 0.9916\n",
      "Epoch 327/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1923 - acc: 0.9552 - auROC: 0.9869 - val_loss: 0.1824 - val_acc: 0.9586 - val_auROC: 0.9922\n",
      "Epoch 328/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1921 - acc: 0.9556 - auROC: 0.9870 - val_loss: 0.1817 - val_acc: 0.9621 - val_auROC: 0.9923\n",
      "Epoch 329/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1920 - acc: 0.9556 - auROC: 0.9870 - val_loss: 0.1816 - val_acc: 0.9621 - val_auROC: 0.9925\n",
      "Epoch 330/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1920 - acc: 0.9556 - auROC: 0.9870 - val_loss: 0.1819 - val_acc: 0.9621 - val_auROC: 0.9923\n",
      "Epoch 331/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1919 - acc: 0.9556 - auROC: 0.9870 - val_loss: 0.1817 - val_acc: 0.9621 - val_auROC: 0.9923\n",
      "Epoch 332/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1918 - acc: 0.9556 - auROC: 0.9870 - val_loss: 0.1812 - val_acc: 0.9621 - val_auROC: 0.9925\n",
      "Epoch 333/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1917 - acc: 0.9556 - auROC: 0.9870 - val_loss: 0.1810 - val_acc: 0.9621 - val_auROC: 0.9926\n",
      "Epoch 334/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1916 - acc: 0.9556 - auROC: 0.9871 - val_loss: 0.1807 - val_acc: 0.9621 - val_auROC: 0.9926\n",
      "Epoch 335/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1915 - acc: 0.9556 - auROC: 0.9871 - val_loss: 0.1806 - val_acc: 0.9621 - val_auROC: 0.9925\n",
      "Epoch 336/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1915 - acc: 0.9556 - auROC: 0.9871 - val_loss: 0.1811 - val_acc: 0.9586 - val_auROC: 0.9924\n",
      "Epoch 337/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1915 - acc: 0.9556 - auROC: 0.9870 - val_loss: 0.1808 - val_acc: 0.9586 - val_auROC: 0.9925\n",
      "Epoch 338/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1913 - acc: 0.9556 - auROC: 0.9870 - val_loss: 0.1805 - val_acc: 0.9621 - val_auROC: 0.9926\n",
      "Epoch 339/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1912 - acc: 0.9556 - auROC: 0.9871 - val_loss: 0.1804 - val_acc: 0.9621 - val_auROC: 0.9928\n",
      "Epoch 340/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1912 - acc: 0.9556 - auROC: 0.9871 - val_loss: 0.1803 - val_acc: 0.9621 - val_auROC: 0.9926\n",
      "Epoch 341/478\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1911 - acc: 0.9556 - auROC: 0.9871 - val_loss: 0.1802 - val_acc: 0.9621 - val_auROC: 0.9926\n",
      "Epoch 342/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1910 - acc: 0.9556 - auROC: 0.9871 - val_loss: 0.1801 - val_acc: 0.9621 - val_auROC: 0.9928\n",
      "Epoch 343/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1910 - acc: 0.9556 - auROC: 0.9871 - val_loss: 0.1800 - val_acc: 0.9621 - val_auROC: 0.9928\n",
      "Epoch 344/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1909 - acc: 0.9556 - auROC: 0.9871 - val_loss: 0.1798 - val_acc: 0.9621 - val_auROC: 0.9928\n",
      "Epoch 345/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1908 - acc: 0.9556 - auROC: 0.9872 - val_loss: 0.1798 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 346/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1908 - acc: 0.9556 - auROC: 0.9872 - val_loss: 0.1797 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 347/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1907 - acc: 0.9556 - auROC: 0.9872 - val_loss: 0.1796 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 348/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1906 - acc: 0.9563 - auROC: 0.9871 - val_loss: 0.1795 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 349/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1906 - acc: 0.9563 - auROC: 0.9871 - val_loss: 0.1793 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 350/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1905 - acc: 0.9563 - auROC: 0.9870 - val_loss: 0.1794 - val_acc: 0.9655 - val_auROC: 0.9925\n",
      "Epoch 351/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1905 - acc: 0.9563 - auROC: 0.9870 - val_loss: 0.1793 - val_acc: 0.9655 - val_auROC: 0.9925\n",
      "Epoch 352/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1904 - acc: 0.9563 - auROC: 0.9870 - val_loss: 0.1793 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 353/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1901 - acc: 0.9567 - auROC: 0.9872 - val_loss: 0.1793 - val_acc: 0.9655 - val_auROC: 0.9930\n",
      "Epoch 354/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1900 - acc: 0.9567 - auROC: 0.9872 - val_loss: 0.1794 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 355/478\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1899 - acc: 0.9567 - auROC: 0.9872 - val_loss: 0.1794 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 356/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1899 - acc: 0.9567 - auROC: 0.9872 - val_loss: 0.1793 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 357/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1898 - acc: 0.9567 - auROC: 0.9873 - val_loss: 0.1792 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 358/478\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1898 - acc: 0.9567 - auROC: 0.9873 - val_loss: 0.1792 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 359/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1898 - acc: 0.9567 - auROC: 0.9872 - val_loss: 0.1798 - val_acc: 0.9621 - val_auROC: 0.9928\n",
      "Epoch 360/478\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1898 - acc: 0.9567 - auROC: 0.9872 - val_loss: 0.1795 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 361/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1897 - acc: 0.9567 - auROC: 0.9872 - val_loss: 0.1791 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 362/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1896 - acc: 0.9567 - auROC: 0.9873 - val_loss: 0.1789 - val_acc: 0.9655 - val_auROC: 0.9930\n",
      "Epoch 363/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1895 - acc: 0.9567 - auROC: 0.9873 - val_loss: 0.1789 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 364/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1895 - acc: 0.9567 - auROC: 0.9873 - val_loss: 0.1789 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 365/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1894 - acc: 0.9567 - auROC: 0.9873 - val_loss: 0.1789 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 366/478\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.1894 - acc: 0.9567 - auROC: 0.9873 - val_loss: 0.1790 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 367/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1893 - acc: 0.9567 - auROC: 0.9873 - val_loss: 0.1789 - val_acc: 0.9655 - val_auROC: 0.9927\n",
      "Epoch 368/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1893 - acc: 0.9567 - auROC: 0.9874 - val_loss: 0.1788 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 369/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1892 - acc: 0.9571 - auROC: 0.9874 - val_loss: 0.1787 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 370/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1891 - acc: 0.9571 - auROC: 0.9873 - val_loss: 0.1788 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 371/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1890 - acc: 0.9571 - auROC: 0.9873 - val_loss: 0.1787 - val_acc: 0.9655 - val_auROC: 0.9931\n",
      "Epoch 372/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1889 - acc: 0.9571 - auROC: 0.9874 - val_loss: 0.1787 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 373/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1889 - acc: 0.9571 - auROC: 0.9874 - val_loss: 0.1787 - val_acc: 0.9655 - val_auROC: 0.9927\n",
      "Epoch 374/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1889 - acc: 0.9571 - auROC: 0.9875 - val_loss: 0.1793 - val_acc: 0.9621 - val_auROC: 0.9927\n",
      "Epoch 375/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1889 - acc: 0.9575 - auROC: 0.9875 - val_loss: 0.1794 - val_acc: 0.9621 - val_auROC: 0.9930\n",
      "Epoch 376/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1890 - acc: 0.9575 - auROC: 0.9874 - val_loss: 0.1797 - val_acc: 0.9621 - val_auROC: 0.9923\n",
      "Epoch 377/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1888 - acc: 0.9575 - auROC: 0.9874 - val_loss: 0.1786 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 378/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1886 - acc: 0.9575 - auROC: 0.9874 - val_loss: 0.1782 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 379/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1886 - acc: 0.9575 - auROC: 0.9874 - val_loss: 0.1783 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 380/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1885 - acc: 0.9575 - auROC: 0.9874 - val_loss: 0.1783 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 381/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1883 - acc: 0.9575 - auROC: 0.9875 - val_loss: 0.1783 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 382/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1882 - acc: 0.9575 - auROC: 0.9875 - val_loss: 0.1782 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 383/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1881 - acc: 0.9575 - auROC: 0.9875 - val_loss: 0.1782 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 384/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1881 - acc: 0.9575 - auROC: 0.9875 - val_loss: 0.1782 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 385/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1880 - acc: 0.9575 - auROC: 0.9875 - val_loss: 0.1781 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 386/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1879 - acc: 0.9575 - auROC: 0.9875 - val_loss: 0.1780 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 387/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1879 - acc: 0.9575 - auROC: 0.9875 - val_loss: 0.1779 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 388/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1878 - acc: 0.9575 - auROC: 0.9875 - val_loss: 0.1778 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 389/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1878 - acc: 0.9575 - auROC: 0.9875 - val_loss: 0.1777 - val_acc: 0.9655 - val_auROC: 0.9928\n",
      "Epoch 390/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1877 - acc: 0.9579 - auROC: 0.9875 - val_loss: 0.1776 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 391/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1877 - acc: 0.9579 - auROC: 0.9875 - val_loss: 0.1776 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 392/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1876 - acc: 0.9579 - auROC: 0.9875 - val_loss: 0.1775 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 393/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1876 - acc: 0.9579 - auROC: 0.9876 - val_loss: 0.1775 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 394/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1875 - acc: 0.9579 - auROC: 0.9876 - val_loss: 0.1777 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 395/478\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1875 - acc: 0.9579 - auROC: 0.9876 - val_loss: 0.1776 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 396/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1874 - acc: 0.9579 - auROC: 0.9876 - val_loss: 0.1775 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 397/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1873 - acc: 0.9579 - auROC: 0.9876 - val_loss: 0.1774 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 398/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1873 - acc: 0.9579 - auROC: 0.9876 - val_loss: 0.1773 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 399/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1872 - acc: 0.9579 - auROC: 0.9876 - val_loss: 0.1772 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 400/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1872 - acc: 0.9579 - auROC: 0.9877 - val_loss: 0.1772 - val_acc: 0.9655 - val_auROC: 0.9931\n",
      "Epoch 401/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1872 - acc: 0.9579 - auROC: 0.9876 - val_loss: 0.1771 - val_acc: 0.9655 - val_auROC: 0.9931\n",
      "Epoch 402/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1871 - acc: 0.9579 - auROC: 0.9877 - val_loss: 0.1770 - val_acc: 0.9655 - val_auROC: 0.9931\n",
      "Epoch 403/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1870 - acc: 0.9579 - auROC: 0.9876 - val_loss: 0.1769 - val_acc: 0.9655 - val_auROC: 0.9930\n",
      "Epoch 404/478\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.1871 - acc: 0.9579 - auROC: 0.9875 - val_loss: 0.1772 - val_acc: 0.9655 - val_auROC: 0.9925\n",
      "Epoch 405/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1871 - acc: 0.9579 - auROC: 0.9874 - val_loss: 0.1771 - val_acc: 0.9655 - val_auROC: 0.9927\n",
      "Epoch 406/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1870 - acc: 0.9579 - auROC: 0.9876 - val_loss: 0.1771 - val_acc: 0.9655 - val_auROC: 0.9930\n",
      "Epoch 407/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1869 - acc: 0.9579 - auROC: 0.9877 - val_loss: 0.1767 - val_acc: 0.9655 - val_auROC: 0.9931\n",
      "Epoch 408/478\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.1871 - acc: 0.9575 - auROC: 0.9876 - val_loss: 0.1775 - val_acc: 0.9621 - val_auROC: 0.9928\n",
      "Epoch 409/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1876 - acc: 0.9575 - auROC: 0.9874 - val_loss: 0.1776 - val_acc: 0.9655 - val_auROC: 0.9926\n",
      "Epoch 410/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1872 - acc: 0.9579 - auROC: 0.9875 - val_loss: 0.1771 - val_acc: 0.9690 - val_auROC: 0.9929\n",
      "Epoch 411/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1867 - acc: 0.9583 - auROC: 0.9876 - val_loss: 0.1770 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 412/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1865 - acc: 0.9583 - auROC: 0.9876 - val_loss: 0.1769 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 413/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1864 - acc: 0.9583 - auROC: 0.9877 - val_loss: 0.1769 - val_acc: 0.9690 - val_auROC: 0.9929\n",
      "Epoch 414/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1862 - acc: 0.9587 - auROC: 0.9876 - val_loss: 0.1768 - val_acc: 0.9690 - val_auROC: 0.9929\n",
      "Epoch 415/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1860 - acc: 0.9587 - auROC: 0.9877 - val_loss: 0.1767 - val_acc: 0.9690 - val_auROC: 0.9931\n",
      "Epoch 416/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1859 - acc: 0.9595 - auROC: 0.9877 - val_loss: 0.1767 - val_acc: 0.9690 - val_auROC: 0.9931\n",
      "Epoch 417/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1858 - acc: 0.9595 - auROC: 0.9877 - val_loss: 0.1767 - val_acc: 0.9690 - val_auROC: 0.9931\n",
      "Epoch 418/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1857 - acc: 0.9595 - auROC: 0.9877 - val_loss: 0.1767 - val_acc: 0.9690 - val_auROC: 0.9931\n",
      "Epoch 419/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1856 - acc: 0.9595 - auROC: 0.9877 - val_loss: 0.1768 - val_acc: 0.9690 - val_auROC: 0.9931\n",
      "Epoch 420/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1855 - acc: 0.9595 - auROC: 0.9878 - val_loss: 0.1771 - val_acc: 0.9655 - val_auROC: 0.9930\n",
      "Epoch 421/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1853 - acc: 0.9598 - auROC: 0.9878 - val_loss: 0.1771 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 422/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1852 - acc: 0.9598 - auROC: 0.9878 - val_loss: 0.1769 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 423/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1852 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1768 - val_acc: 0.9655 - val_auROC: 0.9930\n",
      "Epoch 424/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1851 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1767 - val_acc: 0.9655 - val_auROC: 0.9929\n",
      "Epoch 425/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1850 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1766 - val_acc: 0.9655 - val_auROC: 0.9930\n",
      "Epoch 426/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1850 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1764 - val_acc: 0.9655 - val_auROC: 0.9930\n",
      "Epoch 427/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1850 - acc: 0.9598 - auROC: 0.9878 - val_loss: 0.1761 - val_acc: 0.9690 - val_auROC: 0.9930\n",
      "Epoch 428/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1851 - acc: 0.9598 - auROC: 0.9878 - val_loss: 0.1762 - val_acc: 0.9690 - val_auROC: 0.9930\n",
      "Epoch 429/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1849 - acc: 0.9598 - auROC: 0.9878 - val_loss: 0.1763 - val_acc: 0.9655 - val_auROC: 0.9931\n",
      "Epoch 430/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1848 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1766 - val_acc: 0.9655 - val_auROC: 0.9931\n",
      "Epoch 431/478\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1847 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1766 - val_acc: 0.9655 - val_auROC: 0.9931\n",
      "Epoch 432/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1847 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1765 - val_acc: 0.9655 - val_auROC: 0.9931\n",
      "Epoch 433/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1846 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1762 - val_acc: 0.9655 - val_auROC: 0.9930\n",
      "Epoch 434/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1846 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1759 - val_acc: 0.9655 - val_auROC: 0.9932\n",
      "Epoch 435/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1845 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1758 - val_acc: 0.9655 - val_auROC: 0.9932\n",
      "Epoch 436/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1845 - acc: 0.9598 - auROC: 0.9879 - val_loss: 0.1758 - val_acc: 0.9655 - val_auROC: 0.9932\n",
      "Epoch 437/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1844 - acc: 0.9598 - auROC: 0.9880 - val_loss: 0.1756 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 438/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1843 - acc: 0.9602 - auROC: 0.9879 - val_loss: 0.1750 - val_acc: 0.9690 - val_auROC: 0.9932\n",
      "Epoch 439/478\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1843 - acc: 0.9602 - auROC: 0.9880 - val_loss: 0.1751 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 440/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1842 - acc: 0.9602 - auROC: 0.9880 - val_loss: 0.1755 - val_acc: 0.9655 - val_auROC: 0.9932\n",
      "Epoch 441/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1841 - acc: 0.9602 - auROC: 0.9881 - val_loss: 0.1757 - val_acc: 0.9655 - val_auROC: 0.9931\n",
      "Epoch 442/478\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1839 - acc: 0.9602 - auROC: 0.9881 - val_loss: 0.1755 - val_acc: 0.9655 - val_auROC: 0.9932\n",
      "Epoch 443/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1838 - acc: 0.9606 - auROC: 0.9881 - val_loss: 0.1753 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 444/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1837 - acc: 0.9606 - auROC: 0.9881 - val_loss: 0.1753 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 445/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1837 - acc: 0.9606 - auROC: 0.9881 - val_loss: 0.1753 - val_acc: 0.9655 - val_auROC: 0.9932\n",
      "Epoch 446/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1835 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1752 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 447/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1834 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1751 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 448/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1834 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1749 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 449/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1833 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1748 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 450/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1833 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1748 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 451/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1833 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1747 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 452/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1832 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1748 - val_acc: 0.9655 - val_auROC: 0.9934\n",
      "Epoch 453/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1832 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1748 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 454/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1832 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1747 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 455/478\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1831 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1745 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 456/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1831 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1745 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 457/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1830 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1744 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 458/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1830 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1743 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 459/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1830 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1743 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 460/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1829 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1743 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 461/478\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1829 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1742 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 462/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1829 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1742 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 463/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1828 - acc: 0.9610 - auROC: 0.9882 - val_loss: 0.1743 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 464/478\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1828 - acc: 0.9610 - auROC: 0.9883 - val_loss: 0.1744 - val_acc: 0.9655 - val_auROC: 0.9933\n",
      "Epoch 465/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1827 - acc: 0.9610 - auROC: 0.9883 - val_loss: 0.1742 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 466/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1827 - acc: 0.9610 - auROC: 0.9883 - val_loss: 0.1740 - val_acc: 0.9690 - val_auROC: 0.9934\n",
      "Epoch 467/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1827 - acc: 0.9610 - auROC: 0.9883 - val_loss: 0.1739 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 468/478\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1826 - acc: 0.9610 - auROC: 0.9884 - val_loss: 0.1738 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 469/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1823 - acc: 0.9610 - auROC: 0.9885 - val_loss: 0.1738 - val_acc: 0.9690 - val_auROC: 0.9933\n",
      "Epoch 470/478\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1821 - acc: 0.9610 - auROC: 0.9886 - val_loss: 0.1738 - val_acc: 0.9690 - val_auROC: 0.9934\n",
      "Epoch 471/478\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1819 - acc: 0.9610 - auROC: 0.9887 - val_loss: 0.1738 - val_acc: 0.9690 - val_auROC: 0.9934\n",
      "Epoch 472/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1818 - acc: 0.9610 - auROC: 0.9887 - val_loss: 0.1738 - val_acc: 0.9690 - val_auROC: 0.9934\n",
      "Epoch 473/478\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1817 - acc: 0.9610 - auROC: 0.9887 - val_loss: 0.1737 - val_acc: 0.9690 - val_auROC: 0.9934\n",
      "Epoch 474/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1816 - acc: 0.9610 - auROC: 0.9888 - val_loss: 0.1737 - val_acc: 0.9690 - val_auROC: 0.9935\n",
      "Epoch 475/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1815 - acc: 0.9610 - auROC: 0.9888 - val_loss: 0.1736 - val_acc: 0.9690 - val_auROC: 0.9935\n",
      "Epoch 476/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1814 - acc: 0.9610 - auROC: 0.9889 - val_loss: 0.1735 - val_acc: 0.9690 - val_auROC: 0.9936\n",
      "Epoch 477/478\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1812 - acc: 0.9610 - auROC: 0.9889 - val_loss: 0.1734 - val_acc: 0.9690 - val_auROC: 0.9935\n",
      "Epoch 478/478\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.1811 - acc: 0.9610 - auROC: 0.9889 - val_loss: 0.1733 - val_acc: 0.9690 - val_auROC: 0.9935\n",
      "    0      1      2         3      ...  18014     18015     18016  18017\n",
      "0     0.0    0.0    0.0 -0.364831  ...    0.0 -0.199372 -0.197763    0.0\n",
      "1     0.0    0.0    0.0 -0.207833  ...    0.0 -0.199372 -0.197763    0.0\n",
      "2     0.0    0.0    0.0 -0.330822  ...    0.0 -0.199372 -0.197763    0.0\n",
      "3     0.0    0.0    0.0 -0.364268  ...    0.0  2.631312  2.667564    0.0\n",
      "4     0.0    0.0    0.0  1.188823  ...    0.0 -0.199372 -0.197763    0.0\n",
      "..    ...    ...    ...       ...  ...    ...       ...       ...    ...\n",
      "59    0.0    0.0    0.0 -0.265638  ...    0.0 -0.199372 -0.197763    0.0\n",
      "60    0.0    0.0    0.0 -0.364831  ...    0.0 -0.199372 -0.197763    0.0\n",
      "61    0.0    0.0    0.0 -0.364831  ...    0.0 -0.199372 -0.197763    0.0\n",
      "62    0.0    0.0    0.0 -0.364831  ...    0.0 -0.199372 -0.197763    0.0\n",
      "63    0.0    0.0    0.0 -0.364831  ...    0.0 -0.199372 -0.197763    0.0\n",
      "\n",
      "[64 rows x 18018 columns]\n",
      "Total NANs in input samples: 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "18013    0\n",
      "18014    0\n",
      "18015    0\n",
      "18016    0\n",
      "18017    0\n",
      "Length: 18018, dtype: int64\n",
      "Reordering labels and prediction result\n",
      "Reordering labels and prediction result for samples\n",
      "Running evaluation...\n",
      "Evaluating biome source: root:CRC (stage 0)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc   Pr  F1  ROC-AUC  F-max\n",
      "t                                  ...                                      \n",
      "0.00   0  62   0   0  0.0000  0.0  ...  1.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.01   1  60   0   0  0.0164  0.0  ...  0.9836  0.0  0.0 NaN      0.0    NaN\n",
      "0.02  13  48   0   0  0.2131  0.0  ...  0.7869  0.0  0.0 NaN      0.0    NaN\n",
      "0.03  26  35   0   0  0.4262  0.0  ...  0.5738  0.0  0.0 NaN      0.0    NaN\n",
      "0.04  42  19   0   0  0.6885  0.0  ...  0.3115  0.0  0.0 NaN      0.0    NaN\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...  ...  ..      ...    ...\n",
      "0.97  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.98  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.99  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "1.00  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "1.01  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage I)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                           \n",
      "0.00   0  42   0  20  0.3226  1.0  ...  1.0  1.0  0.3226  0.4878   0.9929  0.9744\n",
      "0.01   0  42   0  20  0.3226  1.0  ...  1.0  1.0  0.3226  0.4878   0.9929  0.9744\n",
      "0.02   0  42   0  20  0.3226  1.0  ...  1.0  1.0  0.3226  0.4878   0.9929  0.9744\n",
      "0.03   0  42   0  20  0.3226  1.0  ...  1.0  1.0  0.3226  0.4878   0.9929  0.9744\n",
      "0.04   0  42   0  20  0.3226  1.0  ...  1.0  1.0  0.3226  0.4878   0.9929  0.9744\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...     ...\n",
      "0.97  42   0  20   0  0.6774  0.0  ...  0.0  0.0  0.0000     NaN   0.9929  0.9744\n",
      "0.98  42   0  20   0  0.6774  0.0  ...  0.0  0.0  0.0000     NaN   0.9929  0.9744\n",
      "0.99  42   0  20   0  0.6774  0.0  ...  0.0  0.0  0.0000     NaN   0.9929  0.9744\n",
      "1.00  42   0  20   0  0.6774  0.0  ...  0.0  0.0  0.0000     NaN   0.9929  0.9744\n",
      "1.01  42   0  20   0  0.6774  0.0  ...  0.0  0.0  0.0000     NaN   0.9929  0.9744\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage II)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  48   0  14  0.2258  1.0  ...  1.0000  1.0  0.2258  0.3684   0.9755   0.88\n",
      "0.01   0  48   0  14  0.2258  1.0  ...  1.0000  1.0  0.2258  0.3684   0.9755   0.88\n",
      "0.02   0  48   0  14  0.2258  1.0  ...  1.0000  1.0  0.2258  0.3684   0.9755   0.88\n",
      "0.03   2  45   0  14  0.2623  1.0  ...  0.9574  1.0  0.2373  0.3836   0.9755   0.88\n",
      "0.04   2  45   0  13  0.2500  1.0  ...  0.9574  1.0  0.2241  0.3662   0.9755   0.88\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  48   0  14   0  0.7742  0.0  ...  0.0000  0.0  0.0000     NaN   0.9755   0.88\n",
      "0.98  48   0  14   0  0.7742  0.0  ...  0.0000  0.0  0.0000     NaN   0.9755   0.88\n",
      "0.99  48   0  14   0  0.7742  0.0  ...  0.0000  0.0  0.0000     NaN   0.9755   0.88\n",
      "1.00  48   0  14   0  0.7742  0.0  ...  0.0000  0.0  0.0000     NaN   0.9755   0.88\n",
      "1.01  48   0  14   0  0.7742  0.0  ...  0.0000  0.0  0.0000     NaN   0.9755   0.88\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage III)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765      1.0    1.0\n",
      "0.01   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765      1.0    1.0\n",
      "0.02   0  55   0   6  0.0984  1.0  ...  1.0000  1.0  0.0984  0.1791      1.0    1.0\n",
      "0.03   7  48   0   6  0.2131  1.0  ...  0.8727  1.0  0.1111  0.2000      1.0    1.0\n",
      "0.04  11  44   0   6  0.2787  1.0  ...  0.8000  1.0  0.1200  0.2143      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage IV)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                              \n",
      "0.00   0  43   0  19  0.3065  1.0  ...  1.0000  1.0  0.3065  0.4691   0.9815  0.9091\n",
      "0.01   0  42   0  19  0.3115  1.0  ...  1.0000  1.0  0.3115  0.4750   0.9815  0.9091\n",
      "0.02   0  42   0  19  0.3115  1.0  ...  1.0000  1.0  0.3115  0.4750   0.9815  0.9091\n",
      "0.03   1  41   0  19  0.3279  1.0  ...  0.9762  1.0  0.3167  0.4810   0.9815  0.9091\n",
      "0.04   6  36   0  19  0.4098  1.0  ...  0.8571  1.0  0.3455  0.5135   0.9815  0.9091\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...     ...\n",
      "0.97  43   0  19   0  0.6935  0.0  ...  0.0000  0.0  0.0000     NaN   0.9815  0.9091\n",
      "0.98  43   0  19   0  0.6935  0.0  ...  0.0000  0.0  0.0000     NaN   0.9815  0.9091\n",
      "0.99  43   0  19   0  0.6935  0.0  ...  0.0000  0.0  0.0000     NaN   0.9815  0.9091\n",
      "1.00  43   0  19   0  0.6935  0.0  ...  0.0000  0.0  0.0000     NaN   0.9815  0.9091\n",
      "1.01  43   0  19   0  0.6935  0.0  ...  0.0000  0.0  0.0000     NaN   0.9815  0.9091\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Saving evaluation results...\n",
      "Reordering labels and samples...\n",
      "Total matched samples: 571\n",
      "Total correct samples: 571?571\n",
      "           mean       std\n",
      "0      0.000000  0.000000\n",
      "1      0.000000  0.000000\n",
      "2      0.000000  0.000000\n",
      "3      0.015062  0.041284\n",
      "4      0.015041  0.041268\n",
      "...         ...       ...\n",
      "18013  0.000061  0.000243\n",
      "18014  0.000000  0.000000\n",
      "18015  0.002382  0.011947\n",
      "18016  0.002317  0.011715\n",
      "18017  0.000000  0.000000\n",
      "\n",
      "[18018 rows x 2 columns]\n",
      "Training using optimizer with lr=0.001...\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.6633 - acc: 0.6175 - auROC: 0.5070 - val_loss: 0.5981 - val_acc: 0.7000 - val_auROC: 0.5849\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.5835 - acc: 0.6947 - auROC: 0.5788 - val_loss: 0.5659 - val_acc: 0.7000 - val_auROC: 0.5898\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.5467 - acc: 0.7458 - auROC: 0.6251 - val_loss: 0.5473 - val_acc: 0.7552 - val_auROC: 0.6221\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.5213 - acc: 0.7786 - auROC: 0.6666 - val_loss: 0.5373 - val_acc: 0.7552 - val_auROC: 0.5929\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4904 - acc: 0.7891 - auROC: 0.6953 - val_loss: 0.5213 - val_acc: 0.7828 - val_auROC: 0.6076\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.4719 - acc: 0.8218 - auROC: 0.7359 - val_loss: 0.4984 - val_acc: 0.7897 - val_auROC: 0.6615\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4554 - acc: 0.8152 - auROC: 0.7563 - val_loss: 0.4660 - val_acc: 0.8069 - val_auROC: 0.7433\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4450 - acc: 0.8168 - auROC: 0.7817 - val_loss: 0.4571 - val_acc: 0.8103 - val_auROC: 0.7286\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.4384 - acc: 0.8183 - auROC: 0.7808 - val_loss: 0.4486 - val_acc: 0.8207 - val_auROC: 0.7615\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4259 - acc: 0.8316 - auROC: 0.8152 - val_loss: 0.4427 - val_acc: 0.8241 - val_auROC: 0.7656\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4128 - acc: 0.8366 - auROC: 0.8341 - val_loss: 0.4371 - val_acc: 0.8103 - val_auROC: 0.7818\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4056 - acc: 0.8413 - auROC: 0.8423 - val_loss: 0.4377 - val_acc: 0.8103 - val_auROC: 0.7757\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3980 - acc: 0.8483 - auROC: 0.8525 - val_loss: 0.4342 - val_acc: 0.8103 - val_auROC: 0.7686\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3949 - acc: 0.8491 - auROC: 0.8437 - val_loss: 0.4356 - val_acc: 0.8034 - val_auROC: 0.7616\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4095 - acc: 0.8292 - auROC: 0.8228 - val_loss: 0.4376 - val_acc: 0.8345 - val_auROC: 0.7436\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3955 - acc: 0.8339 - auROC: 0.8466 - val_loss: 0.4269 - val_acc: 0.8034 - val_auROC: 0.7794\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3892 - acc: 0.8483 - auROC: 0.8478 - val_loss: 0.4177 - val_acc: 0.8000 - val_auROC: 0.7967\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3729 - acc: 0.8503 - auROC: 0.8768 - val_loss: 0.4143 - val_acc: 0.8241 - val_auROC: 0.7850\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3786 - acc: 0.8394 - auROC: 0.8600 - val_loss: 0.4044 - val_acc: 0.8276 - val_auROC: 0.8032\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3670 - acc: 0.8534 - auROC: 0.8767 - val_loss: 0.3998 - val_acc: 0.8207 - val_auROC: 0.8147\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3604 - acc: 0.8585 - auROC: 0.8840 - val_loss: 0.3937 - val_acc: 0.8207 - val_auROC: 0.8352\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3545 - acc: 0.8710 - auROC: 0.8880 - val_loss: 0.3913 - val_acc: 0.8345 - val_auROC: 0.8235\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3461 - acc: 0.8784 - auROC: 0.9024 - val_loss: 0.3857 - val_acc: 0.8310 - val_auROC: 0.8442\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3397 - acc: 0.8834 - auROC: 0.9080 - val_loss: 0.3836 - val_acc: 0.8448 - val_auROC: 0.8369\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3410 - acc: 0.8721 - auROC: 0.9050 - val_loss: 0.3800 - val_acc: 0.8517 - val_auROC: 0.8451\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3363 - acc: 0.8819 - auROC: 0.9055 - val_loss: 0.3805 - val_acc: 0.8448 - val_auROC: 0.8296\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3244 - acc: 0.8904 - auROC: 0.9163 - val_loss: 0.3742 - val_acc: 0.8517 - val_auROC: 0.8505\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3201 - acc: 0.8932 - auROC: 0.9253 - val_loss: 0.3648 - val_acc: 0.8655 - val_auROC: 0.8560\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3127 - acc: 0.8982 - auROC: 0.9294 - val_loss: 0.3643 - val_acc: 0.8483 - val_auROC: 0.8615\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3104 - acc: 0.9025 - auROC: 0.9309 - val_loss: 0.3628 - val_acc: 0.8483 - val_auROC: 0.8619\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3028 - acc: 0.9053 - auROC: 0.9358 - val_loss: 0.3470 - val_acc: 0.8690 - val_auROC: 0.8796\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2976 - acc: 0.9084 - auROC: 0.9382 - val_loss: 0.3416 - val_acc: 0.8586 - val_auROC: 0.8844\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2913 - acc: 0.9103 - auROC: 0.9437 - val_loss: 0.3329 - val_acc: 0.8793 - val_auROC: 0.8924\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2885 - acc: 0.9115 - auROC: 0.9435 - val_loss: 0.3450 - val_acc: 0.8724 - val_auROC: 0.8758\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2908 - acc: 0.9162 - auROC: 0.9381 - val_loss: 0.3342 - val_acc: 0.8724 - val_auROC: 0.8849\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2768 - acc: 0.9244 - auROC: 0.9509 - val_loss: 0.3423 - val_acc: 0.8655 - val_auROC: 0.8785\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2774 - acc: 0.9279 - auROC: 0.9471 - val_loss: 0.3223 - val_acc: 0.8897 - val_auROC: 0.8900\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2778 - acc: 0.9263 - auROC: 0.9428 - val_loss: 0.3242 - val_acc: 0.8793 - val_auROC: 0.8955\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2772 - acc: 0.9279 - auROC: 0.9416 - val_loss: 0.3484 - val_acc: 0.8931 - val_auROC: 0.8541\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2731 - acc: 0.9193 - auROC: 0.9435 - val_loss: 0.3367 - val_acc: 0.8724 - val_auROC: 0.8730\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2894 - acc: 0.9103 - auROC: 0.9198 - val_loss: 0.3337 - val_acc: 0.8828 - val_auROC: 0.8801\n",
      "Epoch 42/300\n",
      "6/9 [===================>..........] - ETA: 0s - loss: 0.2740 - acc: 0.9198 - auROC: 0.9357\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2727 - acc: 0.9170 - auROC: 0.9399 - val_loss: 0.3387 - val_acc: 0.8759 - val_auROC: 0.8600\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2682 - acc: 0.9173 - auROC: 0.9404 - val_loss: 0.3311 - val_acc: 0.8759 - val_auROC: 0.8707\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.2552 - acc: 0.9306 - auROC: 0.9539 - val_loss: 0.3220 - val_acc: 0.8862 - val_auROC: 0.8809\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2509 - acc: 0.9415 - auROC: 0.9565 - val_loss: 0.3262 - val_acc: 0.8724 - val_auROC: 0.8812\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2527 - acc: 0.9384 - auROC: 0.9553 - val_loss: 0.3162 - val_acc: 0.8793 - val_auROC: 0.8924\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2501 - acc: 0.9431 - auROC: 0.9571 - val_loss: 0.3092 - val_acc: 0.9034 - val_auROC: 0.8992\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2460 - acc: 0.9466 - auROC: 0.9595 - val_loss: 0.3070 - val_acc: 0.8966 - val_auROC: 0.9024\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2430 - acc: 0.9478 - auROC: 0.9614 - val_loss: 0.3073 - val_acc: 0.8862 - val_auROC: 0.9015\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2410 - acc: 0.9481 - auROC: 0.9631 - val_loss: 0.3079 - val_acc: 0.8897 - val_auROC: 0.9009\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2399 - acc: 0.9505 - auROC: 0.9637 - val_loss: 0.3078 - val_acc: 0.8862 - val_auROC: 0.9009\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2389 - acc: 0.9497 - auROC: 0.9640 - val_loss: 0.3078 - val_acc: 0.8862 - val_auROC: 0.9008\n",
      "Epoch 53/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.2375 - acc: 0.9512 - auROC: 0.9648\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2379 - acc: 0.9509 - auROC: 0.9645 - val_loss: 0.3080 - val_acc: 0.8897 - val_auROC: 0.8999\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2372 - acc: 0.9509 - auROC: 0.9651 - val_loss: 0.3084 - val_acc: 0.8897 - val_auROC: 0.8996\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2372 - acc: 0.9513 - auROC: 0.9651 - val_loss: 0.3085 - val_acc: 0.8897 - val_auROC: 0.8994\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2372 - acc: 0.9509 - auROC: 0.9652 - val_loss: 0.3091 - val_acc: 0.8931 - val_auROC: 0.9002\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2371 - acc: 0.9517 - auROC: 0.9651 - val_loss: 0.3090 - val_acc: 0.8931 - val_auROC: 0.9003\n",
      "Epoch 58/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.2370 - acc: 0.9516 - auROC: 0.9652\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2370 - acc: 0.9517 - auROC: 0.9653 - val_loss: 0.3081 - val_acc: 0.8897 - val_auROC: 0.9009\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2368 - acc: 0.9509 - auROC: 0.9653 - val_loss: 0.3070 - val_acc: 0.8931 - val_auROC: 0.9023\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2366 - acc: 0.9509 - auROC: 0.9656 - val_loss: 0.3064 - val_acc: 0.8931 - val_auROC: 0.9040\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2365 - acc: 0.9505 - auROC: 0.9654 - val_loss: 0.3060 - val_acc: 0.8931 - val_auROC: 0.9045\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2365 - acc: 0.9509 - auROC: 0.9656 - val_loss: 0.3057 - val_acc: 0.8931 - val_auROC: 0.9046\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2364 - acc: 0.9517 - auROC: 0.9654 - val_loss: 0.3055 - val_acc: 0.8931 - val_auROC: 0.9045\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2363 - acc: 0.9517 - auROC: 0.9655 - val_loss: 0.3053 - val_acc: 0.8931 - val_auROC: 0.9044\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2362 - acc: 0.9513 - auROC: 0.9655 - val_loss: 0.3048 - val_acc: 0.8931 - val_auROC: 0.9041\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2361 - acc: 0.9524 - auROC: 0.9656 - val_loss: 0.3050 - val_acc: 0.8931 - val_auROC: 0.9038\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2360 - acc: 0.9517 - auROC: 0.9657 - val_loss: 0.3048 - val_acc: 0.8931 - val_auROC: 0.9038\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2359 - acc: 0.9517 - auROC: 0.9656 - val_loss: 0.3047 - val_acc: 0.8931 - val_auROC: 0.9040\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2358 - acc: 0.9517 - auROC: 0.9655 - val_loss: 0.3045 - val_acc: 0.8931 - val_auROC: 0.9044\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2357 - acc: 0.9509 - auROC: 0.9656 - val_loss: 0.3037 - val_acc: 0.8931 - val_auROC: 0.9054\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2356 - acc: 0.9513 - auROC: 0.9657 - val_loss: 0.3036 - val_acc: 0.8931 - val_auROC: 0.9056\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2355 - acc: 0.9517 - auROC: 0.9658 - val_loss: 0.3035 - val_acc: 0.8931 - val_auROC: 0.9057\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2354 - acc: 0.9517 - auROC: 0.9657 - val_loss: 0.3035 - val_acc: 0.8931 - val_auROC: 0.9057\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2354 - acc: 0.9517 - auROC: 0.9658 - val_loss: 0.3038 - val_acc: 0.8931 - val_auROC: 0.9066\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2353 - acc: 0.9513 - auROC: 0.9658 - val_loss: 0.3041 - val_acc: 0.8931 - val_auROC: 0.9047\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2352 - acc: 0.9517 - auROC: 0.9659 - val_loss: 0.3040 - val_acc: 0.8931 - val_auROC: 0.9048\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2352 - acc: 0.9517 - auROC: 0.9659 - val_loss: 0.3039 - val_acc: 0.8931 - val_auROC: 0.9048\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2351 - acc: 0.9513 - auROC: 0.9659 - val_loss: 0.3031 - val_acc: 0.8897 - val_auROC: 0.9058\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2350 - acc: 0.9513 - auROC: 0.9659 - val_loss: 0.3029 - val_acc: 0.8931 - val_auROC: 0.9071\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2349 - acc: 0.9517 - auROC: 0.9660 - val_loss: 0.3030 - val_acc: 0.8931 - val_auROC: 0.9069\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2348 - acc: 0.9520 - auROC: 0.9662 - val_loss: 0.3030 - val_acc: 0.8931 - val_auROC: 0.9069\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2348 - acc: 0.9517 - auROC: 0.9661 - val_loss: 0.3029 - val_acc: 0.8966 - val_auROC: 0.9056\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2347 - acc: 0.9513 - auROC: 0.9660 - val_loss: 0.3030 - val_acc: 0.8966 - val_auROC: 0.9053\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2347 - acc: 0.9524 - auROC: 0.9662 - val_loss: 0.3031 - val_acc: 0.8931 - val_auROC: 0.9052\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2346 - acc: 0.9517 - auROC: 0.9662 - val_loss: 0.3030 - val_acc: 0.8931 - val_auROC: 0.9054\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2345 - acc: 0.9524 - auROC: 0.9662 - val_loss: 0.3029 - val_acc: 0.8966 - val_auROC: 0.9058\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2344 - acc: 0.9528 - auROC: 0.9663 - val_loss: 0.3028 - val_acc: 0.8966 - val_auROC: 0.9060\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2343 - acc: 0.9524 - auROC: 0.9663 - val_loss: 0.3028 - val_acc: 0.8966 - val_auROC: 0.9058\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2342 - acc: 0.9520 - auROC: 0.9664 - val_loss: 0.3028 - val_acc: 0.8966 - val_auROC: 0.9057\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2340 - acc: 0.9520 - auROC: 0.9664 - val_loss: 0.3025 - val_acc: 0.8966 - val_auROC: 0.9059\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2339 - acc: 0.9528 - auROC: 0.9665 - val_loss: 0.3017 - val_acc: 0.8966 - val_auROC: 0.9064\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2339 - acc: 0.9524 - auROC: 0.9665 - val_loss: 0.3013 - val_acc: 0.8966 - val_auROC: 0.9066\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2338 - acc: 0.9528 - auROC: 0.9666 - val_loss: 0.3012 - val_acc: 0.8966 - val_auROC: 0.9067\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2337 - acc: 0.9528 - auROC: 0.9667 - val_loss: 0.3012 - val_acc: 0.8966 - val_auROC: 0.9068\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2336 - acc: 0.9532 - auROC: 0.9667 - val_loss: 0.3009 - val_acc: 0.9000 - val_auROC: 0.9073\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2335 - acc: 0.9536 - auROC: 0.9668 - val_loss: 0.3008 - val_acc: 0.9000 - val_auROC: 0.9074\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2333 - acc: 0.9536 - auROC: 0.9668 - val_loss: 0.3009 - val_acc: 0.9000 - val_auROC: 0.9074\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2332 - acc: 0.9536 - auROC: 0.9668 - val_loss: 0.3013 - val_acc: 0.8966 - val_auROC: 0.9071\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2331 - acc: 0.9528 - auROC: 0.9669 - val_loss: 0.3015 - val_acc: 0.8966 - val_auROC: 0.9073\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2330 - acc: 0.9532 - auROC: 0.9669 - val_loss: 0.3018 - val_acc: 0.8966 - val_auROC: 0.9068\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2329 - acc: 0.9532 - auROC: 0.9670 - val_loss: 0.3022 - val_acc: 0.8966 - val_auROC: 0.9057\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2328 - acc: 0.9536 - auROC: 0.9671 - val_loss: 0.3025 - val_acc: 0.8931 - val_auROC: 0.9071\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2327 - acc: 0.9548 - auROC: 0.9675 - val_loss: 0.3021 - val_acc: 0.8966 - val_auROC: 0.9073\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2326 - acc: 0.9544 - auROC: 0.9676 - val_loss: 0.3018 - val_acc: 0.8966 - val_auROC: 0.9074\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2326 - acc: 0.9544 - auROC: 0.9674 - val_loss: 0.3017 - val_acc: 0.8966 - val_auROC: 0.9074\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2325 - acc: 0.9544 - auROC: 0.9675 - val_loss: 0.3017 - val_acc: 0.8966 - val_auROC: 0.9078\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2324 - acc: 0.9544 - auROC: 0.9674 - val_loss: 0.3014 - val_acc: 0.9000 - val_auROC: 0.9077\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2323 - acc: 0.9552 - auROC: 0.9674 - val_loss: 0.3011 - val_acc: 0.9000 - val_auROC: 0.9080\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2323 - acc: 0.9548 - auROC: 0.9675 - val_loss: 0.3010 - val_acc: 0.9000 - val_auROC: 0.9080\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2322 - acc: 0.9548 - auROC: 0.9675 - val_loss: 0.3008 - val_acc: 0.9000 - val_auROC: 0.9084\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2321 - acc: 0.9544 - auROC: 0.9675 - val_loss: 0.3001 - val_acc: 0.9000 - val_auROC: 0.9091\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2321 - acc: 0.9548 - auROC: 0.9674 - val_loss: 0.3000 - val_acc: 0.9000 - val_auROC: 0.9091\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2320 - acc: 0.9544 - auROC: 0.9674 - val_loss: 0.3001 - val_acc: 0.9000 - val_auROC: 0.9090\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2320 - acc: 0.9548 - auROC: 0.9673 - val_loss: 0.3000 - val_acc: 0.9000 - val_auROC: 0.9091\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2321 - acc: 0.9552 - auROC: 0.9673 - val_loss: 0.3004 - val_acc: 0.9000 - val_auROC: 0.9090\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2321 - acc: 0.9552 - auROC: 0.9672 - val_loss: 0.3012 - val_acc: 0.8897 - val_auROC: 0.9084\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2320 - acc: 0.9559 - auROC: 0.9673 - val_loss: 0.3015 - val_acc: 0.8897 - val_auROC: 0.9084\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2319 - acc: 0.9559 - auROC: 0.9675 - val_loss: 0.3014 - val_acc: 0.8931 - val_auROC: 0.9093\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2317 - acc: 0.9556 - auROC: 0.9676 - val_loss: 0.3013 - val_acc: 0.8931 - val_auROC: 0.9080\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2315 - acc: 0.9556 - auROC: 0.9676 - val_loss: 0.3012 - val_acc: 0.8931 - val_auROC: 0.9080\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2314 - acc: 0.9556 - auROC: 0.9677 - val_loss: 0.3012 - val_acc: 0.8931 - val_auROC: 0.9078\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2313 - acc: 0.9556 - auROC: 0.9678 - val_loss: 0.3012 - val_acc: 0.8931 - val_auROC: 0.9082\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2313 - acc: 0.9556 - auROC: 0.9678 - val_loss: 0.3012 - val_acc: 0.8931 - val_auROC: 0.9082\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2312 - acc: 0.9559 - auROC: 0.9678 - val_loss: 0.3006 - val_acc: 0.9000 - val_auROC: 0.9089\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2311 - acc: 0.9548 - auROC: 0.9678 - val_loss: 0.3005 - val_acc: 0.9000 - val_auROC: 0.9091\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2310 - acc: 0.9552 - auROC: 0.9678 - val_loss: 0.3006 - val_acc: 0.9000 - val_auROC: 0.9091\n",
      "Epoch 127/300\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.2315 - acc: 0.9554 - auROC: 0.9672Restoring model weights from the end of the best epoch.\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2309 - acc: 0.9552 - auROC: 0.9679 - val_loss: 0.3007 - val_acc: 0.9034 - val_auROC: 0.9087\n",
      "Epoch 00127: early stopping\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 18018)]           0         \n",
      "_________________________________________________________________\n",
      "base (Sequential)            (None, 512)               18976256  \n",
      "_________________________________________________________________\n",
      "l2_inter (Sequential)        (None, 10)                21550     \n",
      "_________________________________________________________________\n",
      "l2_integration (Sequential)  (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "l2o (Sequential)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 18,998,051\n",
      "Trainable params: 21,795\n",
      "Non-trainable params: 18,976,256\n",
      "_________________________________________________________________\n",
      "Fine-tuning using optimizer with lr=1e-05...\n",
      "Epoch 127/426\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 0.2323 - acc: 0.9544 - auROC: 0.9670 - val_loss: 0.3003 - val_acc: 0.9034 - val_auROC: 0.9083\n",
      "Epoch 128/426\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2274 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2994 - val_acc: 0.9103 - val_auROC: 0.9080\n",
      "Epoch 129/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2244 - acc: 0.9634 - auROC: 0.9712 - val_loss: 0.2982 - val_acc: 0.9103 - val_auROC: 0.9083\n",
      "Epoch 130/426\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2227 - acc: 0.9653 - auROC: 0.9714 - val_loss: 0.2986 - val_acc: 0.9103 - val_auROC: 0.9085\n",
      "Epoch 131/426\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2205 - acc: 0.9657 - auROC: 0.9728 - val_loss: 0.2957 - val_acc: 0.9138 - val_auROC: 0.9084\n",
      "Epoch 132/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2190 - acc: 0.9676 - auROC: 0.9733 - val_loss: 0.2935 - val_acc: 0.9172 - val_auROC: 0.9103\n",
      "Epoch 133/426\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2176 - acc: 0.9680 - auROC: 0.9739 - val_loss: 0.2940 - val_acc: 0.9103 - val_auROC: 0.9106\n",
      "Epoch 134/426\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2161 - acc: 0.9680 - auROC: 0.9746 - val_loss: 0.2930 - val_acc: 0.9138 - val_auROC: 0.9121\n",
      "Epoch 135/426\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2147 - acc: 0.9696 - auROC: 0.9752 - val_loss: 0.2899 - val_acc: 0.9207 - val_auROC: 0.9144\n",
      "Epoch 136/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2134 - acc: 0.9696 - auROC: 0.9755 - val_loss: 0.2890 - val_acc: 0.9138 - val_auROC: 0.9152\n",
      "Epoch 137/426\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2124 - acc: 0.9712 - auROC: 0.9757 - val_loss: 0.2885 - val_acc: 0.9103 - val_auROC: 0.9150\n",
      "Epoch 138/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2114 - acc: 0.9723 - auROC: 0.9760 - val_loss: 0.2870 - val_acc: 0.9172 - val_auROC: 0.9162\n",
      "Epoch 139/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2105 - acc: 0.9727 - auROC: 0.9760 - val_loss: 0.2867 - val_acc: 0.9138 - val_auROC: 0.9174\n",
      "Epoch 140/426\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2095 - acc: 0.9727 - auROC: 0.9762 - val_loss: 0.2870 - val_acc: 0.9172 - val_auROC: 0.9161\n",
      "Epoch 141/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2087 - acc: 0.9743 - auROC: 0.9766 - val_loss: 0.2861 - val_acc: 0.9207 - val_auROC: 0.9168\n",
      "Epoch 142/426\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.2081 - acc: 0.9754 - auROC: 0.9770 - val_loss: 0.2847 - val_acc: 0.9241 - val_auROC: 0.9162\n",
      "Epoch 143/426\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.2070 - acc: 0.9750 - auROC: 0.9769 - val_loss: 0.2833 - val_acc: 0.9276 - val_auROC: 0.9172\n",
      "Epoch 144/426\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2061 - acc: 0.9762 - auROC: 0.9768 - val_loss: 0.2834 - val_acc: 0.9276 - val_auROC: 0.9178\n",
      "Epoch 145/426\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2054 - acc: 0.9754 - auROC: 0.9771 - val_loss: 0.2819 - val_acc: 0.9276 - val_auROC: 0.9196\n",
      "Epoch 146/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2046 - acc: 0.9754 - auROC: 0.9773 - val_loss: 0.2820 - val_acc: 0.9276 - val_auROC: 0.9192\n",
      "Epoch 147/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2039 - acc: 0.9758 - auROC: 0.9772 - val_loss: 0.2815 - val_acc: 0.9276 - val_auROC: 0.9198\n",
      "Epoch 148/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2034 - acc: 0.9766 - auROC: 0.9776 - val_loss: 0.2798 - val_acc: 0.9276 - val_auROC: 0.9209\n",
      "Epoch 149/426\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2029 - acc: 0.9762 - auROC: 0.9777 - val_loss: 0.2801 - val_acc: 0.9241 - val_auROC: 0.9207\n",
      "Epoch 150/426\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2023 - acc: 0.9774 - auROC: 0.9776 - val_loss: 0.2800 - val_acc: 0.9241 - val_auROC: 0.9207\n",
      "Epoch 151/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2015 - acc: 0.9778 - auROC: 0.9779 - val_loss: 0.2793 - val_acc: 0.9241 - val_auROC: 0.9210\n",
      "Epoch 152/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2010 - acc: 0.9778 - auROC: 0.9779 - val_loss: 0.2793 - val_acc: 0.9241 - val_auROC: 0.9210\n",
      "Epoch 153/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2005 - acc: 0.9774 - auROC: 0.9780 - val_loss: 0.2779 - val_acc: 0.9276 - val_auROC: 0.9219\n",
      "Epoch 154/426\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1999 - acc: 0.9782 - auROC: 0.9782 - val_loss: 0.2769 - val_acc: 0.9276 - val_auROC: 0.9229\n",
      "Epoch 155/426\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.1994 - acc: 0.9786 - auROC: 0.9784 - val_loss: 0.2761 - val_acc: 0.9310 - val_auROC: 0.9232\n",
      "Epoch 156/426\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1990 - acc: 0.9801 - auROC: 0.9785 - val_loss: 0.2753 - val_acc: 0.9310 - val_auROC: 0.9233\n",
      "Epoch 157/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1989 - acc: 0.9789 - auROC: 0.9784 - val_loss: 0.2751 - val_acc: 0.9276 - val_auROC: 0.9249\n",
      "Epoch 158/426\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.1986 - acc: 0.9805 - auROC: 0.9787 - val_loss: 0.2741 - val_acc: 0.9310 - val_auROC: 0.9235\n",
      "Epoch 159/426\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1980 - acc: 0.9809 - auROC: 0.9788 - val_loss: 0.2736 - val_acc: 0.9310 - val_auROC: 0.9242\n",
      "Epoch 160/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1976 - acc: 0.9813 - auROC: 0.9790 - val_loss: 0.2731 - val_acc: 0.9310 - val_auROC: 0.9264\n",
      "Epoch 161/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1971 - acc: 0.9821 - auROC: 0.9790 - val_loss: 0.2733 - val_acc: 0.9276 - val_auROC: 0.9264\n",
      "Epoch 162/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1973 - acc: 0.9821 - auROC: 0.9790 - val_loss: 0.2730 - val_acc: 0.9310 - val_auROC: 0.9246\n",
      "Epoch 163/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1974 - acc: 0.9832 - auROC: 0.9789 - val_loss: 0.2724 - val_acc: 0.9310 - val_auROC: 0.9249\n",
      "Epoch 164/426\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1967 - acc: 0.9821 - auROC: 0.9791 - val_loss: 0.2733 - val_acc: 0.9310 - val_auROC: 0.9252\n",
      "Epoch 165/426\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1960 - acc: 0.9821 - auROC: 0.9793 - val_loss: 0.2733 - val_acc: 0.9310 - val_auROC: 0.9248\n",
      "Epoch 166/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1957 - acc: 0.9825 - auROC: 0.9797 - val_loss: 0.2713 - val_acc: 0.9310 - val_auROC: 0.9272\n",
      "Epoch 167/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1953 - acc: 0.9825 - auROC: 0.9793 - val_loss: 0.2711 - val_acc: 0.9310 - val_auROC: 0.9256\n",
      "Epoch 168/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1947 - acc: 0.9832 - auROC: 0.9795 - val_loss: 0.2719 - val_acc: 0.9310 - val_auROC: 0.9253\n",
      "Epoch 169/426\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1942 - acc: 0.9836 - auROC: 0.9802 - val_loss: 0.2713 - val_acc: 0.9310 - val_auROC: 0.9256\n",
      "Epoch 170/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1938 - acc: 0.9836 - auROC: 0.9805 - val_loss: 0.2706 - val_acc: 0.9310 - val_auROC: 0.9259\n",
      "Epoch 171/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1935 - acc: 0.9836 - auROC: 0.9806 - val_loss: 0.2697 - val_acc: 0.9345 - val_auROC: 0.9258\n",
      "Epoch 172/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1930 - acc: 0.9840 - auROC: 0.9807 - val_loss: 0.2707 - val_acc: 0.9310 - val_auROC: 0.9250\n",
      "Epoch 173/426\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1930 - acc: 0.9840 - auROC: 0.9804 - val_loss: 0.2714 - val_acc: 0.9310 - val_auROC: 0.9238\n",
      "Epoch 174/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1925 - acc: 0.9832 - auROC: 0.9811 - val_loss: 0.2711 - val_acc: 0.9310 - val_auROC: 0.9250\n",
      "Epoch 175/426\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1922 - acc: 0.9832 - auROC: 0.9812 - val_loss: 0.2714 - val_acc: 0.9310 - val_auROC: 0.9252\n",
      "Epoch 176/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1919 - acc: 0.9840 - auROC: 0.9813 - val_loss: 0.2708 - val_acc: 0.9310 - val_auROC: 0.9250\n",
      "Epoch 177/426\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1914 - acc: 0.9844 - auROC: 0.9813 - val_loss: 0.2703 - val_acc: 0.9310 - val_auROC: 0.9246\n",
      "Epoch 178/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1911 - acc: 0.9844 - auROC: 0.9814 - val_loss: 0.2694 - val_acc: 0.9310 - val_auROC: 0.9242\n",
      "Epoch 179/426\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1910 - acc: 0.9844 - auROC: 0.9813 - val_loss: 0.2681 - val_acc: 0.9310 - val_auROC: 0.9252\n",
      "Epoch 180/426\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.1905 - acc: 0.9844 - auROC: 0.9813 - val_loss: 0.2665 - val_acc: 0.9310 - val_auROC: 0.9262\n",
      "Epoch 181/426\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1900 - acc: 0.9844 - auROC: 0.9813 - val_loss: 0.2656 - val_acc: 0.9345 - val_auROC: 0.9268\n",
      "Epoch 182/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1896 - acc: 0.9840 - auROC: 0.9814 - val_loss: 0.2655 - val_acc: 0.9345 - val_auROC: 0.9268\n",
      "Epoch 183/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1891 - acc: 0.9848 - auROC: 0.9818 - val_loss: 0.2648 - val_acc: 0.9310 - val_auROC: 0.9270\n",
      "Epoch 184/426\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.1888 - acc: 0.9848 - auROC: 0.9822 - val_loss: 0.2650 - val_acc: 0.9310 - val_auROC: 0.9268\n",
      "Epoch 185/426\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.1884 - acc: 0.9848 - auROC: 0.9823 - val_loss: 0.2646 - val_acc: 0.9310 - val_auROC: 0.9273\n",
      "Epoch 186/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1881 - acc: 0.9852 - auROC: 0.9826 - val_loss: 0.2644 - val_acc: 0.9345 - val_auROC: 0.9286\n",
      "Epoch 187/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1877 - acc: 0.9852 - auROC: 0.9829 - val_loss: 0.2645 - val_acc: 0.9345 - val_auROC: 0.9281\n",
      "Epoch 188/426\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1873 - acc: 0.9856 - auROC: 0.9836 - val_loss: 0.2642 - val_acc: 0.9345 - val_auROC: 0.9296\n",
      "Epoch 189/426\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1870 - acc: 0.9856 - auROC: 0.9836 - val_loss: 0.2632 - val_acc: 0.9345 - val_auROC: 0.9304\n",
      "Epoch 190/426\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1865 - acc: 0.9864 - auROC: 0.9841 - val_loss: 0.2628 - val_acc: 0.9345 - val_auROC: 0.9303\n",
      "Epoch 191/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1862 - acc: 0.9864 - auROC: 0.9842 - val_loss: 0.2621 - val_acc: 0.9310 - val_auROC: 0.9303\n",
      "Epoch 192/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1864 - acc: 0.9864 - auROC: 0.9840 - val_loss: 0.2644 - val_acc: 0.9345 - val_auROC: 0.9266\n",
      "Epoch 193/426\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1867 - acc: 0.9856 - auROC: 0.9832 - val_loss: 0.2642 - val_acc: 0.9345 - val_auROC: 0.9255\n",
      "Epoch 194/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1864 - acc: 0.9856 - auROC: 0.9835 - val_loss: 0.2633 - val_acc: 0.9345 - val_auROC: 0.9285\n",
      "Epoch 195/426\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1859 - acc: 0.9856 - auROC: 0.9840 - val_loss: 0.2613 - val_acc: 0.9379 - val_auROC: 0.9301\n",
      "Epoch 196/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1852 - acc: 0.9860 - auROC: 0.9843 - val_loss: 0.2581 - val_acc: 0.9379 - val_auROC: 0.9326\n",
      "Epoch 197/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1850 - acc: 0.9856 - auROC: 0.9844 - val_loss: 0.2562 - val_acc: 0.9414 - val_auROC: 0.9346\n",
      "Epoch 198/426\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1854 - acc: 0.9864 - auROC: 0.9844 - val_loss: 0.2562 - val_acc: 0.9379 - val_auROC: 0.9347\n",
      "Epoch 199/426\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.1872 - acc: 0.9832 - auROC: 0.9838 - val_loss: 0.2558 - val_acc: 0.9379 - val_auROC: 0.9340\n",
      "Epoch 200/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1862 - acc: 0.9832 - auROC: 0.9845 - val_loss: 0.2554 - val_acc: 0.9379 - val_auROC: 0.9346\n",
      "Epoch 201/426\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1846 - acc: 0.9852 - auROC: 0.9852 - val_loss: 0.2568 - val_acc: 0.9276 - val_auROC: 0.9343\n",
      "Epoch 202/426\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1836 - acc: 0.9864 - auROC: 0.9854 - val_loss: 0.2558 - val_acc: 0.9379 - val_auROC: 0.9342\n",
      "Epoch 203/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1833 - acc: 0.9864 - auROC: 0.9854 - val_loss: 0.2546 - val_acc: 0.9448 - val_auROC: 0.9350\n",
      "Epoch 204/426\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1839 - acc: 0.9860 - auROC: 0.9853 - val_loss: 0.2534 - val_acc: 0.9414 - val_auROC: 0.9369\n",
      "Epoch 205/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1832 - acc: 0.9867 - auROC: 0.9850 - val_loss: 0.2511 - val_acc: 0.9448 - val_auROC: 0.9375\n",
      "Epoch 206/426\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.1826 - acc: 0.9871 - auROC: 0.9848 - val_loss: 0.2505 - val_acc: 0.9483 - val_auROC: 0.9377\n",
      "Epoch 207/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1820 - acc: 0.9871 - auROC: 0.9855 - val_loss: 0.2500 - val_acc: 0.9448 - val_auROC: 0.9371\n",
      "Epoch 208/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1817 - acc: 0.9867 - auROC: 0.9857 - val_loss: 0.2499 - val_acc: 0.9414 - val_auROC: 0.9378\n",
      "Epoch 209/426\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.1813 - acc: 0.9871 - auROC: 0.9858 - val_loss: 0.2492 - val_acc: 0.9448 - val_auROC: 0.9384\n",
      "Epoch 210/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1811 - acc: 0.9871 - auROC: 0.9856 - val_loss: 0.2488 - val_acc: 0.9448 - val_auROC: 0.9386\n",
      "Epoch 211/426\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.1809 - acc: 0.9871 - auROC: 0.9861 - val_loss: 0.2495 - val_acc: 0.9448 - val_auROC: 0.9381\n",
      "Epoch 212/426\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1806 - acc: 0.9871 - auROC: 0.9864 - val_loss: 0.2496 - val_acc: 0.9448 - val_auROC: 0.9387\n",
      "Epoch 213/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1803 - acc: 0.9875 - auROC: 0.9864 - val_loss: 0.2504 - val_acc: 0.9483 - val_auROC: 0.9387\n",
      "Epoch 214/426\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1801 - acc: 0.9875 - auROC: 0.9865 - val_loss: 0.2491 - val_acc: 0.9483 - val_auROC: 0.9400\n",
      "Epoch 215/426\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1798 - acc: 0.9875 - auROC: 0.9866 - val_loss: 0.2480 - val_acc: 0.9483 - val_auROC: 0.9405\n",
      "Epoch 216/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1796 - acc: 0.9875 - auROC: 0.9867 - val_loss: 0.2470 - val_acc: 0.9483 - val_auROC: 0.9415\n",
      "Epoch 217/426\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1794 - acc: 0.9879 - auROC: 0.9869 - val_loss: 0.2466 - val_acc: 0.9483 - val_auROC: 0.9418\n",
      "Epoch 218/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1791 - acc: 0.9879 - auROC: 0.9870 - val_loss: 0.2460 - val_acc: 0.9483 - val_auROC: 0.9422\n",
      "Epoch 219/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1789 - acc: 0.9879 - auROC: 0.9871 - val_loss: 0.2454 - val_acc: 0.9483 - val_auROC: 0.9427\n",
      "Epoch 220/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1788 - acc: 0.9879 - auROC: 0.9873 - val_loss: 0.2453 - val_acc: 0.9483 - val_auROC: 0.9426\n",
      "Epoch 221/426\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1788 - acc: 0.9879 - auROC: 0.9875 - val_loss: 0.2450 - val_acc: 0.9483 - val_auROC: 0.9443\n",
      "Epoch 222/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1786 - acc: 0.9879 - auROC: 0.9878 - val_loss: 0.2450 - val_acc: 0.9483 - val_auROC: 0.9435\n",
      "Epoch 223/426\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1783 - acc: 0.9879 - auROC: 0.9880 - val_loss: 0.2439 - val_acc: 0.9483 - val_auROC: 0.9440\n",
      "Epoch 224/426\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1779 - acc: 0.9879 - auROC: 0.9882 - val_loss: 0.2425 - val_acc: 0.9483 - val_auROC: 0.9445\n",
      "Epoch 225/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1776 - acc: 0.9879 - auROC: 0.9885 - val_loss: 0.2421 - val_acc: 0.9483 - val_auROC: 0.9449\n",
      "Epoch 226/426\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1774 - acc: 0.9883 - auROC: 0.9887 - val_loss: 0.2410 - val_acc: 0.9483 - val_auROC: 0.9459\n",
      "Epoch 227/426\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1772 - acc: 0.9883 - auROC: 0.9889 - val_loss: 0.2403 - val_acc: 0.9483 - val_auROC: 0.9468\n",
      "Epoch 228/426\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1770 - acc: 0.9883 - auROC: 0.9892 - val_loss: 0.2389 - val_acc: 0.9483 - val_auROC: 0.9501\n",
      "Epoch 229/426\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1788 - acc: 0.9871 - auROC: 0.9892 - val_loss: 0.2425 - val_acc: 0.9448 - val_auROC: 0.9519\n",
      "Epoch 230/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1796 - acc: 0.9867 - auROC: 0.9897 - val_loss: 0.2359 - val_acc: 0.9483 - val_auROC: 0.9547\n",
      "Epoch 231/426\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1776 - acc: 0.9883 - auROC: 0.9902 - val_loss: 0.2330 - val_acc: 0.9552 - val_auROC: 0.9573\n",
      "Epoch 232/426\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1769 - acc: 0.9883 - auROC: 0.9903 - val_loss: 0.2330 - val_acc: 0.9552 - val_auROC: 0.9569\n",
      "Epoch 233/426\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1765 - acc: 0.9883 - auROC: 0.9902 - val_loss: 0.2367 - val_acc: 0.9552 - val_auROC: 0.9546\n",
      "Epoch 234/426\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1764 - acc: 0.9883 - auROC: 0.9899 - val_loss: 0.2365 - val_acc: 0.9517 - val_auROC: 0.9546\n",
      "Epoch 235/426\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1758 - acc: 0.9883 - auROC: 0.9903 - val_loss: 0.2351 - val_acc: 0.9517 - val_auROC: 0.9555\n",
      "Epoch 236/426\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1755 - acc: 0.9883 - auROC: 0.9905 - val_loss: 0.2349 - val_acc: 0.9483 - val_auROC: 0.9554\n",
      "Epoch 237/426\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1751 - acc: 0.9883 - auROC: 0.9905 - val_loss: 0.2356 - val_acc: 0.9517 - val_auROC: 0.9545\n",
      "Epoch 238/426\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1749 - acc: 0.9883 - auROC: 0.9905 - val_loss: 0.2356 - val_acc: 0.9517 - val_auROC: 0.9543\n",
      "Epoch 239/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1747 - acc: 0.9883 - auROC: 0.9906 - val_loss: 0.2351 - val_acc: 0.9517 - val_auROC: 0.9552\n",
      "Epoch 240/426\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1745 - acc: 0.9883 - auROC: 0.9906 - val_loss: 0.2351 - val_acc: 0.9517 - val_auROC: 0.9550\n",
      "Epoch 241/426\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1743 - acc: 0.9883 - auROC: 0.9906 - val_loss: 0.2350 - val_acc: 0.9517 - val_auROC: 0.9548\n",
      "Epoch 242/426\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1740 - acc: 0.9883 - auROC: 0.9906 - val_loss: 0.2347 - val_acc: 0.9517 - val_auROC: 0.9551\n",
      "Epoch 243/426\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1739 - acc: 0.9879 - auROC: 0.9907 - val_loss: 0.2353 - val_acc: 0.9483 - val_auROC: 0.9545\n",
      "Epoch 244/426\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1744 - acc: 0.9883 - auROC: 0.9898 - val_loss: 0.2364 - val_acc: 0.9517 - val_auROC: 0.9524\n",
      "Epoch 245/426\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1748 - acc: 0.9879 - auROC: 0.9891 - val_loss: 0.2356 - val_acc: 0.9448 - val_auROC: 0.9543\n",
      "Epoch 246/426\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1739 - acc: 0.9887 - auROC: 0.9901 - val_loss: 0.2343 - val_acc: 0.9483 - val_auROC: 0.9554\n",
      "Epoch 247/426\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1735 - acc: 0.9887 - auROC: 0.9903Restoring model weights from the end of the best epoch.\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.1735 - acc: 0.9887 - auROC: 0.9903 - val_loss: 0.2343 - val_acc: 0.9517 - val_auROC: 0.9552\n",
      "Epoch 00247: early stopping\n",
      "    0      1      2         3      ...  18014     18015     18016  18017\n",
      "0     0.0    0.0    0.0 -0.364831  ...    0.0 -0.199372 -0.197763    0.0\n",
      "1     0.0    0.0    0.0 -0.207833  ...    0.0 -0.199372 -0.197763    0.0\n",
      "2     0.0    0.0    0.0 -0.330822  ...    0.0 -0.199372 -0.197763    0.0\n",
      "3     0.0    0.0    0.0 -0.364268  ...    0.0  2.631315  2.667567    0.0\n",
      "4     0.0    0.0    0.0  1.188823  ...    0.0 -0.199372 -0.197763    0.0\n",
      "..    ...    ...    ...       ...  ...    ...       ...       ...    ...\n",
      "59    0.0    0.0    0.0 -0.265638  ...    0.0 -0.199372 -0.197763    0.0\n",
      "60    0.0    0.0    0.0 -0.364831  ...    0.0 -0.199372 -0.197763    0.0\n",
      "61    0.0    0.0    0.0 -0.364831  ...    0.0 -0.199372 -0.197763    0.0\n",
      "62    0.0    0.0    0.0 -0.364831  ...    0.0 -0.199372 -0.197763    0.0\n",
      "63    0.0    0.0    0.0 -0.364831  ...    0.0 -0.199372 -0.197763    0.0\n",
      "\n",
      "[64 rows x 18018 columns]\n",
      "Total NANs in input samples: 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "18013    0\n",
      "18014    0\n",
      "18015    0\n",
      "18016    0\n",
      "18017    0\n",
      "Length: 18018, dtype: int64\n",
      "Reordering labels and prediction result\n",
      "Reordering labels and prediction result for samples\n",
      "Running evaluation...\n",
      "Evaluating biome source: root:CRC (stage 0)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc   Pr  F1  ROC-AUC  F-max\n",
      "t                                  ...                                      \n",
      "0.00   0  62   0   0  0.0000  0.0  ...  1.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.01   0  62   0   0  0.0000  0.0  ...  1.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.02   0  61   0   0  0.0000  0.0  ...  1.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.03   2  59   0   0  0.0328  0.0  ...  0.9672  0.0  0.0 NaN      0.0    NaN\n",
      "0.04  18  43   0   0  0.2951  0.0  ...  0.7049  0.0  0.0 NaN      0.0    NaN\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...  ...  ..      ...    ...\n",
      "0.97  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.98  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.99  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "1.00  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "1.01  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage I)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  42   0  20  0.3226  1.0  ...  1.0000  1.0  0.3226  0.4878      1.0    1.0\n",
      "0.01   0  42   0  20  0.3226  1.0  ...  1.0000  1.0  0.3226  0.4878      1.0    1.0\n",
      "0.02   0  42   0  20  0.3226  1.0  ...  1.0000  1.0  0.3226  0.4878      1.0    1.0\n",
      "0.03   0  42   0  20  0.3226  1.0  ...  1.0000  1.0  0.3226  0.4878      1.0    1.0\n",
      "0.04   1  40   0  20  0.3443  1.0  ...  0.9756  1.0  0.3333  0.5000      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  42   0  20   0  0.6774  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  42   0  20   0  0.6774  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  42   0  20   0  0.6774  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  42   0  20   0  0.6774  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  42   0  20   0  0.6774  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage II)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  48   0  14  0.2258  1.0  ...  1.0000  1.0  0.2258  0.3684      1.0    1.0\n",
      "0.01   0  48   0  14  0.2258  1.0  ...  1.0000  1.0  0.2258  0.3684      1.0    1.0\n",
      "0.02   0  48   0  14  0.2258  1.0  ...  1.0000  1.0  0.2258  0.3684      1.0    1.0\n",
      "0.03   1  46   0  14  0.2459  1.0  ...  0.9787  1.0  0.2333  0.3784      1.0    1.0\n",
      "0.04  13  34   0  14  0.4426  1.0  ...  0.7234  1.0  0.2917  0.4516      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  48   0  14   0  0.7742  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  48   0  14   0  0.7742  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  48   0  14   0  0.7742  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  48   0  14   0  0.7742  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  48   0  14   0  0.7742  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage III)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765      1.0    1.0\n",
      "0.01   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765      1.0    1.0\n",
      "0.02   6  49   0   6  0.1967  1.0  ...  0.8909  1.0  0.1091  0.1967      1.0    1.0\n",
      "0.03  14  41   0   6  0.3279  1.0  ...  0.7455  1.0  0.1277  0.2264      1.0    1.0\n",
      "0.04  17  38   0   6  0.3770  1.0  ...  0.6909  1.0  0.1364  0.2400      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage IV)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                           \n",
      "0.00   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9206  0.8824\n",
      "0.01   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9206  0.8824\n",
      "0.02   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9206  0.8824\n",
      "0.03   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9206  0.8824\n",
      "0.04   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9206  0.8824\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...     ...\n",
      "0.97  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9206  0.8824\n",
      "0.98  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9206  0.8824\n",
      "0.99  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9206  0.8824\n",
      "1.00  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9206  0.8824\n",
      "1.01  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9206  0.8824\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Saving evaluation results...\n",
      "Reordering labels and samples...\n",
      "Total matched samples: 571\n",
      "N. NaN in input features: 0\n",
      "           mean       std\n",
      "0      0.000000  0.000000\n",
      "1      0.000000  0.000000\n",
      "2      0.000000  0.000000\n",
      "3      0.015589  0.044423\n",
      "4      0.015568  0.044409\n",
      "...         ...       ...\n",
      "18013  0.000055  0.000231\n",
      "18014  0.000000  0.000000\n",
      "18015  0.002367  0.011945\n",
      "18016  0.002302  0.011713\n",
      "18017  0.000000  0.000000\n",
      "\n",
      "[18018 rows x 2 columns]\n",
      "Pre-training using Adam with lr=1e-05...\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.7036 - acc: 0.4901 - val_loss: 0.6880 - val_acc: 0.5207\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6929 - acc: 0.5037 - val_loss: 0.6801 - val_acc: 0.5379\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 18018)]           0         \n",
      "_________________________________________________________________\n",
      "base (Sequential)            (None, 512)               18976256  \n",
      "_________________________________________________________________\n",
      "l2_inter (Sequential)        (None, 10)                21550     \n",
      "_________________________________________________________________\n",
      "l2_integration (Sequential)  (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "l2o (Sequential)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 18,998,051\n",
      "Trainable params: 18,998,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training using Adam with lr=0.001...\n",
      "Epoch 3/1002\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.6839 - acc: 0.5228 - auROC: 0.4530 - val_loss: 0.6317 - val_acc: 0.6690 - val_auROC: 0.5731\n",
      "Epoch 4/1002\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6662 - acc: 0.6624 - auROC: 0.5130 - val_loss: 0.5806 - val_acc: 0.6793 - val_auROC: 0.6494\n",
      "Epoch 5/1002\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6185 - acc: 0.6374 - auROC: 0.5740 - val_loss: 0.5572 - val_acc: 0.7172 - val_auROC: 0.6537\n",
      "Epoch 6/1002\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6136 - acc: 0.6600 - auROC: 0.5690 - val_loss: 0.5369 - val_acc: 0.7379 - val_auROC: 0.7010\n",
      "Epoch 7/1002\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.5915 - acc: 0.6733 - auROC: 0.6038 - val_loss: 0.5145 - val_acc: 0.7655 - val_auROC: 0.7380\n",
      "Epoch 8/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5623 - acc: 0.7138 - auROC: 0.6515 - val_loss: 0.5187 - val_acc: 0.7586 - val_auROC: 0.7201\n",
      "Epoch 9/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5644 - acc: 0.6971 - auROC: 0.6434 - val_loss: 0.5409 - val_acc: 0.7414 - val_auROC: 0.7538\n",
      "Epoch 10/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5685 - acc: 0.7427 - auROC: 0.6777 - val_loss: 0.5319 - val_acc: 0.7379 - val_auROC: 0.7617\n",
      "Epoch 11/1002\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.5597 - acc: 0.7404 - auROC: 0.6896 - val_loss: 0.5140 - val_acc: 0.7655 - val_auROC: 0.7743\n",
      "Epoch 12/1002\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5379 - acc: 0.7442 - auROC: 0.7170 - val_loss: 0.5212 - val_acc: 0.7552 - val_auROC: 0.7350\n",
      "Epoch 13/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5373 - acc: 0.7400 - auROC: 0.7069 - val_loss: 0.5082 - val_acc: 0.7793 - val_auROC: 0.7364\n",
      "Epoch 14/1002\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5260 - acc: 0.7579 - auROC: 0.7102 - val_loss: 0.4933 - val_acc: 0.8000 - val_auROC: 0.7315\n",
      "Epoch 15/1002\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5216 - acc: 0.7618 - auROC: 0.6844 - val_loss: 0.4809 - val_acc: 0.8000 - val_auROC: 0.7746\n",
      "Epoch 16/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5033 - acc: 0.7673 - auROC: 0.7393 - val_loss: 0.4796 - val_acc: 0.7931 - val_auROC: 0.7896\n",
      "Epoch 17/1002\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4939 - acc: 0.7786 - auROC: 0.7744 - val_loss: 0.4745 - val_acc: 0.8138 - val_auROC: 0.7825\n",
      "Epoch 18/1002\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4868 - acc: 0.7887 - auROC: 0.7741 - val_loss: 0.4634 - val_acc: 0.8172 - val_auROC: 0.7704\n",
      "Epoch 19/1002\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4856 - acc: 0.8000 - auROC: 0.7552 - val_loss: 0.4587 - val_acc: 0.8345 - val_auROC: 0.7829\n",
      "Epoch 20/1002\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4781 - acc: 0.8078 - auROC: 0.7694 - val_loss: 0.4516 - val_acc: 0.8276 - val_auROC: 0.7991\n",
      "Epoch 21/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4716 - acc: 0.8058 - auROC: 0.7833 - val_loss: 0.4496 - val_acc: 0.8345 - val_auROC: 0.8006\n",
      "Epoch 22/1002\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4659 - acc: 0.8086 - auROC: 0.7896 - val_loss: 0.4451 - val_acc: 0.8483 - val_auROC: 0.8102\n",
      "Epoch 23/1002\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4600 - acc: 0.8140 - auROC: 0.8033 - val_loss: 0.4429 - val_acc: 0.8448 - val_auROC: 0.8155\n",
      "Epoch 24/1002\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4570 - acc: 0.8168 - auROC: 0.8108 - val_loss: 0.4375 - val_acc: 0.8345 - val_auROC: 0.8234\n",
      "Epoch 25/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4541 - acc: 0.8133 - auROC: 0.8098 - val_loss: 0.4346 - val_acc: 0.8172 - val_auROC: 0.8283\n",
      "Epoch 26/1002\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4507 - acc: 0.8152 - auROC: 0.8158 - val_loss: 0.4330 - val_acc: 0.8172 - val_auROC: 0.8250\n",
      "Epoch 27/1002\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4449 - acc: 0.8214 - auROC: 0.8123 - val_loss: 0.4312 - val_acc: 0.8241 - val_auROC: 0.8257\n",
      "Epoch 28/1002\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4438 - acc: 0.8273 - auROC: 0.8110 - val_loss: 0.4331 - val_acc: 0.8414 - val_auROC: 0.8443\n",
      "Epoch 29/1002\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4413 - acc: 0.8429 - auROC: 0.8366 - val_loss: 0.4230 - val_acc: 0.8586 - val_auROC: 0.8585\n",
      "Epoch 30/1002\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4376 - acc: 0.8405 - auROC: 0.8451 - val_loss: 0.4175 - val_acc: 0.8448 - val_auROC: 0.8473\n",
      "Epoch 31/1002\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4305 - acc: 0.8312 - auROC: 0.8448 - val_loss: 0.4165 - val_acc: 0.8241 - val_auROC: 0.8456\n",
      "Epoch 32/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4267 - acc: 0.8327 - auROC: 0.8430 - val_loss: 0.4196 - val_acc: 0.8517 - val_auROC: 0.8474\n",
      "Epoch 33/1002\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4235 - acc: 0.8511 - auROC: 0.8558 - val_loss: 0.4170 - val_acc: 0.8414 - val_auROC: 0.8492\n",
      "Epoch 34/1002\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4191 - acc: 0.8534 - auROC: 0.8635 - val_loss: 0.4098 - val_acc: 0.8345 - val_auROC: 0.8491\n",
      "Epoch 35/1002\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.4134 - acc: 0.8472 - auROC: 0.8645 - val_loss: 0.4064 - val_acc: 0.8414 - val_auROC: 0.8477\n",
      "Epoch 36/1002\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.4130 - acc: 0.8480 - auROC: 0.8595 - val_loss: 0.3996 - val_acc: 0.8586 - val_auROC: 0.8729\n",
      "Epoch 37/1002\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4082 - acc: 0.8546 - auROC: 0.8741 - val_loss: 0.4018 - val_acc: 0.8448 - val_auROC: 0.8694\n",
      "Epoch 38/1002\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.4063 - acc: 0.8515 - auROC: 0.8751 - val_loss: 0.3976 - val_acc: 0.8448 - val_auROC: 0.8725\n",
      "Epoch 39/1002\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.4019 - acc: 0.8515 - auROC: 0.8776 - val_loss: 0.3972 - val_acc: 0.8483 - val_auROC: 0.8582\n",
      "Epoch 40/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4001 - acc: 0.8530 - auROC: 0.8740 - val_loss: 0.4002 - val_acc: 0.8483 - val_auROC: 0.8620\n",
      "Epoch 41/1002\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3972 - acc: 0.8612 - auROC: 0.8880 - val_loss: 0.4021 - val_acc: 0.8552 - val_auROC: 0.8545\n",
      "Epoch 42/1002\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.3947 - acc: 0.8674 - auROC: 0.8888 - val_loss: 0.3950 - val_acc: 0.8517 - val_auROC: 0.8593\n",
      "Epoch 43/1002\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.3904 - acc: 0.8608 - auROC: 0.8851 - val_loss: 0.3908 - val_acc: 0.8345 - val_auROC: 0.8625\n",
      "Epoch 44/1002\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3915 - acc: 0.8483 - auROC: 0.8749 - val_loss: 0.3905 - val_acc: 0.8517 - val_auROC: 0.8727\n",
      "Epoch 45/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3880 - acc: 0.8639 - auROC: 0.8920 - val_loss: 0.3873 - val_acc: 0.8586 - val_auROC: 0.8823\n",
      "Epoch 46/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3882 - acc: 0.8690 - auROC: 0.8968 - val_loss: 0.3882 - val_acc: 0.8586 - val_auROC: 0.8654\n",
      "Epoch 47/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3839 - acc: 0.8663 - auROC: 0.8969 - val_loss: 0.3857 - val_acc: 0.8414 - val_auROC: 0.8646\n",
      "Epoch 48/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3788 - acc: 0.8569 - auROC: 0.8925 - val_loss: 0.3875 - val_acc: 0.8517 - val_auROC: 0.8635\n",
      "Epoch 49/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3796 - acc: 0.8698 - auROC: 0.8865 - val_loss: 0.3894 - val_acc: 0.8586 - val_auROC: 0.8667\n",
      "Epoch 50/1002\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.3764 - acc: 0.8811 - auROC: 0.8962 - val_loss: 0.3826 - val_acc: 0.8552 - val_auROC: 0.8747\n",
      "Epoch 51/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.3730 - acc: 0.8768 - auROC: 0.8992 - val_loss: 0.3706 - val_acc: 0.8621 - val_auROC: 0.8866\n",
      "Epoch 52/1002\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3707 - acc: 0.8717 - auROC: 0.8988 - val_loss: 0.3661 - val_acc: 0.8690 - val_auROC: 0.8936\n",
      "Epoch 53/1002\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3683 - acc: 0.8784 - auROC: 0.9028 - val_loss: 0.3693 - val_acc: 0.8759 - val_auROC: 0.8962\n",
      "Epoch 54/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3670 - acc: 0.8834 - auROC: 0.9064 - val_loss: 0.3693 - val_acc: 0.8552 - val_auROC: 0.8934\n",
      "Epoch 55/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3619 - acc: 0.8815 - auROC: 0.9113 - val_loss: 0.3689 - val_acc: 0.8448 - val_auROC: 0.8888\n",
      "Epoch 56/1002\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.3613 - acc: 0.8682 - auROC: 0.9060 - val_loss: 0.3625 - val_acc: 0.8586 - val_auROC: 0.8958\n",
      "Epoch 57/1002\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3571 - acc: 0.8869 - auROC: 0.9131 - val_loss: 0.3602 - val_acc: 0.8724 - val_auROC: 0.8992\n",
      "Epoch 58/1002\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3548 - acc: 0.8955 - auROC: 0.9159 - val_loss: 0.3562 - val_acc: 0.8759 - val_auROC: 0.9054\n",
      "Epoch 59/1002\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.3532 - acc: 0.8959 - auROC: 0.9170 - val_loss: 0.3517 - val_acc: 0.8724 - val_auROC: 0.9106\n",
      "Epoch 60/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3496 - acc: 0.8912 - auROC: 0.9183 - val_loss: 0.3525 - val_acc: 0.8621 - val_auROC: 0.9067\n",
      "Epoch 61/1002\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.3479 - acc: 0.8865 - auROC: 0.9181 - val_loss: 0.3505 - val_acc: 0.8690 - val_auROC: 0.9070\n",
      "Epoch 62/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.3437 - acc: 0.8889 - auROC: 0.9249 - val_loss: 0.3480 - val_acc: 0.8759 - val_auROC: 0.9079\n",
      "Epoch 63/1002\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3420 - acc: 0.8912 - auROC: 0.9259 - val_loss: 0.3442 - val_acc: 0.8759 - val_auROC: 0.9108\n",
      "Epoch 64/1002\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3385 - acc: 0.8943 - auROC: 0.9274 - val_loss: 0.3426 - val_acc: 0.8759 - val_auROC: 0.9152\n",
      "Epoch 65/1002\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3357 - acc: 0.8998 - auROC: 0.9294 - val_loss: 0.3425 - val_acc: 0.8793 - val_auROC: 0.9136\n",
      "Epoch 66/1002\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3337 - acc: 0.9033 - auROC: 0.9293 - val_loss: 0.3406 - val_acc: 0.8828 - val_auROC: 0.9137\n",
      "Epoch 67/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.3309 - acc: 0.9053 - auROC: 0.9325 - val_loss: 0.3395 - val_acc: 0.8828 - val_auROC: 0.9154\n",
      "Epoch 68/1002\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.3282 - acc: 0.9057 - auROC: 0.9352 - val_loss: 0.3377 - val_acc: 0.8862 - val_auROC: 0.9157\n",
      "Epoch 69/1002\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.3260 - acc: 0.9072 - auROC: 0.9347 - val_loss: 0.3357 - val_acc: 0.8897 - val_auROC: 0.9180\n",
      "Epoch 70/1002\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.3230 - acc: 0.9092 - auROC: 0.9356 - val_loss: 0.3326 - val_acc: 0.8828 - val_auROC: 0.9211\n",
      "Epoch 71/1002\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.3217 - acc: 0.9084 - auROC: 0.9357 - val_loss: 0.3318 - val_acc: 0.8862 - val_auROC: 0.9208\n",
      "Epoch 72/1002\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.3181 - acc: 0.9119 - auROC: 0.9394 - val_loss: 0.3295 - val_acc: 0.8897 - val_auROC: 0.9222\n",
      "Epoch 73/1002\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3164 - acc: 0.9123 - auROC: 0.9409 - val_loss: 0.3290 - val_acc: 0.8897 - val_auROC: 0.9213\n",
      "Epoch 74/1002\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3148 - acc: 0.9135 - auROC: 0.9417 - val_loss: 0.3211 - val_acc: 0.8966 - val_auROC: 0.9306\n",
      "Epoch 75/1002\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3121 - acc: 0.9154 - auROC: 0.9430 - val_loss: 0.3174 - val_acc: 0.8966 - val_auROC: 0.9318\n",
      "Epoch 76/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3105 - acc: 0.9170 - auROC: 0.9418 - val_loss: 0.3165 - val_acc: 0.8966 - val_auROC: 0.9330\n",
      "Epoch 77/1002\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3083 - acc: 0.9166 - auROC: 0.9420 - val_loss: 0.3140 - val_acc: 0.9000 - val_auROC: 0.9349\n",
      "Epoch 78/1002\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.3058 - acc: 0.9170 - auROC: 0.9448 - val_loss: 0.3125 - val_acc: 0.9000 - val_auROC: 0.9350\n",
      "Epoch 79/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3038 - acc: 0.9170 - auROC: 0.9469 - val_loss: 0.3129 - val_acc: 0.9000 - val_auROC: 0.9348\n",
      "Epoch 80/1002\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3017 - acc: 0.9166 - auROC: 0.9476 - val_loss: 0.3104 - val_acc: 0.9000 - val_auROC: 0.9349\n",
      "Epoch 81/1002\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2997 - acc: 0.9170 - auROC: 0.9473 - val_loss: 0.3101 - val_acc: 0.9000 - val_auROC: 0.9343\n",
      "Epoch 82/1002\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2976 - acc: 0.9177 - auROC: 0.9487 - val_loss: 0.3097 - val_acc: 0.9000 - val_auROC: 0.9355\n",
      "Epoch 83/1002\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2959 - acc: 0.9220 - auROC: 0.9497 - val_loss: 0.3074 - val_acc: 0.9000 - val_auROC: 0.9364\n",
      "Epoch 84/1002\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2938 - acc: 0.9209 - auROC: 0.9505 - val_loss: 0.3084 - val_acc: 0.9000 - val_auROC: 0.9361\n",
      "Epoch 85/1002\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2930 - acc: 0.9197 - auROC: 0.9499 - val_loss: 0.3070 - val_acc: 0.9000 - val_auROC: 0.9350\n",
      "Epoch 86/1002\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2904 - acc: 0.9228 - auROC: 0.9518 - val_loss: 0.3051 - val_acc: 0.9000 - val_auROC: 0.9362\n",
      "Epoch 87/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2884 - acc: 0.9244 - auROC: 0.9521 - val_loss: 0.3053 - val_acc: 0.9000 - val_auROC: 0.9348\n",
      "Epoch 88/1002\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2878 - acc: 0.9251 - auROC: 0.9519 - val_loss: 0.3024 - val_acc: 0.9000 - val_auROC: 0.9367\n",
      "Epoch 89/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2851 - acc: 0.9267 - auROC: 0.9532 - val_loss: 0.3025 - val_acc: 0.9034 - val_auROC: 0.9356\n",
      "Epoch 90/1002\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2835 - acc: 0.9263 - auROC: 0.9523 - val_loss: 0.3004 - val_acc: 0.9034 - val_auROC: 0.9360\n",
      "Epoch 91/1002\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2833 - acc: 0.9259 - auROC: 0.9489 - val_loss: 0.2965 - val_acc: 0.9034 - val_auROC: 0.9398\n",
      "Epoch 92/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2785 - acc: 0.9294 - auROC: 0.9547 - val_loss: 0.3028 - val_acc: 0.9034 - val_auROC: 0.9360\n",
      "Epoch 93/1002\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2766 - acc: 0.9341 - auROC: 0.9574 - val_loss: 0.2944 - val_acc: 0.9069 - val_auROC: 0.9411\n",
      "Epoch 94/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2768 - acc: 0.9368 - auROC: 0.9548 - val_loss: 0.3046 - val_acc: 0.9000 - val_auROC: 0.9337\n",
      "Epoch 95/1002\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2783 - acc: 0.9341 - auROC: 0.9564 - val_loss: 0.2935 - val_acc: 0.9103 - val_auROC: 0.9408\n",
      "Epoch 96/1002\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2713 - acc: 0.9365 - auROC: 0.9568 - val_loss: 0.2918 - val_acc: 0.9138 - val_auROC: 0.9379\n",
      "Epoch 97/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2772 - acc: 0.9326 - auROC: 0.9476 - val_loss: 0.3138 - val_acc: 0.8966 - val_auROC: 0.9254\n",
      "Epoch 98/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2829 - acc: 0.9333 - auROC: 0.9509 - val_loss: 0.3007 - val_acc: 0.9138 - val_auROC: 0.9300\n",
      "Epoch 99/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2752 - acc: 0.9400 - auROC: 0.9494 - val_loss: 0.2921 - val_acc: 0.9103 - val_auROC: 0.9278\n",
      "Epoch 100/1002\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2708 - acc: 0.9396 - auROC: 0.9518 - val_loss: 0.2893 - val_acc: 0.9138 - val_auROC: 0.9376\n",
      "Epoch 101/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2706 - acc: 0.9368 - auROC: 0.9532 - val_loss: 0.2995 - val_acc: 0.9000 - val_auROC: 0.9337\n",
      "Epoch 102/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2685 - acc: 0.9431 - auROC: 0.9571 - val_loss: 0.3113 - val_acc: 0.8931 - val_auROC: 0.9181\n",
      "Epoch 103/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2749 - acc: 0.9357 - auROC: 0.9497 - val_loss: 0.2964 - val_acc: 0.9069 - val_auROC: 0.9331\n",
      "Epoch 104/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2632 - acc: 0.9439 - auROC: 0.9591 - val_loss: 0.2909 - val_acc: 0.9103 - val_auROC: 0.9300\n",
      "Epoch 105/1002\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2652 - acc: 0.9404 - auROC: 0.9545 - val_loss: 0.2867 - val_acc: 0.9138 - val_auROC: 0.9303\n",
      "Epoch 106/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2592 - acc: 0.9454 - auROC: 0.9567 - val_loss: 0.2913 - val_acc: 0.9172 - val_auROC: 0.9281\n",
      "Epoch 107/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2584 - acc: 0.9454 - auROC: 0.9581 - val_loss: 0.2964 - val_acc: 0.9034 - val_auROC: 0.9258\n",
      "Epoch 108/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2582 - acc: 0.9478 - auROC: 0.9597 - val_loss: 0.2956 - val_acc: 0.9034 - val_auROC: 0.9275\n",
      "Epoch 109/1002\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2576 - acc: 0.9478 - auROC: 0.9593 - val_loss: 0.2829 - val_acc: 0.9172 - val_auROC: 0.9368\n",
      "Epoch 110/1002\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2528 - acc: 0.9489 - auROC: 0.9612 - val_loss: 0.2810 - val_acc: 0.9138 - val_auROC: 0.9329\n",
      "Epoch 111/1002\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2538 - acc: 0.9431 - auROC: 0.9593 - val_loss: 0.2779 - val_acc: 0.9138 - val_auROC: 0.9392\n",
      "Epoch 112/1002\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.2496 - acc: 0.9466 - auROC: 0.9614 - val_loss: 0.2772 - val_acc: 0.9207 - val_auROC: 0.9396\n",
      "Epoch 113/1002\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2491 - acc: 0.9520 - auROC: 0.9623 - val_loss: 0.2803 - val_acc: 0.9172 - val_auROC: 0.9377\n",
      "Epoch 114/1002\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.2489 - acc: 0.9528 - auROC: 0.9621 - val_loss: 0.2764 - val_acc: 0.9138 - val_auROC: 0.9408\n",
      "Epoch 115/1002\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2452 - acc: 0.9536 - auROC: 0.9624 - val_loss: 0.2737 - val_acc: 0.9172 - val_auROC: 0.9368\n",
      "Epoch 116/1002\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2437 - acc: 0.9524 - auROC: 0.9615 - val_loss: 0.2715 - val_acc: 0.9207 - val_auROC: 0.9379\n",
      "Epoch 117/1002\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2423 - acc: 0.9528 - auROC: 0.9614 - val_loss: 0.2745 - val_acc: 0.9138 - val_auROC: 0.9411\n",
      "Epoch 118/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2412 - acc: 0.9513 - auROC: 0.9633 - val_loss: 0.2791 - val_acc: 0.9138 - val_auROC: 0.9322\n",
      "Epoch 119/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2400 - acc: 0.9532 - auROC: 0.9637 - val_loss: 0.2781 - val_acc: 0.9172 - val_auROC: 0.9294\n",
      "Epoch 120/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2383 - acc: 0.9540 - auROC: 0.9638 - val_loss: 0.2725 - val_acc: 0.9207 - val_auROC: 0.9326\n",
      "Epoch 121/1002\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2369 - acc: 0.9536 - auROC: 0.9637 - val_loss: 0.2684 - val_acc: 0.9241 - val_auROC: 0.9368\n",
      "Epoch 122/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2354 - acc: 0.9548 - auROC: 0.9644 - val_loss: 0.2686 - val_acc: 0.9241 - val_auROC: 0.9364\n",
      "Epoch 123/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2341 - acc: 0.9548 - auROC: 0.9650 - val_loss: 0.2714 - val_acc: 0.9241 - val_auROC: 0.9276\n",
      "Epoch 124/1002\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2328 - acc: 0.9544 - auROC: 0.9652 - val_loss: 0.2729 - val_acc: 0.9241 - val_auROC: 0.9276\n",
      "Epoch 125/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2316 - acc: 0.9544 - auROC: 0.9648 - val_loss: 0.2707 - val_acc: 0.9276 - val_auROC: 0.9286\n",
      "Epoch 126/1002\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2305 - acc: 0.9563 - auROC: 0.9653 - val_loss: 0.2673 - val_acc: 0.9241 - val_auROC: 0.9308\n",
      "Epoch 127/1002\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2289 - acc: 0.9559 - auROC: 0.9666 - val_loss: 0.2637 - val_acc: 0.9276 - val_auROC: 0.9334\n",
      "Epoch 128/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2290 - acc: 0.9552 - auROC: 0.9665 - val_loss: 0.2677 - val_acc: 0.9241 - val_auROC: 0.9306\n",
      "Epoch 129/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2273 - acc: 0.9556 - auROC: 0.9656 - val_loss: 0.2694 - val_acc: 0.9276 - val_auROC: 0.9337\n",
      "Epoch 130/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2262 - acc: 0.9595 - auROC: 0.9669 - val_loss: 0.2647 - val_acc: 0.9241 - val_auROC: 0.9370\n",
      "Epoch 131/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2246 - acc: 0.9567 - auROC: 0.9676 - val_loss: 0.2568 - val_acc: 0.9310 - val_auROC: 0.9415\n",
      "Epoch 132/1002\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2236 - acc: 0.9583 - auROC: 0.9669 - val_loss: 0.2554 - val_acc: 0.9310 - val_auROC: 0.9403\n",
      "Epoch 133/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2229 - acc: 0.9583 - auROC: 0.9663 - val_loss: 0.2567 - val_acc: 0.9276 - val_auROC: 0.9392\n",
      "Epoch 134/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2217 - acc: 0.9583 - auROC: 0.9669 - val_loss: 0.2590 - val_acc: 0.9276 - val_auROC: 0.9376\n",
      "Epoch 135/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2205 - acc: 0.9579 - auROC: 0.9676 - val_loss: 0.2589 - val_acc: 0.9276 - val_auROC: 0.9366\n",
      "Epoch 136/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2196 - acc: 0.9579 - auROC: 0.9677 - val_loss: 0.2566 - val_acc: 0.9276 - val_auROC: 0.9363\n",
      "Epoch 137/1002\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2186 - acc: 0.9583 - auROC: 0.9673 - val_loss: 0.2531 - val_acc: 0.9276 - val_auROC: 0.9376\n",
      "Epoch 138/1002\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2174 - acc: 0.9583 - auROC: 0.9677 - val_loss: 0.2509 - val_acc: 0.9345 - val_auROC: 0.9389\n",
      "Epoch 139/1002\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2168 - acc: 0.9579 - auROC: 0.9679 - val_loss: 0.2506 - val_acc: 0.9310 - val_auROC: 0.9379\n",
      "Epoch 140/1002\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2161 - acc: 0.9579 - auROC: 0.9677 - val_loss: 0.2502 - val_acc: 0.9310 - val_auROC: 0.9376\n",
      "Epoch 141/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2151 - acc: 0.9579 - auROC: 0.9678 - val_loss: 0.2503 - val_acc: 0.9310 - val_auROC: 0.9380\n",
      "Epoch 142/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2143 - acc: 0.9579 - auROC: 0.9677 - val_loss: 0.2507 - val_acc: 0.9310 - val_auROC: 0.9373\n",
      "Epoch 143/1002\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2136 - acc: 0.9579 - auROC: 0.9679 - val_loss: 0.2500 - val_acc: 0.9310 - val_auROC: 0.9376\n",
      "Epoch 144/1002\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2127 - acc: 0.9587 - auROC: 0.9680 - val_loss: 0.2463 - val_acc: 0.9379 - val_auROC: 0.9387\n",
      "Epoch 145/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2113 - acc: 0.9598 - auROC: 0.9684 - val_loss: 0.2434 - val_acc: 0.9379 - val_auROC: 0.9401\n",
      "Epoch 146/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2105 - acc: 0.9606 - auROC: 0.9684 - val_loss: 0.2437 - val_acc: 0.9345 - val_auROC: 0.9375\n",
      "Epoch 147/1002\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2090 - acc: 0.9614 - auROC: 0.9688 - val_loss: 0.2419 - val_acc: 0.9379 - val_auROC: 0.9393\n",
      "Epoch 148/1002\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2081 - acc: 0.9641 - auROC: 0.9687 - val_loss: 0.2423 - val_acc: 0.9345 - val_auROC: 0.9392\n",
      "Epoch 149/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2087 - acc: 0.9622 - auROC: 0.9683 - val_loss: 0.2474 - val_acc: 0.9310 - val_auROC: 0.9391\n",
      "Epoch 150/1002\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2100 - acc: 0.9626 - auROC: 0.9686 - val_loss: 0.2413 - val_acc: 0.9345 - val_auROC: 0.9390\n",
      "Epoch 151/1002\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2059 - acc: 0.9645 - auROC: 0.9686 - val_loss: 0.2433 - val_acc: 0.9345 - val_auROC: 0.9376\n",
      "Epoch 152/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2076 - acc: 0.9618 - auROC: 0.9673 - val_loss: 0.2494 - val_acc: 0.9310 - val_auROC: 0.9307\n",
      "Epoch 153/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2095 - acc: 0.9579 - auROC: 0.9673 - val_loss: 0.2428 - val_acc: 0.9345 - val_auROC: 0.9378\n",
      "Epoch 154/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2054 - acc: 0.9614 - auROC: 0.9683 - val_loss: 0.2493 - val_acc: 0.9241 - val_auROC: 0.9296\n",
      "Epoch 155/1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2084 - acc: 0.9610 - auROC: 0.9651\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2084 - acc: 0.9610 - auROC: 0.9651 - val_loss: 0.2462 - val_acc: 0.9310 - val_auROC: 0.9385\n",
      "Epoch 156/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2074 - acc: 0.9630 - auROC: 0.9676 - val_loss: 0.2462 - val_acc: 0.9310 - val_auROC: 0.9386\n",
      "Epoch 157/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2075 - acc: 0.9630 - auROC: 0.9677 - val_loss: 0.2450 - val_acc: 0.9345 - val_auROC: 0.9389\n",
      "Epoch 158/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2061 - acc: 0.9634 - auROC: 0.9682 - val_loss: 0.2430 - val_acc: 0.9345 - val_auROC: 0.9421\n",
      "Epoch 159/1002\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2051 - acc: 0.9641 - auROC: 0.9682 - val_loss: 0.2412 - val_acc: 0.9345 - val_auROC: 0.9429\n",
      "Epoch 160/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2046 - acc: 0.9641 - auROC: 0.9683 - val_loss: 0.2401 - val_acc: 0.9345 - val_auROC: 0.9430\n",
      "Epoch 161/1002\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2045 - acc: 0.9637 - auROC: 0.9678 - val_loss: 0.2394 - val_acc: 0.9310 - val_auROC: 0.9431\n",
      "Epoch 162/1002\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2046 - acc: 0.9637 - auROC: 0.9672 - val_loss: 0.2387 - val_acc: 0.9310 - val_auROC: 0.9432\n",
      "Epoch 163/1002\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2046 - acc: 0.9637 - auROC: 0.9671 - val_loss: 0.2379 - val_acc: 0.9345 - val_auROC: 0.9439\n",
      "Epoch 164/1002\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2045 - acc: 0.9641 - auROC: 0.9671 - val_loss: 0.2372 - val_acc: 0.9379 - val_auROC: 0.9443\n",
      "Epoch 165/1002\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2040 - acc: 0.9645 - auROC: 0.9673 - val_loss: 0.2365 - val_acc: 0.9379 - val_auROC: 0.9452\n",
      "Epoch 166/1002\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2033 - acc: 0.9653 - auROC: 0.9680 - val_loss: 0.2360 - val_acc: 0.9379 - val_auROC: 0.9453\n",
      "Epoch 167/1002\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2030 - acc: 0.9653 - auROC: 0.9683 - val_loss: 0.2357 - val_acc: 0.9379 - val_auROC: 0.9461\n",
      "Epoch 168/1002\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2028 - acc: 0.9653 - auROC: 0.9685 - val_loss: 0.2356 - val_acc: 0.9379 - val_auROC: 0.9472\n",
      "Epoch 169/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2026 - acc: 0.9653 - auROC: 0.9686 - val_loss: 0.2356 - val_acc: 0.9379 - val_auROC: 0.9472\n",
      "Epoch 170/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2024 - acc: 0.9653 - auROC: 0.9689 - val_loss: 0.2358 - val_acc: 0.9345 - val_auROC: 0.9470\n",
      "Epoch 171/1002\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2019 - acc: 0.9634 - auROC: 0.9698 - val_loss: 0.2360 - val_acc: 0.9345 - val_auROC: 0.9470\n",
      "Epoch 172/1002\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2018 - acc: 0.9630 - auROC: 0.9698 - val_loss: 0.2361 - val_acc: 0.9345 - val_auROC: 0.9470\n",
      "Epoch 173/1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2018 - acc: 0.9626 - auROC: 0.9698\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2018 - acc: 0.9626 - auROC: 0.9698 - val_loss: 0.2361 - val_acc: 0.9345 - val_auROC: 0.9469\n",
      "Epoch 174/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2017 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2361 - val_acc: 0.9345 - val_auROC: 0.9469\n",
      "Epoch 175/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2017 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2360 - val_acc: 0.9345 - val_auROC: 0.9469\n",
      "Epoch 176/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2017 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2360 - val_acc: 0.9345 - val_auROC: 0.9469\n",
      "Epoch 177/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2017 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2359 - val_acc: 0.9345 - val_auROC: 0.9469\n",
      "Epoch 178/1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2017 - acc: 0.9618 - auROC: 0.9698\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2017 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2359 - val_acc: 0.9345 - val_auROC: 0.9469\n",
      "Epoch 179/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2017 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2358 - val_acc: 0.9345 - val_auROC: 0.9469\n",
      "Epoch 180/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2016 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2357 - val_acc: 0.9345 - val_auROC: 0.9470\n",
      "Epoch 181/1002\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2016 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2357 - val_acc: 0.9345 - val_auROC: 0.9470\n",
      "Epoch 182/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2016 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2356 - val_acc: 0.9345 - val_auROC: 0.9471\n",
      "Epoch 183/1002\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2016 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2355 - val_acc: 0.9345 - val_auROC: 0.9471\n",
      "Epoch 184/1002\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2016 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2354 - val_acc: 0.9379 - val_auROC: 0.9472\n",
      "Epoch 185/1002\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2015 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2353 - val_acc: 0.9379 - val_auROC: 0.9472\n",
      "Epoch 186/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2015 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2353 - val_acc: 0.9379 - val_auROC: 0.9472\n",
      "Epoch 187/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2015 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2352 - val_acc: 0.9379 - val_auROC: 0.9473\n",
      "Epoch 188/1002\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2015 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2351 - val_acc: 0.9379 - val_auROC: 0.9473\n",
      "Epoch 189/1002\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2014 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2350 - val_acc: 0.9379 - val_auROC: 0.9473\n",
      "Epoch 190/1002\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2014 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2350 - val_acc: 0.9379 - val_auROC: 0.9473\n",
      "Epoch 191/1002\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2013 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2349 - val_acc: 0.9379 - val_auROC: 0.9474\n",
      "Epoch 192/1002\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2013 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2348 - val_acc: 0.9379 - val_auROC: 0.9474\n",
      "Epoch 193/1002\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2012 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2348 - val_acc: 0.9379 - val_auROC: 0.9474\n",
      "Epoch 194/1002\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2011 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2347 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 195/1002\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2010 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2347 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 196/1002\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2009 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2347 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 197/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2008 - acc: 0.9618 - auROC: 0.9698 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 198/1002\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2007 - acc: 0.9618 - auROC: 0.9699 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 199/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2007 - acc: 0.9618 - auROC: 0.9699 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9476\n",
      "Epoch 200/1002\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2006 - acc: 0.9618 - auROC: 0.9699 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9477\n",
      "Epoch 201/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2005 - acc: 0.9618 - auROC: 0.9699 - val_loss: 0.2345 - val_acc: 0.9379 - val_auROC: 0.9478\n",
      "Epoch 202/1002\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2005 - acc: 0.9618 - auROC: 0.9699 - val_loss: 0.2345 - val_acc: 0.9379 - val_auROC: 0.9478\n",
      "Epoch 203/1002\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2004 - acc: 0.9618 - auROC: 0.9699 - val_loss: 0.2345 - val_acc: 0.9379 - val_auROC: 0.9477\n",
      "Epoch 204/1002\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2003 - acc: 0.9618 - auROC: 0.9699 - val_loss: 0.2345 - val_acc: 0.9379 - val_auROC: 0.9477\n",
      "Epoch 205/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2003 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2345 - val_acc: 0.9379 - val_auROC: 0.9478\n",
      "Epoch 206/1002\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2002 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2345 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 207/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2001 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2345 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 208/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2001 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2345 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 209/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2001 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 210/1002\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 211/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 212/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 213/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9474\n",
      "Epoch 214/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9474\n",
      "Epoch 215/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9474\n",
      "Epoch 216/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9474\n",
      "Epoch 217/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 218/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9475\n",
      "Epoch 219/1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700Restoring model weights from the end of the best epoch.\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2000 - acc: 0.9618 - auROC: 0.9700 - val_loss: 0.2346 - val_acc: 0.9379 - val_auROC: 0.9476\n",
      "Epoch 00219: early stopping\n",
      "    0      1      2         3      ...  18014     18015     18016  18017\n",
      "0     0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196532    0.0\n",
      "1     0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196532    0.0\n",
      "2     0.0    0.0    0.0 -0.003108  ...    0.0 -0.198135 -0.196532    0.0\n",
      "3     0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196532    0.0\n",
      "4     0.0    0.0    0.0  0.568506  ...    0.0 -0.198135 -0.196532    0.0\n",
      "..    ...    ...    ...       ...  ...    ...       ...       ...    ...\n",
      "59    0.0    0.0    0.0  3.113151  ...    0.0 -0.198135 -0.196532    0.0\n",
      "60    0.0    0.0    0.0 -0.350213  ...    0.0 -0.198135 -0.196532    0.0\n",
      "61    0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196532    0.0\n",
      "62    0.0    0.0    0.0 -0.139348  ...    0.0 -0.198135 -0.196532    0.0\n",
      "63    0.0    0.0    0.0 -0.350680  ...    0.0 -0.198135 -0.196532    0.0\n",
      "\n",
      "[64 rows x 18018 columns]\n",
      "Total NANs in input samples: 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "18013    0\n",
      "18014    0\n",
      "18015    0\n",
      "18016    0\n",
      "18017    0\n",
      "Length: 18018, dtype: int64\n",
      "Reordering labels and prediction result\n",
      "Reordering labels and prediction result for samples\n",
      "Running evaluation...\n",
      "Evaluating biome source: root:CRC (stage 0)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                           \n",
      "0.00   0  61   0   1  0.0161  1.0  ...  1.0  1.0  0.0161  0.0317   0.6917  0.0714\n",
      "0.01   0  61   0   1  0.0161  1.0  ...  1.0  1.0  0.0161  0.0317   0.6917  0.0714\n",
      "0.02   0  61   0   1  0.0161  1.0  ...  1.0  1.0  0.0161  0.0317   0.6917  0.0714\n",
      "0.03   0  61   0   1  0.0161  1.0  ...  1.0  1.0  0.0161  0.0317   0.6917  0.0714\n",
      "0.04   0  60   0   1  0.0164  1.0  ...  1.0  1.0  0.0164  0.0323   0.6917  0.0714\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...     ...\n",
      "0.97  61   0   1   0  0.9839  0.0  ...  0.0  0.0  0.0000     NaN   0.6917  0.0714\n",
      "0.98  61   0   1   0  0.9839  0.0  ...  0.0  0.0  0.0000     NaN   0.6917  0.0714\n",
      "0.99  61   0   1   0  0.9839  0.0  ...  0.0  0.0  0.0000     NaN   0.6917  0.0714\n",
      "1.00  61   0   1   0  0.9839  0.0  ...  0.0  0.0  0.0000     NaN   0.6917  0.0714\n",
      "1.01  61   0   1   0  0.9839  0.0  ...  0.0  0.0  0.0000     NaN   0.6917  0.0714\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage I)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                          \n",
      "0.00   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896      1.0    1.0\n",
      "0.01   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896      1.0    1.0\n",
      "0.02   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896      1.0    1.0\n",
      "0.03   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896      1.0    1.0\n",
      "0.04   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...    ...\n",
      "0.97  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage II)\n",
      "      TN  FP  FN  TP    Acc   Sn  ...  FPR   Rc     Pr      F1  ROC-AUC  F-max\n",
      "t                                 ...                                         \n",
      "0.00   0  54   0   8  0.129  1.0  ...  1.0  1.0  0.129  0.2286      1.0    1.0\n",
      "0.01   0  54   0   8  0.129  1.0  ...  1.0  1.0  0.129  0.2286      1.0    1.0\n",
      "0.02   0  54   0   8  0.129  1.0  ...  1.0  1.0  0.129  0.2286      1.0    1.0\n",
      "0.03   0  54   0   8  0.129  1.0  ...  1.0  1.0  0.129  0.2286      1.0    1.0\n",
      "0.04   0  54   0   8  0.129  1.0  ...  1.0  1.0  0.129  0.2286      1.0    1.0\n",
      "...   ..  ..  ..  ..    ...  ...  ...  ...  ...    ...     ...      ...    ...\n",
      "0.97  54   0   8   0  0.871  0.0  ...  0.0  0.0  0.000     NaN      1.0    1.0\n",
      "0.98  54   0   8   0  0.871  0.0  ...  0.0  0.0  0.000     NaN      1.0    1.0\n",
      "0.99  54   0   8   0  0.871  0.0  ...  0.0  0.0  0.000     NaN      1.0    1.0\n",
      "1.00  54   0   8   0  0.871  0.0  ...  0.0  0.0  0.000     NaN      1.0    1.0\n",
      "1.01  54   0   8   0  0.871  0.0  ...  0.0  0.0  0.000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage III)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                              \n",
      "0.00   0  54   0   8  0.1290  1.0  ...  1.0000  1.0  0.1290  0.2286   0.9542  0.7368\n",
      "0.01   0  54   0   8  0.1290  1.0  ...  1.0000  1.0  0.1290  0.2286   0.9542  0.7368\n",
      "0.02   0  54   0   8  0.1290  1.0  ...  1.0000  1.0  0.1290  0.2286   0.9542  0.7368\n",
      "0.03  21  32   0   8  0.4754  1.0  ...  0.6038  1.0  0.2000  0.3333   0.9542  0.7368\n",
      "0.04  22  31   0   8  0.4918  1.0  ...  0.5849  1.0  0.2051  0.3404   0.9542  0.7368\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...     ...\n",
      "0.97  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN   0.9542  0.7368\n",
      "0.98  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN   0.9542  0.7368\n",
      "0.99  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN   0.9542  0.7368\n",
      "1.00  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN   0.9542  0.7368\n",
      "1.01  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN   0.9542  0.7368\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage IV)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                              \n",
      "0.00   0  35   0  27  0.4355  1.0  ...  1.0000  1.0  0.4355  0.6067   0.9027  0.8936\n",
      "0.01   0  35   0  27  0.4355  1.0  ...  1.0000  1.0  0.4355  0.6067   0.9027  0.8936\n",
      "0.02   2  32   0  26  0.4667  1.0  ...  0.9412  1.0  0.4483  0.6190   0.9027  0.8936\n",
      "0.03   2  32   0  26  0.4667  1.0  ...  0.9412  1.0  0.4483  0.6190   0.9027  0.8936\n",
      "0.04   2  32   0  26  0.4667  1.0  ...  0.9412  1.0  0.4483  0.6190   0.9027  0.8936\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...     ...\n",
      "0.97  35   0  27   0  0.5645  0.0  ...  0.0000  0.0  0.0000     NaN   0.9027  0.8936\n",
      "0.98  35   0  27   0  0.5645  0.0  ...  0.0000  0.0  0.0000     NaN   0.9027  0.8936\n",
      "0.99  35   0  27   0  0.5645  0.0  ...  0.0000  0.0  0.0000     NaN   0.9027  0.8936\n",
      "1.00  35   0  27   0  0.5645  0.0  ...  0.0000  0.0  0.0000     NaN   0.9027  0.8936\n",
      "1.01  35   0  27   0  0.5645  0.0  ...  0.0000  0.0  0.0000     NaN   0.9027  0.8936\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Saving evaluation results...\n",
      "Reordering labels and samples...\n",
      "Total matched samples: 571\n",
      "Total correct samples: 571?571\n",
      "           mean       std\n",
      "0      0.000000  0.000000\n",
      "1      0.000000  0.000000\n",
      "2      0.000000  0.000000\n",
      "3      0.015589  0.044423\n",
      "4      0.015568  0.044409\n",
      "...         ...       ...\n",
      "18013  0.000055  0.000231\n",
      "18014  0.000000  0.000000\n",
      "18015  0.002367  0.011945\n",
      "18016  0.002302  0.011713\n",
      "18017  0.000000  0.000000\n",
      "\n",
      "[18018 rows x 2 columns]\n",
      "Training using optimizer with lr=0.001...\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.6768 - acc: 0.6027 - auROC: 0.4772 - val_loss: 0.6068 - val_acc: 0.6793 - val_auROC: 0.5664\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.5882 - acc: 0.7021 - auROC: 0.5631 - val_loss: 0.5279 - val_acc: 0.7655 - val_auROC: 0.6768\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.5423 - acc: 0.7435 - auROC: 0.6063 - val_loss: 0.5205 - val_acc: 0.7552 - val_auROC: 0.6321\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5183 - acc: 0.7626 - auROC: 0.6424 - val_loss: 0.4965 - val_acc: 0.8172 - val_auROC: 0.6916\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4920 - acc: 0.7813 - auROC: 0.7063 - val_loss: 0.4806 - val_acc: 0.8069 - val_auROC: 0.7137\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4749 - acc: 0.7922 - auROC: 0.7218 - val_loss: 0.4907 - val_acc: 0.7966 - val_auROC: 0.6759\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4588 - acc: 0.8058 - auROC: 0.7541 - val_loss: 0.4603 - val_acc: 0.8138 - val_auROC: 0.7379\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4420 - acc: 0.8172 - auROC: 0.7814 - val_loss: 0.4598 - val_acc: 0.8172 - val_auROC: 0.7341\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4342 - acc: 0.8191 - auROC: 0.7926 - val_loss: 0.4565 - val_acc: 0.8172 - val_auROC: 0.7358\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4315 - acc: 0.8250 - auROC: 0.7912 - val_loss: 0.4426 - val_acc: 0.8241 - val_auROC: 0.7744\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4252 - acc: 0.8187 - auROC: 0.8051 - val_loss: 0.4374 - val_acc: 0.8241 - val_auROC: 0.7782\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.4211 - acc: 0.8187 - auROC: 0.8044 - val_loss: 0.4290 - val_acc: 0.8207 - val_auROC: 0.7841\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4124 - acc: 0.8250 - auROC: 0.8145 - val_loss: 0.4119 - val_acc: 0.8310 - val_auROC: 0.8213\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4091 - acc: 0.8304 - auROC: 0.8133 - val_loss: 0.4249 - val_acc: 0.8172 - val_auROC: 0.7875\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4065 - acc: 0.8343 - auROC: 0.8121 - val_loss: 0.4258 - val_acc: 0.8000 - val_auROC: 0.7834\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4058 - acc: 0.8366 - auROC: 0.8108 - val_loss: 0.4098 - val_acc: 0.8103 - val_auROC: 0.8111\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3940 - acc: 0.8448 - auROC: 0.8290 - val_loss: 0.4063 - val_acc: 0.8069 - val_auROC: 0.8197\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3826 - acc: 0.8491 - auROC: 0.8471 - val_loss: 0.3943 - val_acc: 0.8207 - val_auROC: 0.8344\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3761 - acc: 0.8511 - auROC: 0.8556 - val_loss: 0.3883 - val_acc: 0.8276 - val_auROC: 0.8438\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3734 - acc: 0.8526 - auROC: 0.8564 - val_loss: 0.3848 - val_acc: 0.8379 - val_auROC: 0.8446\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3679 - acc: 0.8530 - auROC: 0.8646 - val_loss: 0.3871 - val_acc: 0.8379 - val_auROC: 0.8343\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3624 - acc: 0.8519 - auROC: 0.8730 - val_loss: 0.3839 - val_acc: 0.8448 - val_auROC: 0.8444\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3641 - acc: 0.8534 - auROC: 0.8731 - val_loss: 0.3991 - val_acc: 0.8379 - val_auROC: 0.8084\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3722 - acc: 0.8495 - auROC: 0.8485 - val_loss: 0.3965 - val_acc: 0.8241 - val_auROC: 0.8188\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3625 - acc: 0.8589 - auROC: 0.8635 - val_loss: 0.3828 - val_acc: 0.8207 - val_auROC: 0.8419\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3528 - acc: 0.8639 - auROC: 0.8795 - val_loss: 0.3645 - val_acc: 0.8379 - val_auROC: 0.8800\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3429 - acc: 0.8694 - auROC: 0.8961 - val_loss: 0.3620 - val_acc: 0.8414 - val_auROC: 0.8741\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3358 - acc: 0.8838 - auROC: 0.8995 - val_loss: 0.3541 - val_acc: 0.8517 - val_auROC: 0.8790\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3272 - acc: 0.8865 - auROC: 0.9072 - val_loss: 0.3636 - val_acc: 0.8379 - val_auROC: 0.8668\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3790 - acc: 0.8635 - auROC: 0.8278 - val_loss: 0.3854 - val_acc: 0.8448 - val_auROC: 0.8224\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3741 - acc: 0.8585 - auROC: 0.8416 - val_loss: 0.3562 - val_acc: 0.8552 - val_auROC: 0.8695\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3567 - acc: 0.8639 - auROC: 0.8669 - val_loss: 0.3394 - val_acc: 0.8655 - val_auROC: 0.8927\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3418 - acc: 0.8772 - auROC: 0.8858 - val_loss: 0.3375 - val_acc: 0.8586 - val_auROC: 0.8957\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3354 - acc: 0.8756 - auROC: 0.8924 - val_loss: 0.3387 - val_acc: 0.8621 - val_auROC: 0.8924\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3227 - acc: 0.8877 - auROC: 0.9061 - val_loss: 0.3344 - val_acc: 0.8690 - val_auROC: 0.8898\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3140 - acc: 0.8908 - auROC: 0.9128 - val_loss: 0.3294 - val_acc: 0.8690 - val_auROC: 0.8919\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3078 - acc: 0.8936 - auROC: 0.9180 - val_loss: 0.3234 - val_acc: 0.8724 - val_auROC: 0.8934\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3053 - acc: 0.8947 - auROC: 0.9192 - val_loss: 0.3248 - val_acc: 0.8828 - val_auROC: 0.8922\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2980 - acc: 0.8986 - auROC: 0.9255 - val_loss: 0.3178 - val_acc: 0.8931 - val_auROC: 0.8978\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2943 - acc: 0.8998 - auROC: 0.9271 - val_loss: 0.3142 - val_acc: 0.8897 - val_auROC: 0.9009\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2895 - acc: 0.9025 - auROC: 0.9302 - val_loss: 0.3128 - val_acc: 0.8897 - val_auROC: 0.9018\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2868 - acc: 0.9018 - auROC: 0.9320 - val_loss: 0.3107 - val_acc: 0.8966 - val_auROC: 0.9032\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2836 - acc: 0.9053 - auROC: 0.9337 - val_loss: 0.3091 - val_acc: 0.8897 - val_auROC: 0.9045\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2799 - acc: 0.9064 - auROC: 0.9371 - val_loss: 0.3037 - val_acc: 0.8966 - val_auROC: 0.9105\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2805 - acc: 0.9072 - auROC: 0.9382 - val_loss: 0.3009 - val_acc: 0.9000 - val_auROC: 0.9112\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2833 - acc: 0.9041 - auROC: 0.9364 - val_loss: 0.3084 - val_acc: 0.8931 - val_auROC: 0.9045\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2853 - acc: 0.9053 - auROC: 0.9292 - val_loss: 0.3099 - val_acc: 0.8966 - val_auROC: 0.9003\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2797 - acc: 0.9076 - auROC: 0.9348 - val_loss: 0.3213 - val_acc: 0.8793 - val_auROC: 0.8867\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2748 - acc: 0.9080 - auROC: 0.9393 - val_loss: 0.3076 - val_acc: 0.8931 - val_auROC: 0.8994\n",
      "Epoch 50/300\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.2718 - acc: 0.9085 - auROC: 0.9425\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2686 - acc: 0.9123 - auROC: 0.9446 - val_loss: 0.3010 - val_acc: 0.9034 - val_auROC: 0.9055\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2679 - acc: 0.9131 - auROC: 0.9457 - val_loss: 0.3029 - val_acc: 0.8966 - val_auROC: 0.9056\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2637 - acc: 0.9142 - auROC: 0.9489 - val_loss: 0.3042 - val_acc: 0.8931 - val_auROC: 0.9043\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2620 - acc: 0.9154 - auROC: 0.9503 - val_loss: 0.3063 - val_acc: 0.8966 - val_auROC: 0.9004\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2602 - acc: 0.9162 - auROC: 0.9516 - val_loss: 0.3067 - val_acc: 0.8931 - val_auROC: 0.8999\n",
      "Epoch 55/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.2586 - acc: 0.9156 - auROC: 0.9526\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2585 - acc: 0.9158 - auROC: 0.9527 - val_loss: 0.3016 - val_acc: 0.9000 - val_auROC: 0.9051\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2573 - acc: 0.9173 - auROC: 0.9539 - val_loss: 0.3013 - val_acc: 0.9000 - val_auROC: 0.9064\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2572 - acc: 0.9173 - auROC: 0.9538 - val_loss: 0.3013 - val_acc: 0.9000 - val_auROC: 0.9059\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2570 - acc: 0.9173 - auROC: 0.9539 - val_loss: 0.3011 - val_acc: 0.9000 - val_auROC: 0.9060\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2569 - acc: 0.9177 - auROC: 0.9540 - val_loss: 0.3006 - val_acc: 0.9000 - val_auROC: 0.9060\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2568 - acc: 0.9177 - auROC: 0.9541 - val_loss: 0.3004 - val_acc: 0.9000 - val_auROC: 0.9063\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.2567 - acc: 0.9177 - auROC: 0.9542 - val_loss: 0.2999 - val_acc: 0.9000 - val_auROC: 0.9068\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2566 - acc: 0.9181 - auROC: 0.9543 - val_loss: 0.2996 - val_acc: 0.9000 - val_auROC: 0.9069\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2565 - acc: 0.9181 - auROC: 0.9544 - val_loss: 0.2995 - val_acc: 0.9000 - val_auROC: 0.9070\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2563 - acc: 0.9181 - auROC: 0.9545 - val_loss: 0.2993 - val_acc: 0.9000 - val_auROC: 0.9071\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2562 - acc: 0.9185 - auROC: 0.9546 - val_loss: 0.2992 - val_acc: 0.9000 - val_auROC: 0.9071\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2562 - acc: 0.9185 - auROC: 0.9546 - val_loss: 0.2991 - val_acc: 0.9000 - val_auROC: 0.9063\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2560 - acc: 0.9193 - auROC: 0.9547 - val_loss: 0.2990 - val_acc: 0.9000 - val_auROC: 0.9063\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2559 - acc: 0.9193 - auROC: 0.9547 - val_loss: 0.2989 - val_acc: 0.9000 - val_auROC: 0.9063\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2559 - acc: 0.9193 - auROC: 0.9547 - val_loss: 0.2990 - val_acc: 0.9000 - val_auROC: 0.9063\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2557 - acc: 0.9197 - auROC: 0.9548 - val_loss: 0.2987 - val_acc: 0.8966 - val_auROC: 0.9062\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2556 - acc: 0.9197 - auROC: 0.9550 - val_loss: 0.2986 - val_acc: 0.8966 - val_auROC: 0.9064\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2555 - acc: 0.9201 - auROC: 0.9550 - val_loss: 0.2984 - val_acc: 0.8966 - val_auROC: 0.9067\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2554 - acc: 0.9201 - auROC: 0.9552 - val_loss: 0.2984 - val_acc: 0.9000 - val_auROC: 0.9072\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2553 - acc: 0.9201 - auROC: 0.9554 - val_loss: 0.2983 - val_acc: 0.9000 - val_auROC: 0.9073\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2552 - acc: 0.9201 - auROC: 0.9554 - val_loss: 0.2982 - val_acc: 0.9000 - val_auROC: 0.9073\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2551 - acc: 0.9201 - auROC: 0.9555 - val_loss: 0.2981 - val_acc: 0.9000 - val_auROC: 0.9072\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2550 - acc: 0.9201 - auROC: 0.9556 - val_loss: 0.2979 - val_acc: 0.9000 - val_auROC: 0.9073\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.2549 - acc: 0.9201 - auROC: 0.9556 - val_loss: 0.2978 - val_acc: 0.9000 - val_auROC: 0.9073\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2548 - acc: 0.9201 - auROC: 0.9557 - val_loss: 0.2976 - val_acc: 0.9000 - val_auROC: 0.9074\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2547 - acc: 0.9201 - auROC: 0.9559 - val_loss: 0.2975 - val_acc: 0.9000 - val_auROC: 0.9074\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.2546 - acc: 0.9201 - auROC: 0.9559 - val_loss: 0.2974 - val_acc: 0.9000 - val_auROC: 0.9076\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.2545 - acc: 0.9201 - auROC: 0.9560 - val_loss: 0.2973 - val_acc: 0.9000 - val_auROC: 0.9084\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.2545 - acc: 0.9201 - auROC: 0.9560 - val_loss: 0.2972 - val_acc: 0.9000 - val_auROC: 0.9084\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2544 - acc: 0.9201 - auROC: 0.9561 - val_loss: 0.2971 - val_acc: 0.9000 - val_auROC: 0.9083\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2543 - acc: 0.9205 - auROC: 0.9563 - val_loss: 0.2970 - val_acc: 0.9000 - val_auROC: 0.9083\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2542 - acc: 0.9201 - auROC: 0.9564 - val_loss: 0.2974 - val_acc: 0.9000 - val_auROC: 0.9082\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2541 - acc: 0.9201 - auROC: 0.9563 - val_loss: 0.2974 - val_acc: 0.9000 - val_auROC: 0.9083\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2540 - acc: 0.9205 - auROC: 0.9564 - val_loss: 0.2972 - val_acc: 0.9000 - val_auROC: 0.9087\n",
      "Epoch 89/300\n",
      "6/9 [===================>..........] - ETA: 0s - loss: 0.2570 - acc: 0.9156 - auROC: 0.9552\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2539 - acc: 0.9205 - auROC: 0.9565 - val_loss: 0.2970 - val_acc: 0.8966 - val_auROC: 0.9087\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2538 - acc: 0.9209 - auROC: 0.9566 - val_loss: 0.2968 - val_acc: 0.8966 - val_auROC: 0.9089\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2537 - acc: 0.9209 - auROC: 0.9566 - val_loss: 0.2967 - val_acc: 0.8966 - val_auROC: 0.9090\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2536 - acc: 0.9209 - auROC: 0.9567 - val_loss: 0.2967 - val_acc: 0.8966 - val_auROC: 0.9090\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2535 - acc: 0.9209 - auROC: 0.9568 - val_loss: 0.2966 - val_acc: 0.8966 - val_auROC: 0.9091\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2534 - acc: 0.9209 - auROC: 0.9569 - val_loss: 0.2965 - val_acc: 0.8966 - val_auROC: 0.9095\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2533 - acc: 0.9209 - auROC: 0.9570 - val_loss: 0.2963 - val_acc: 0.8966 - val_auROC: 0.9095\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2531 - acc: 0.9209 - auROC: 0.9571 - val_loss: 0.2962 - val_acc: 0.8966 - val_auROC: 0.9095\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.2531 - acc: 0.9209 - auROC: 0.9572 - val_loss: 0.2962 - val_acc: 0.8966 - val_auROC: 0.9096\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.2530 - acc: 0.9205 - auROC: 0.9573 - val_loss: 0.2961 - val_acc: 0.8966 - val_auROC: 0.9097\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.2529 - acc: 0.9205 - auROC: 0.9574 - val_loss: 0.2960 - val_acc: 0.8966 - val_auROC: 0.9099\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2528 - acc: 0.9205 - auROC: 0.9574 - val_loss: 0.2959 - val_acc: 0.8966 - val_auROC: 0.9106\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2527 - acc: 0.9205 - auROC: 0.9575 - val_loss: 0.2958 - val_acc: 0.8966 - val_auROC: 0.9106\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2526 - acc: 0.9205 - auROC: 0.9576 - val_loss: 0.2959 - val_acc: 0.8966 - val_auROC: 0.9102\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2526 - acc: 0.9209 - auROC: 0.9574 - val_loss: 0.2965 - val_acc: 0.8966 - val_auROC: 0.9108\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2527 - acc: 0.9201 - auROC: 0.9573 - val_loss: 0.2965 - val_acc: 0.8966 - val_auROC: 0.9108\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2527 - acc: 0.9201 - auROC: 0.9573 - val_loss: 0.2961 - val_acc: 0.8966 - val_auROC: 0.9120\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2528 - acc: 0.9209 - auROC: 0.9573 - val_loss: 0.2958 - val_acc: 0.8966 - val_auROC: 0.9124\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2527 - acc: 0.9209 - auROC: 0.9574 - val_loss: 0.2954 - val_acc: 0.8966 - val_auROC: 0.9115\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2525 - acc: 0.9209 - auROC: 0.9575 - val_loss: 0.2952 - val_acc: 0.8966 - val_auROC: 0.9115\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2523 - acc: 0.9209 - auROC: 0.9577 - val_loss: 0.2951 - val_acc: 0.8966 - val_auROC: 0.9115\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.2521 - acc: 0.9209 - auROC: 0.9577 - val_loss: 0.2950 - val_acc: 0.8966 - val_auROC: 0.9113\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2520 - acc: 0.9209 - auROC: 0.9578 - val_loss: 0.2949 - val_acc: 0.8966 - val_auROC: 0.9114\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2519 - acc: 0.9209 - auROC: 0.9578 - val_loss: 0.2950 - val_acc: 0.8966 - val_auROC: 0.9115\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2518 - acc: 0.9209 - auROC: 0.9578 - val_loss: 0.2953 - val_acc: 0.8966 - val_auROC: 0.9113\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2517 - acc: 0.9209 - auROC: 0.9580 - val_loss: 0.2955 - val_acc: 0.8966 - val_auROC: 0.9113\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2517 - acc: 0.9209 - auROC: 0.9581 - val_loss: 0.2957 - val_acc: 0.8966 - val_auROC: 0.9112\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2516 - acc: 0.9209 - auROC: 0.9582 - val_loss: 0.2958 - val_acc: 0.8966 - val_auROC: 0.9113\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2515 - acc: 0.9209 - auROC: 0.9582 - val_loss: 0.2957 - val_acc: 0.8966 - val_auROC: 0.9115\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2514 - acc: 0.9212 - auROC: 0.9583 - val_loss: 0.2956 - val_acc: 0.8966 - val_auROC: 0.9115\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2513 - acc: 0.9212 - auROC: 0.9583 - val_loss: 0.2956 - val_acc: 0.8966 - val_auROC: 0.9114\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2513 - acc: 0.9216 - auROC: 0.9584 - val_loss: 0.2956 - val_acc: 0.8966 - val_auROC: 0.9114\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2512 - acc: 0.9216 - auROC: 0.9584 - val_loss: 0.2955 - val_acc: 0.8966 - val_auROC: 0.9115\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2511 - acc: 0.9216 - auROC: 0.9584 - val_loss: 0.2954 - val_acc: 0.8966 - val_auROC: 0.9113\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2511 - acc: 0.9216 - auROC: 0.9584 - val_loss: 0.2954 - val_acc: 0.8966 - val_auROC: 0.9113\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2510 - acc: 0.9216 - auROC: 0.9585 - val_loss: 0.2954 - val_acc: 0.8966 - val_auROC: 0.9112\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2509 - acc: 0.9216 - auROC: 0.9585 - val_loss: 0.2954 - val_acc: 0.8966 - val_auROC: 0.9112\n",
      "Epoch 126/300\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.2451 - acc: 0.9250 - auROC: 0.9622Restoring model weights from the end of the best epoch.\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2508 - acc: 0.9216 - auROC: 0.9585 - val_loss: 0.2954 - val_acc: 0.8966 - val_auROC: 0.9112\n",
      "Epoch 00126: early stopping\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 18018)]           0         \n",
      "_________________________________________________________________\n",
      "base (Sequential)            (None, 512)               18976256  \n",
      "_________________________________________________________________\n",
      "l2_inter (Sequential)        (None, 10)                21550     \n",
      "_________________________________________________________________\n",
      "l2_integration (Sequential)  (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "l2o (Sequential)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 18,998,051\n",
      "Trainable params: 21,795\n",
      "Non-trainable params: 18,976,256\n",
      "_________________________________________________________________\n",
      "Fine-tuning using optimizer with lr=1e-05...\n",
      "Epoch 126/425\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.2519 - acc: 0.9209 - auROC: 0.9578 - val_loss: 0.2948 - val_acc: 0.8966 - val_auROC: 0.9130\n",
      "Epoch 127/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2496 - acc: 0.9236 - auROC: 0.9593 - val_loss: 0.2933 - val_acc: 0.8966 - val_auROC: 0.9158\n",
      "Epoch 128/425\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2482 - acc: 0.9248 - auROC: 0.9602 - val_loss: 0.2928 - val_acc: 0.9000 - val_auROC: 0.9164\n",
      "Epoch 129/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2473 - acc: 0.9248 - auROC: 0.9608 - val_loss: 0.2908 - val_acc: 0.9000 - val_auROC: 0.9180\n",
      "Epoch 130/425\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2470 - acc: 0.9244 - auROC: 0.9611 - val_loss: 0.2901 - val_acc: 0.9000 - val_auROC: 0.9190\n",
      "Epoch 131/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2467 - acc: 0.9255 - auROC: 0.9610 - val_loss: 0.2903 - val_acc: 0.9000 - val_auROC: 0.9188\n",
      "Epoch 132/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2458 - acc: 0.9248 - auROC: 0.9612 - val_loss: 0.2896 - val_acc: 0.9000 - val_auROC: 0.9187\n",
      "Epoch 133/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2451 - acc: 0.9244 - auROC: 0.9617 - val_loss: 0.2882 - val_acc: 0.9000 - val_auROC: 0.9189\n",
      "Epoch 134/425\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2446 - acc: 0.9244 - auROC: 0.9622 - val_loss: 0.2873 - val_acc: 0.9000 - val_auROC: 0.9193\n",
      "Epoch 135/425\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2440 - acc: 0.9248 - auROC: 0.9626 - val_loss: 0.2871 - val_acc: 0.9000 - val_auROC: 0.9195\n",
      "Epoch 136/425\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2436 - acc: 0.9251 - auROC: 0.9629 - val_loss: 0.2870 - val_acc: 0.9000 - val_auROC: 0.9194\n",
      "Epoch 137/425\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2433 - acc: 0.9251 - auROC: 0.9630 - val_loss: 0.2869 - val_acc: 0.9000 - val_auROC: 0.9192\n",
      "Epoch 138/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2428 - acc: 0.9251 - auROC: 0.9632 - val_loss: 0.2868 - val_acc: 0.9000 - val_auROC: 0.9183\n",
      "Epoch 139/425\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2425 - acc: 0.9255 - auROC: 0.9635 - val_loss: 0.2866 - val_acc: 0.9000 - val_auROC: 0.9187\n",
      "Epoch 140/425\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2421 - acc: 0.9251 - auROC: 0.9636 - val_loss: 0.2864 - val_acc: 0.9000 - val_auROC: 0.9203\n",
      "Epoch 141/425\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2419 - acc: 0.9251 - auROC: 0.9639 - val_loss: 0.2865 - val_acc: 0.9000 - val_auROC: 0.9203\n",
      "Epoch 142/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2417 - acc: 0.9255 - auROC: 0.9640 - val_loss: 0.2864 - val_acc: 0.9000 - val_auROC: 0.9203\n",
      "Epoch 143/425\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.2411 - acc: 0.9251 - auROC: 0.9644 - val_loss: 0.2860 - val_acc: 0.9000 - val_auROC: 0.9204\n",
      "Epoch 144/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2406 - acc: 0.9255 - auROC: 0.9646 - val_loss: 0.2860 - val_acc: 0.9000 - val_auROC: 0.9202\n",
      "Epoch 145/425\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2402 - acc: 0.9267 - auROC: 0.9647 - val_loss: 0.2859 - val_acc: 0.9034 - val_auROC: 0.9201\n",
      "Epoch 146/425\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2402 - acc: 0.9263 - auROC: 0.9648 - val_loss: 0.2853 - val_acc: 0.9034 - val_auROC: 0.9205\n",
      "Epoch 147/425\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2395 - acc: 0.9267 - auROC: 0.9651 - val_loss: 0.2848 - val_acc: 0.9034 - val_auROC: 0.9207\n",
      "Epoch 148/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2392 - acc: 0.9263 - auROC: 0.9654 - val_loss: 0.2839 - val_acc: 0.9034 - val_auROC: 0.9210\n",
      "Epoch 149/425\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2389 - acc: 0.9267 - auROC: 0.9656 - val_loss: 0.2838 - val_acc: 0.9034 - val_auROC: 0.9209\n",
      "Epoch 150/425\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2384 - acc: 0.9271 - auROC: 0.9658 - val_loss: 0.2839 - val_acc: 0.9034 - val_auROC: 0.9207\n",
      "Epoch 151/425\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2381 - acc: 0.9275 - auROC: 0.9660 - val_loss: 0.2838 - val_acc: 0.9034 - val_auROC: 0.9212\n",
      "Epoch 152/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2377 - acc: 0.9283 - auROC: 0.9661 - val_loss: 0.2834 - val_acc: 0.9034 - val_auROC: 0.9213\n",
      "Epoch 153/425\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2374 - acc: 0.9290 - auROC: 0.9662 - val_loss: 0.2827 - val_acc: 0.9034 - val_auROC: 0.9217\n",
      "Epoch 154/425\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.2369 - acc: 0.9290 - auROC: 0.9663 - val_loss: 0.2825 - val_acc: 0.9034 - val_auROC: 0.9219\n",
      "Epoch 155/425\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2364 - acc: 0.9302 - auROC: 0.9664 - val_loss: 0.2843 - val_acc: 0.9000 - val_auROC: 0.9207\n",
      "Epoch 156/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2369 - acc: 0.9290 - auROC: 0.9660 - val_loss: 0.2891 - val_acc: 0.8931 - val_auROC: 0.9170\n",
      "Epoch 157/425\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2375 - acc: 0.9290 - auROC: 0.9654 - val_loss: 0.2880 - val_acc: 0.8931 - val_auROC: 0.9175\n",
      "Epoch 158/425\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2366 - acc: 0.9290 - auROC: 0.9660 - val_loss: 0.2859 - val_acc: 0.8966 - val_auROC: 0.9183\n",
      "Epoch 159/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2358 - acc: 0.9294 - auROC: 0.9664 - val_loss: 0.2847 - val_acc: 0.9034 - val_auROC: 0.9189\n",
      "Epoch 160/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2356 - acc: 0.9302 - auROC: 0.9665 - val_loss: 0.2838 - val_acc: 0.9034 - val_auROC: 0.9194\n",
      "Epoch 161/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2356 - acc: 0.9298 - auROC: 0.9663 - val_loss: 0.2833 - val_acc: 0.9034 - val_auROC: 0.9187\n",
      "Epoch 162/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2355 - acc: 0.9306 - auROC: 0.9663 - val_loss: 0.2841 - val_acc: 0.9034 - val_auROC: 0.9194\n",
      "Epoch 163/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2354 - acc: 0.9306 - auROC: 0.9664 - val_loss: 0.2833 - val_acc: 0.9034 - val_auROC: 0.9204\n",
      "Epoch 164/425\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2348 - acc: 0.9306 - auROC: 0.9666 - val_loss: 0.2822 - val_acc: 0.9069 - val_auROC: 0.9209\n",
      "Epoch 165/425\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2342 - acc: 0.9310 - auROC: 0.9670 - val_loss: 0.2819 - val_acc: 0.9069 - val_auROC: 0.9210\n",
      "Epoch 166/425\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2337 - acc: 0.9314 - auROC: 0.9673 - val_loss: 0.2809 - val_acc: 0.9069 - val_auROC: 0.9209\n",
      "Epoch 167/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2332 - acc: 0.9314 - auROC: 0.9675 - val_loss: 0.2804 - val_acc: 0.9069 - val_auROC: 0.9208\n",
      "Epoch 168/425\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2329 - acc: 0.9318 - auROC: 0.9675 - val_loss: 0.2800 - val_acc: 0.9069 - val_auROC: 0.9212\n",
      "Epoch 169/425\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2326 - acc: 0.9322 - auROC: 0.9677 - val_loss: 0.2801 - val_acc: 0.9069 - val_auROC: 0.9214\n",
      "Epoch 170/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2324 - acc: 0.9322 - auROC: 0.9677 - val_loss: 0.2801 - val_acc: 0.9069 - val_auROC: 0.9213\n",
      "Epoch 171/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2321 - acc: 0.9322 - auROC: 0.9678 - val_loss: 0.2796 - val_acc: 0.9069 - val_auROC: 0.9217\n",
      "Epoch 172/425\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2320 - acc: 0.9322 - auROC: 0.9679 - val_loss: 0.2789 - val_acc: 0.9103 - val_auROC: 0.9223\n",
      "Epoch 173/425\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2319 - acc: 0.9322 - auROC: 0.9679 - val_loss: 0.2793 - val_acc: 0.9103 - val_auROC: 0.9221\n",
      "Epoch 174/425\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2316 - acc: 0.9322 - auROC: 0.9680 - val_loss: 0.2794 - val_acc: 0.9069 - val_auROC: 0.9220\n",
      "Epoch 175/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2314 - acc: 0.9326 - auROC: 0.9680 - val_loss: 0.2793 - val_acc: 0.9069 - val_auROC: 0.9218\n",
      "Epoch 176/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2310 - acc: 0.9326 - auROC: 0.9680 - val_loss: 0.2797 - val_acc: 0.9069 - val_auROC: 0.9213\n",
      "Epoch 177/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2308 - acc: 0.9329 - auROC: 0.9682 - val_loss: 0.2804 - val_acc: 0.9069 - val_auROC: 0.9211\n",
      "Epoch 178/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2305 - acc: 0.9329 - auROC: 0.9682 - val_loss: 0.2803 - val_acc: 0.9069 - val_auROC: 0.9222\n",
      "Epoch 179/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2303 - acc: 0.9326 - auROC: 0.9682 - val_loss: 0.2796 - val_acc: 0.9069 - val_auROC: 0.9222\n",
      "Epoch 180/425\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2302 - acc: 0.9326 - auROC: 0.9683 - val_loss: 0.2790 - val_acc: 0.9069 - val_auROC: 0.9223\n",
      "Epoch 181/425\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2300 - acc: 0.9326 - auROC: 0.9683 - val_loss: 0.2788 - val_acc: 0.9069 - val_auROC: 0.9226\n",
      "Epoch 182/425\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2299 - acc: 0.9326 - auROC: 0.9684 - val_loss: 0.2787 - val_acc: 0.9069 - val_auROC: 0.9230\n",
      "Epoch 183/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2297 - acc: 0.9326 - auROC: 0.9684 - val_loss: 0.2786 - val_acc: 0.9069 - val_auROC: 0.9228\n",
      "Epoch 184/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2297 - acc: 0.9326 - auROC: 0.9684 - val_loss: 0.2787 - val_acc: 0.9069 - val_auROC: 0.9227\n",
      "Epoch 185/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2306 - acc: 0.9318 - auROC: 0.9678 - val_loss: 0.2789 - val_acc: 0.9069 - val_auROC: 0.9221\n",
      "Epoch 186/425\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2311 - acc: 0.9322 - auROC: 0.9675 - val_loss: 0.2785 - val_acc: 0.9103 - val_auROC: 0.9223\n",
      "Epoch 187/425\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2303 - acc: 0.9322 - auROC: 0.9679 - val_loss: 0.2775 - val_acc: 0.9103 - val_auROC: 0.9234\n",
      "Epoch 188/425\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2297 - acc: 0.9326 - auROC: 0.9684 - val_loss: 0.2772 - val_acc: 0.9103 - val_auROC: 0.9227\n",
      "Epoch 189/425\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2295 - acc: 0.9326 - auROC: 0.9684 - val_loss: 0.2770 - val_acc: 0.9069 - val_auROC: 0.9234\n",
      "Epoch 190/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2294 - acc: 0.9326 - auROC: 0.9685 - val_loss: 0.2775 - val_acc: 0.9069 - val_auROC: 0.9229\n",
      "Epoch 191/425\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2298 - acc: 0.9326 - auROC: 0.9684 - val_loss: 0.2777 - val_acc: 0.9069 - val_auROC: 0.9232\n",
      "Epoch 192/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2296 - acc: 0.9326 - auROC: 0.9684 - val_loss: 0.2773 - val_acc: 0.9069 - val_auROC: 0.9238\n",
      "Epoch 193/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2291 - acc: 0.9333 - auROC: 0.9686 - val_loss: 0.2771 - val_acc: 0.9103 - val_auROC: 0.9240\n",
      "Epoch 194/425\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2288 - acc: 0.9333 - auROC: 0.9687 - val_loss: 0.2763 - val_acc: 0.9138 - val_auROC: 0.9242\n",
      "Epoch 195/425\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2284 - acc: 0.9341 - auROC: 0.9689 - val_loss: 0.2749 - val_acc: 0.9138 - val_auROC: 0.9247\n",
      "Epoch 196/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2286 - acc: 0.9337 - auROC: 0.9691 - val_loss: 0.2769 - val_acc: 0.9138 - val_auROC: 0.9229\n",
      "Epoch 197/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2294 - acc: 0.9337 - auROC: 0.9689 - val_loss: 0.2773 - val_acc: 0.9138 - val_auROC: 0.9222\n",
      "Epoch 198/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2289 - acc: 0.9341 - auROC: 0.9690 - val_loss: 0.2765 - val_acc: 0.9103 - val_auROC: 0.9238\n",
      "Epoch 199/425\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2283 - acc: 0.9341 - auROC: 0.9691 - val_loss: 0.2755 - val_acc: 0.9103 - val_auROC: 0.9249\n",
      "Epoch 200/425\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2274 - acc: 0.9349 - auROC: 0.9693 - val_loss: 0.2745 - val_acc: 0.9069 - val_auROC: 0.9253\n",
      "Epoch 201/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2272 - acc: 0.9349 - auROC: 0.9694 - val_loss: 0.2739 - val_acc: 0.9103 - val_auROC: 0.9262\n",
      "Epoch 202/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2270 - acc: 0.9353 - auROC: 0.9694 - val_loss: 0.2734 - val_acc: 0.9103 - val_auROC: 0.9261\n",
      "Epoch 203/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2268 - acc: 0.9353 - auROC: 0.9695 - val_loss: 0.2739 - val_acc: 0.9103 - val_auROC: 0.9258\n",
      "Epoch 204/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2267 - acc: 0.9353 - auROC: 0.9695 - val_loss: 0.2736 - val_acc: 0.9103 - val_auROC: 0.9257\n",
      "Epoch 205/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2270 - acc: 0.9353 - auROC: 0.9693 - val_loss: 0.2770 - val_acc: 0.9138 - val_auROC: 0.9241\n",
      "Epoch 206/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2276 - acc: 0.9353 - auROC: 0.9691 - val_loss: 0.2758 - val_acc: 0.9138 - val_auROC: 0.9242\n",
      "Epoch 207/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2269 - acc: 0.9353 - auROC: 0.9694 - val_loss: 0.2739 - val_acc: 0.9138 - val_auROC: 0.9259\n",
      "Epoch 208/425\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2264 - acc: 0.9353 - auROC: 0.9694 - val_loss: 0.2733 - val_acc: 0.9138 - val_auROC: 0.9264\n",
      "Epoch 209/425\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2263 - acc: 0.9353 - auROC: 0.9695 - val_loss: 0.2725 - val_acc: 0.9138 - val_auROC: 0.9266\n",
      "Epoch 210/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2263 - acc: 0.9353 - auROC: 0.9694 - val_loss: 0.2704 - val_acc: 0.9172 - val_auROC: 0.9278\n",
      "Epoch 211/425\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2265 - acc: 0.9353 - auROC: 0.9692 - val_loss: 0.2701 - val_acc: 0.9172 - val_auROC: 0.9278\n",
      "Epoch 212/425\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2270 - acc: 0.9349 - auROC: 0.9686 - val_loss: 0.2692 - val_acc: 0.9172 - val_auROC: 0.9288\n",
      "Epoch 213/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2269 - acc: 0.9353 - auROC: 0.9687 - val_loss: 0.2694 - val_acc: 0.9172 - val_auROC: 0.9284\n",
      "Epoch 214/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2261 - acc: 0.9357 - auROC: 0.9693 - val_loss: 0.2704 - val_acc: 0.9172 - val_auROC: 0.9276\n",
      "Epoch 215/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2259 - acc: 0.9357 - auROC: 0.9694 - val_loss: 0.2712 - val_acc: 0.9138 - val_auROC: 0.9269\n",
      "Epoch 216/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2256 - acc: 0.9361 - auROC: 0.9695 - val_loss: 0.2717 - val_acc: 0.9103 - val_auROC: 0.9269\n",
      "Epoch 217/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2254 - acc: 0.9361 - auROC: 0.9695 - val_loss: 0.2719 - val_acc: 0.9103 - val_auROC: 0.9271\n",
      "Epoch 218/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2253 - acc: 0.9361 - auROC: 0.9696 - val_loss: 0.2717 - val_acc: 0.9103 - val_auROC: 0.9271\n",
      "Epoch 219/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2251 - acc: 0.9361 - auROC: 0.9695 - val_loss: 0.2716 - val_acc: 0.9103 - val_auROC: 0.9272\n",
      "Epoch 220/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2250 - acc: 0.9361 - auROC: 0.9696 - val_loss: 0.2713 - val_acc: 0.9103 - val_auROC: 0.9272\n",
      "Epoch 221/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2249 - acc: 0.9361 - auROC: 0.9695 - val_loss: 0.2712 - val_acc: 0.9103 - val_auROC: 0.9278\n",
      "Epoch 222/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2248 - acc: 0.9361 - auROC: 0.9695 - val_loss: 0.2710 - val_acc: 0.9138 - val_auROC: 0.9277\n",
      "Epoch 223/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2248 - acc: 0.9361 - auROC: 0.9695 - val_loss: 0.2708 - val_acc: 0.9138 - val_auROC: 0.9284\n",
      "Epoch 224/425\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2247 - acc: 0.9361 - auROC: 0.9696 - val_loss: 0.2707 - val_acc: 0.9138 - val_auROC: 0.9284\n",
      "Epoch 225/425\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2246 - acc: 0.9361 - auROC: 0.9696 - val_loss: 0.2706 - val_acc: 0.9138 - val_auROC: 0.9285\n",
      "Epoch 226/425\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2245 - acc: 0.9361 - auROC: 0.9696 - val_loss: 0.2705 - val_acc: 0.9138 - val_auROC: 0.9280\n",
      "Epoch 227/425\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2244 - acc: 0.9361 - auROC: 0.9696Restoring model weights from the end of the best epoch.\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2244 - acc: 0.9361 - auROC: 0.9696 - val_loss: 0.2703 - val_acc: 0.9138 - val_auROC: 0.9280\n",
      "Epoch 00227: early stopping\n",
      "    0      1      2         3      ...  18014     18015     18016  18017\n",
      "0     0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196531    0.0\n",
      "1     0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196531    0.0\n",
      "2     0.0    0.0    0.0 -0.003108  ...    0.0 -0.198135 -0.196531    0.0\n",
      "3     0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196531    0.0\n",
      "4     0.0    0.0    0.0  0.568506  ...    0.0 -0.198135 -0.196531    0.0\n",
      "..    ...    ...    ...       ...  ...    ...       ...       ...    ...\n",
      "59    0.0    0.0    0.0  3.113152  ...    0.0 -0.198135 -0.196531    0.0\n",
      "60    0.0    0.0    0.0 -0.350213  ...    0.0 -0.198135 -0.196531    0.0\n",
      "61    0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196531    0.0\n",
      "62    0.0    0.0    0.0 -0.139348  ...    0.0 -0.198135 -0.196531    0.0\n",
      "63    0.0    0.0    0.0 -0.350679  ...    0.0 -0.198135 -0.196531    0.0\n",
      "\n",
      "[64 rows x 18018 columns]\n",
      "Total NANs in input samples: 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "18013    0\n",
      "18014    0\n",
      "18015    0\n",
      "18016    0\n",
      "18017    0\n",
      "Length: 18018, dtype: int64\n",
      "Reordering labels and prediction result\n",
      "Reordering labels and prediction result for samples\n",
      "Running evaluation...\n",
      "Evaluating biome source: root:CRC (stage 0)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  61   0   1  0.0161  1.0  ...  1.0000  1.0  0.0161  0.0317      1.0    1.0\n",
      "0.01   0  61   0   1  0.0161  1.0  ...  1.0000  1.0  0.0161  0.0317      1.0    1.0\n",
      "0.02   4  56   0   1  0.0820  1.0  ...  0.9333  1.0  0.0175  0.0345      1.0    1.0\n",
      "0.03  22  38   0   1  0.3770  1.0  ...  0.6333  1.0  0.0256  0.0500      1.0    1.0\n",
      "0.04  41  19   0   1  0.6885  1.0  ...  0.3167  1.0  0.0500  0.0952      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  61   0   1   0  0.9839  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  61   0   1   0  0.9839  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  61   0   1   0  0.9839  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  61   0   1   0  0.9839  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  61   0   1   0  0.9839  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage I)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                           \n",
      "0.00   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896   0.9837  0.9333\n",
      "0.01   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896   0.9837  0.9333\n",
      "0.02   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896   0.9837  0.9333\n",
      "0.03   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896   0.9837  0.9333\n",
      "0.04   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896   0.9837  0.9333\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...     ...\n",
      "0.97  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN   0.9837  0.9333\n",
      "0.98  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN   0.9837  0.9333\n",
      "0.99  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN   0.9837  0.9333\n",
      "1.00  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN   0.9837  0.9333\n",
      "1.01  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN   0.9837  0.9333\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage II)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  54   0   8  0.1290  1.0  ...  1.0000  1.0  0.1290  0.2286      1.0    1.0\n",
      "0.01   0  54   0   8  0.1290  1.0  ...  1.0000  1.0  0.1290  0.2286      1.0    1.0\n",
      "0.02   0  53   0   8  0.1311  1.0  ...  1.0000  1.0  0.1311  0.2319      1.0    1.0\n",
      "0.03   1  52   0   8  0.1475  1.0  ...  0.9811  1.0  0.1333  0.2353      1.0    1.0\n",
      "0.04  15  38   0   8  0.3770  1.0  ...  0.7170  1.0  0.1739  0.2963      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage III)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                              \n",
      "0.00   0  54   0   8  0.1290  1.0  ...  1.0000  1.0  0.1290  0.2286   0.8396  0.7273\n",
      "0.01   0  54   0   8  0.1290  1.0  ...  1.0000  1.0  0.1290  0.2286   0.8396  0.7273\n",
      "0.02   0  54   0   8  0.1290  1.0  ...  1.0000  1.0  0.1290  0.2286   0.8396  0.7273\n",
      "0.03   2  51   0   8  0.1639  1.0  ...  0.9623  1.0  0.1356  0.2388   0.8396  0.7273\n",
      "0.04   5  48   0   8  0.2131  1.0  ...  0.9057  1.0  0.1429  0.2500   0.8396  0.7273\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...     ...\n",
      "0.97  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN   0.8396  0.7273\n",
      "0.98  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN   0.8396  0.7273\n",
      "0.99  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN   0.8396  0.7273\n",
      "1.00  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN   0.8396  0.7273\n",
      "1.01  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN   0.8396  0.7273\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage IV)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                              \n",
      "0.00   0  35   0  27  0.4355  1.0  ...  1.0000  1.0  0.4355  0.6067   0.9926  0.9818\n",
      "0.01   0  35   0  27  0.4355  1.0  ...  1.0000  1.0  0.4355  0.6067   0.9926  0.9818\n",
      "0.02   0  35   0  27  0.4355  1.0  ...  1.0000  1.0  0.4355  0.6067   0.9926  0.9818\n",
      "0.03   0  34   0  27  0.4426  1.0  ...  1.0000  1.0  0.4426  0.6136   0.9926  0.9818\n",
      "0.04   1  33   0  27  0.4590  1.0  ...  0.9706  1.0  0.4500  0.6207   0.9926  0.9818\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...     ...\n",
      "0.97  35   0  27   0  0.5645  0.0  ...  0.0000  0.0  0.0000     NaN   0.9926  0.9818\n",
      "0.98  35   0  27   0  0.5645  0.0  ...  0.0000  0.0  0.0000     NaN   0.9926  0.9818\n",
      "0.99  35   0  27   0  0.5645  0.0  ...  0.0000  0.0  0.0000     NaN   0.9926  0.9818\n",
      "1.00  35   0  27   0  0.5645  0.0  ...  0.0000  0.0  0.0000     NaN   0.9926  0.9818\n",
      "1.01  35   0  27   0  0.5645  0.0  ...  0.0000  0.0  0.0000     NaN   0.9926  0.9818\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Saving evaluation results...\n",
      "Reordering labels and samples...\n",
      "Total matched samples: 571\n",
      "Total correct samples: 571?571\n",
      "           mean       std\n",
      "0      0.000000  0.000000\n",
      "1      0.000000  0.000000\n",
      "2      0.000000  0.000000\n",
      "3      0.015589  0.044423\n",
      "4      0.015568  0.044409\n",
      "...         ...       ...\n",
      "18013  0.000055  0.000231\n",
      "18014  0.000000  0.000000\n",
      "18015  0.002367  0.011945\n",
      "18016  0.002302  0.011713\n",
      "18017  0.000000  0.000000\n",
      "\n",
      "[18018 rows x 2 columns]\n",
      "Training using optimizer with lr=0.001...\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.6548 - acc: 0.6062 - auROC: 0.5205 - val_loss: 0.6176 - val_acc: 0.6759 - val_auROC: 0.5288\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.5957 - acc: 0.7111 - auROC: 0.5797 - val_loss: 0.5770 - val_acc: 0.7621 - val_auROC: 0.6005\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.5547 - acc: 0.7747 - auROC: 0.6557 - val_loss: 0.5363 - val_acc: 0.7897 - val_auROC: 0.6636\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.5137 - acc: 0.7914 - auROC: 0.6587 - val_loss: 0.5164 - val_acc: 0.7862 - val_auROC: 0.6355\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4881 - acc: 0.8133 - auROC: 0.6905 - val_loss: 0.5011 - val_acc: 0.7828 - val_auROC: 0.6591\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4671 - acc: 0.8183 - auROC: 0.7253 - val_loss: 0.4844 - val_acc: 0.7966 - val_auROC: 0.6943\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4517 - acc: 0.8183 - auROC: 0.7595 - val_loss: 0.4678 - val_acc: 0.7862 - val_auROC: 0.7397\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4401 - acc: 0.8195 - auROC: 0.7793 - val_loss: 0.4581 - val_acc: 0.7966 - val_auROC: 0.7535\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4285 - acc: 0.8207 - auROC: 0.7980 - val_loss: 0.4478 - val_acc: 0.8172 - val_auROC: 0.7532\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4211 - acc: 0.8207 - auROC: 0.8041 - val_loss: 0.4507 - val_acc: 0.8172 - val_auROC: 0.7309\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4164 - acc: 0.8273 - auROC: 0.7975 - val_loss: 0.4421 - val_acc: 0.8000 - val_auROC: 0.7588\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4101 - acc: 0.8191 - auROC: 0.8140 - val_loss: 0.4303 - val_acc: 0.8034 - val_auROC: 0.7785\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4092 - acc: 0.8199 - auROC: 0.8166 - val_loss: 0.4263 - val_acc: 0.8172 - val_auROC: 0.7833\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4020 - acc: 0.8324 - auROC: 0.8172 - val_loss: 0.4276 - val_acc: 0.8103 - val_auROC: 0.7774\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4008 - acc: 0.8269 - auROC: 0.8286 - val_loss: 0.4349 - val_acc: 0.8034 - val_auROC: 0.7528\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4337 - acc: 0.8261 - auROC: 0.7529 - val_loss: 0.4226 - val_acc: 0.8034 - val_auROC: 0.7833\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4186 - acc: 0.8125 - auROC: 0.7857 - val_loss: 0.4349 - val_acc: 0.8034 - val_auROC: 0.7650\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4092 - acc: 0.8265 - auROC: 0.7915 - val_loss: 0.4342 - val_acc: 0.8000 - val_auROC: 0.7473\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4003 - acc: 0.8378 - auROC: 0.8064 - val_loss: 0.4228 - val_acc: 0.8000 - val_auROC: 0.7782\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3868 - acc: 0.8288 - auROC: 0.8339 - val_loss: 0.4256 - val_acc: 0.8241 - val_auROC: 0.7619\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3835 - acc: 0.8398 - auROC: 0.8298 - val_loss: 0.4078 - val_acc: 0.8172 - val_auROC: 0.8037\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3733 - acc: 0.8433 - auROC: 0.8475 - val_loss: 0.4015 - val_acc: 0.8172 - val_auROC: 0.8137\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3691 - acc: 0.8437 - auROC: 0.8535 - val_loss: 0.3989 - val_acc: 0.8241 - val_auROC: 0.8158\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3729 - acc: 0.8448 - auROC: 0.8454 - val_loss: 0.3946 - val_acc: 0.8379 - val_auROC: 0.8145\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3614 - acc: 0.8515 - auROC: 0.8603 - val_loss: 0.3889 - val_acc: 0.8276 - val_auROC: 0.8257\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3524 - acc: 0.8620 - auROC: 0.8727 - val_loss: 0.3838 - val_acc: 0.8207 - val_auROC: 0.8366\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3611 - acc: 0.8452 - auROC: 0.8666 - val_loss: 0.4001 - val_acc: 0.8172 - val_auROC: 0.8019\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3524 - acc: 0.8565 - auROC: 0.8661 - val_loss: 0.3900 - val_acc: 0.8310 - val_auROC: 0.8187\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3490 - acc: 0.8593 - auROC: 0.8770 - val_loss: 0.3875 - val_acc: 0.8276 - val_auROC: 0.8207\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3485 - acc: 0.8706 - auROC: 0.8689 - val_loss: 0.3880 - val_acc: 0.8379 - val_auROC: 0.8178\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3517 - acc: 0.8667 - auROC: 0.8672 - val_loss: 0.3741 - val_acc: 0.8276 - val_auROC: 0.8435\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3441 - acc: 0.8710 - auROC: 0.8774 - val_loss: 0.3692 - val_acc: 0.8414 - val_auROC: 0.8381\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3363 - acc: 0.8791 - auROC: 0.8862 - val_loss: 0.3535 - val_acc: 0.8379 - val_auROC: 0.8645\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3333 - acc: 0.8752 - auROC: 0.8865 - val_loss: 0.3759 - val_acc: 0.8448 - val_auROC: 0.8419\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3396 - acc: 0.8690 - auROC: 0.8782 - val_loss: 0.3498 - val_acc: 0.8276 - val_auROC: 0.8906\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3219 - acc: 0.8788 - auROC: 0.8986 - val_loss: 0.3805 - val_acc: 0.8621 - val_auROC: 0.8292\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3169 - acc: 0.8897 - auROC: 0.9036 - val_loss: 0.3398 - val_acc: 0.8310 - val_auROC: 0.8896\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3036 - acc: 0.8912 - auROC: 0.9174 - val_loss: 0.3323 - val_acc: 0.8552 - val_auROC: 0.8877\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3015 - acc: 0.8920 - auROC: 0.9197 - val_loss: 0.3230 - val_acc: 0.8517 - val_auROC: 0.8986\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2928 - acc: 0.9002 - auROC: 0.9270 - val_loss: 0.3698 - val_acc: 0.8517 - val_auROC: 0.8309\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3387 - acc: 0.8674 - auROC: 0.8701 - val_loss: 0.3696 - val_acc: 0.8276 - val_auROC: 0.8532\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3434 - acc: 0.8600 - auROC: 0.8724 - val_loss: 0.3308 - val_acc: 0.8793 - val_auROC: 0.8915\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3388 - acc: 0.8608 - auROC: 0.8732 - val_loss: 0.3319 - val_acc: 0.8207 - val_auROC: 0.9058\n",
      "Epoch 44/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.3344 - acc: 0.8562 - auROC: 0.8865\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3340 - acc: 0.8565 - auROC: 0.8868 - val_loss: 0.3264 - val_acc: 0.8621 - val_auROC: 0.8940\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3148 - acc: 0.8756 - auROC: 0.8995 - val_loss: 0.3226 - val_acc: 0.8621 - val_auROC: 0.9003\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3087 - acc: 0.8819 - auROC: 0.9075 - val_loss: 0.3225 - val_acc: 0.8586 - val_auROC: 0.8989\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3068 - acc: 0.8862 - auROC: 0.9101 - val_loss: 0.3198 - val_acc: 0.8655 - val_auROC: 0.9051\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3042 - acc: 0.8815 - auROC: 0.9151 - val_loss: 0.3229 - val_acc: 0.8655 - val_auROC: 0.9032\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3031 - acc: 0.8811 - auROC: 0.9156 - val_loss: 0.3358 - val_acc: 0.8759 - val_auROC: 0.8796\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3029 - acc: 0.8846 - auROC: 0.9136 - val_loss: 0.3379 - val_acc: 0.8655 - val_auROC: 0.8721\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2983 - acc: 0.8869 - auROC: 0.9177 - val_loss: 0.3294 - val_acc: 0.8655 - val_auROC: 0.8828\n",
      "Epoch 52/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.2955 - acc: 0.8926 - auROC: 0.9193\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2959 - acc: 0.8924 - auROC: 0.9189 - val_loss: 0.3239 - val_acc: 0.8690 - val_auROC: 0.8901\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2945 - acc: 0.8936 - auROC: 0.9197 - val_loss: 0.3234 - val_acc: 0.8690 - val_auROC: 0.8903\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2942 - acc: 0.8932 - auROC: 0.9199 - val_loss: 0.3233 - val_acc: 0.8690 - val_auROC: 0.8893\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2936 - acc: 0.8936 - auROC: 0.9204 - val_loss: 0.3237 - val_acc: 0.8690 - val_auROC: 0.8897\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2932 - acc: 0.8940 - auROC: 0.9207 - val_loss: 0.3237 - val_acc: 0.8655 - val_auROC: 0.8886\n",
      "Epoch 57/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.2930 - acc: 0.8941 - auROC: 0.9206\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2929 - acc: 0.8943 - auROC: 0.9207 - val_loss: 0.3235 - val_acc: 0.8655 - val_auROC: 0.8885\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2926 - acc: 0.8936 - auROC: 0.9211 - val_loss: 0.3233 - val_acc: 0.8655 - val_auROC: 0.8895\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2923 - acc: 0.8936 - auROC: 0.9213 - val_loss: 0.3230 - val_acc: 0.8655 - val_auROC: 0.8897\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2920 - acc: 0.8936 - auROC: 0.9216 - val_loss: 0.3226 - val_acc: 0.8655 - val_auROC: 0.8906\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2917 - acc: 0.8940 - auROC: 0.9219 - val_loss: 0.3220 - val_acc: 0.8690 - val_auROC: 0.8919\n",
      "Epoch 62/300\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.2940 - acc: 0.8942 - auROC: 0.9200Restoring model weights from the end of the best epoch.\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2914 - acc: 0.8951 - auROC: 0.9225 - val_loss: 0.3217 - val_acc: 0.8690 - val_auROC: 0.8918\n",
      "Epoch 00062: early stopping\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 18018)]           0         \n",
      "_________________________________________________________________\n",
      "base (Sequential)            (None, 512)               18976256  \n",
      "_________________________________________________________________\n",
      "l2_inter (Sequential)        (None, 10)                21550     \n",
      "_________________________________________________________________\n",
      "l2_integration (Sequential)  (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "l2o (Sequential)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 18,998,051\n",
      "Trainable params: 21,795\n",
      "Non-trainable params: 18,976,256\n",
      "_________________________________________________________________\n",
      "Fine-tuning using optimizer with lr=1e-05...\n",
      "Epoch 62/361\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3033 - acc: 0.8850 - auROC: 0.9151 - val_loss: 0.3071 - val_acc: 0.8724 - val_auROC: 0.9195\n",
      "Epoch 63/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2935 - acc: 0.8908 - auROC: 0.9257 - val_loss: 0.3026 - val_acc: 0.8793 - val_auROC: 0.9228\n",
      "Epoch 64/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2879 - acc: 0.8994 - auROC: 0.9301 - val_loss: 0.2998 - val_acc: 0.8759 - val_auROC: 0.9266\n",
      "Epoch 65/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2830 - acc: 0.9025 - auROC: 0.9338 - val_loss: 0.2977 - val_acc: 0.8862 - val_auROC: 0.9289\n",
      "Epoch 66/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2787 - acc: 0.9088 - auROC: 0.9373 - val_loss: 0.2947 - val_acc: 0.8931 - val_auROC: 0.9317\n",
      "Epoch 67/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2752 - acc: 0.9119 - auROC: 0.9404 - val_loss: 0.2902 - val_acc: 0.9000 - val_auROC: 0.9358\n",
      "Epoch 68/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2722 - acc: 0.9150 - auROC: 0.9425 - val_loss: 0.2872 - val_acc: 0.9069 - val_auROC: 0.9380\n",
      "Epoch 69/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2693 - acc: 0.9193 - auROC: 0.9444 - val_loss: 0.2828 - val_acc: 0.9069 - val_auROC: 0.9406\n",
      "Epoch 70/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2664 - acc: 0.9216 - auROC: 0.9469 - val_loss: 0.2811 - val_acc: 0.9069 - val_auROC: 0.9417\n",
      "Epoch 71/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2642 - acc: 0.9224 - auROC: 0.9482 - val_loss: 0.2801 - val_acc: 0.9034 - val_auROC: 0.9425\n",
      "Epoch 72/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2632 - acc: 0.9240 - auROC: 0.9486 - val_loss: 0.2834 - val_acc: 0.9034 - val_auROC: 0.9362\n",
      "Epoch 73/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2625 - acc: 0.9259 - auROC: 0.9487 - val_loss: 0.2788 - val_acc: 0.9103 - val_auROC: 0.9403\n",
      "Epoch 74/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2604 - acc: 0.9283 - auROC: 0.9502 - val_loss: 0.2739 - val_acc: 0.9172 - val_auROC: 0.9435\n",
      "Epoch 75/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2590 - acc: 0.9279 - auROC: 0.9510 - val_loss: 0.2694 - val_acc: 0.9207 - val_auROC: 0.9470\n",
      "Epoch 76/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2577 - acc: 0.9298 - auROC: 0.9518 - val_loss: 0.2680 - val_acc: 0.9241 - val_auROC: 0.9482\n",
      "Epoch 77/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2561 - acc: 0.9326 - auROC: 0.9525 - val_loss: 0.2689 - val_acc: 0.9207 - val_auROC: 0.9483\n",
      "Epoch 78/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2547 - acc: 0.9361 - auROC: 0.9531 - val_loss: 0.2682 - val_acc: 0.9172 - val_auROC: 0.9495\n",
      "Epoch 79/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2536 - acc: 0.9365 - auROC: 0.9540 - val_loss: 0.2686 - val_acc: 0.9138 - val_auROC: 0.9494\n",
      "Epoch 80/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2524 - acc: 0.9372 - auROC: 0.9546 - val_loss: 0.2664 - val_acc: 0.9138 - val_auROC: 0.9508\n",
      "Epoch 81/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2513 - acc: 0.9400 - auROC: 0.9555 - val_loss: 0.2639 - val_acc: 0.9207 - val_auROC: 0.9519\n",
      "Epoch 82/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2502 - acc: 0.9404 - auROC: 0.9560 - val_loss: 0.2622 - val_acc: 0.9172 - val_auROC: 0.9528\n",
      "Epoch 83/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2489 - acc: 0.9407 - auROC: 0.9566 - val_loss: 0.2612 - val_acc: 0.9207 - val_auROC: 0.9541\n",
      "Epoch 84/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2477 - acc: 0.9411 - auROC: 0.9572 - val_loss: 0.2606 - val_acc: 0.9207 - val_auROC: 0.9545\n",
      "Epoch 85/361\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.2467 - acc: 0.9411 - auROC: 0.9577 - val_loss: 0.2601 - val_acc: 0.9241 - val_auROC: 0.9544\n",
      "Epoch 86/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2459 - acc: 0.9404 - auROC: 0.9580 - val_loss: 0.2594 - val_acc: 0.9241 - val_auROC: 0.9556\n",
      "Epoch 87/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2449 - acc: 0.9411 - auROC: 0.9586 - val_loss: 0.2586 - val_acc: 0.9207 - val_auROC: 0.9569\n",
      "Epoch 88/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2440 - acc: 0.9411 - auROC: 0.9592 - val_loss: 0.2576 - val_acc: 0.9207 - val_auROC: 0.9568\n",
      "Epoch 89/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2437 - acc: 0.9419 - auROC: 0.9596 - val_loss: 0.2562 - val_acc: 0.9241 - val_auROC: 0.9574\n",
      "Epoch 90/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2434 - acc: 0.9415 - auROC: 0.9599 - val_loss: 0.2554 - val_acc: 0.9241 - val_auROC: 0.9583\n",
      "Epoch 91/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2425 - acc: 0.9423 - auROC: 0.9602 - val_loss: 0.2547 - val_acc: 0.9241 - val_auROC: 0.9587\n",
      "Epoch 92/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2417 - acc: 0.9442 - auROC: 0.9605 - val_loss: 0.2538 - val_acc: 0.9241 - val_auROC: 0.9593\n",
      "Epoch 93/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2410 - acc: 0.9442 - auROC: 0.9609 - val_loss: 0.2531 - val_acc: 0.9276 - val_auROC: 0.9597\n",
      "Epoch 94/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2401 - acc: 0.9442 - auROC: 0.9612 - val_loss: 0.2526 - val_acc: 0.9241 - val_auROC: 0.9602\n",
      "Epoch 95/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2397 - acc: 0.9431 - auROC: 0.9612 - val_loss: 0.2511 - val_acc: 0.9241 - val_auROC: 0.9596\n",
      "Epoch 96/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2395 - acc: 0.9431 - auROC: 0.9610 - val_loss: 0.2509 - val_acc: 0.9241 - val_auROC: 0.9606\n",
      "Epoch 97/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2394 - acc: 0.9439 - auROC: 0.9605 - val_loss: 0.2489 - val_acc: 0.9345 - val_auROC: 0.9617\n",
      "Epoch 98/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2392 - acc: 0.9454 - auROC: 0.9605 - val_loss: 0.2487 - val_acc: 0.9345 - val_auROC: 0.9617\n",
      "Epoch 99/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2382 - acc: 0.9470 - auROC: 0.9607 - val_loss: 0.2482 - val_acc: 0.9345 - val_auROC: 0.9608\n",
      "Epoch 100/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2370 - acc: 0.9470 - auROC: 0.9612 - val_loss: 0.2484 - val_acc: 0.9345 - val_auROC: 0.9593\n",
      "Epoch 101/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2359 - acc: 0.9481 - auROC: 0.9618 - val_loss: 0.2466 - val_acc: 0.9345 - val_auROC: 0.9632\n",
      "Epoch 102/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2354 - acc: 0.9485 - auROC: 0.9621 - val_loss: 0.2468 - val_acc: 0.9345 - val_auROC: 0.9641\n",
      "Epoch 103/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2347 - acc: 0.9505 - auROC: 0.9628 - val_loss: 0.2463 - val_acc: 0.9345 - val_auROC: 0.9642\n",
      "Epoch 104/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2339 - acc: 0.9509 - auROC: 0.9631 - val_loss: 0.2453 - val_acc: 0.9345 - val_auROC: 0.9643\n",
      "Epoch 105/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2329 - acc: 0.9513 - auROC: 0.9637 - val_loss: 0.2444 - val_acc: 0.9310 - val_auROC: 0.9640\n",
      "Epoch 106/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2324 - acc: 0.9517 - auROC: 0.9640 - val_loss: 0.2431 - val_acc: 0.9345 - val_auROC: 0.9647\n",
      "Epoch 107/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2316 - acc: 0.9517 - auROC: 0.9650 - val_loss: 0.2430 - val_acc: 0.9241 - val_auROC: 0.9656\n",
      "Epoch 108/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2312 - acc: 0.9505 - auROC: 0.9663 - val_loss: 0.2488 - val_acc: 0.9310 - val_auROC: 0.9645\n",
      "Epoch 109/361\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2321 - acc: 0.9497 - auROC: 0.9662 - val_loss: 0.2483 - val_acc: 0.9276 - val_auROC: 0.9672\n",
      "Epoch 110/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2313 - acc: 0.9493 - auROC: 0.9664 - val_loss: 0.2464 - val_acc: 0.9276 - val_auROC: 0.9675\n",
      "Epoch 111/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2302 - acc: 0.9513 - auROC: 0.9670 - val_loss: 0.2449 - val_acc: 0.9276 - val_auROC: 0.9681\n",
      "Epoch 112/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2294 - acc: 0.9520 - auROC: 0.9672 - val_loss: 0.2437 - val_acc: 0.9241 - val_auROC: 0.9689\n",
      "Epoch 113/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2287 - acc: 0.9532 - auROC: 0.9676 - val_loss: 0.2427 - val_acc: 0.9241 - val_auROC: 0.9684\n",
      "Epoch 114/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2284 - acc: 0.9528 - auROC: 0.9681 - val_loss: 0.2431 - val_acc: 0.9276 - val_auROC: 0.9666\n",
      "Epoch 115/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2284 - acc: 0.9517 - auROC: 0.9689 - val_loss: 0.2422 - val_acc: 0.9276 - val_auROC: 0.9679\n",
      "Epoch 116/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2276 - acc: 0.9520 - auROC: 0.9688 - val_loss: 0.2407 - val_acc: 0.9276 - val_auROC: 0.9695\n",
      "Epoch 117/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2270 - acc: 0.9517 - auROC: 0.9689 - val_loss: 0.2381 - val_acc: 0.9241 - val_auROC: 0.9697\n",
      "Epoch 118/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2268 - acc: 0.9513 - auROC: 0.9690 - val_loss: 0.2368 - val_acc: 0.9241 - val_auROC: 0.9712\n",
      "Epoch 119/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2261 - acc: 0.9532 - auROC: 0.9691 - val_loss: 0.2362 - val_acc: 0.9276 - val_auROC: 0.9723\n",
      "Epoch 120/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2255 - acc: 0.9544 - auROC: 0.9691 - val_loss: 0.2361 - val_acc: 0.9276 - val_auROC: 0.9732\n",
      "Epoch 121/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2250 - acc: 0.9544 - auROC: 0.9691 - val_loss: 0.2356 - val_acc: 0.9276 - val_auROC: 0.9731\n",
      "Epoch 122/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2246 - acc: 0.9540 - auROC: 0.9693 - val_loss: 0.2353 - val_acc: 0.9276 - val_auROC: 0.9731\n",
      "Epoch 123/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2241 - acc: 0.9536 - auROC: 0.9695 - val_loss: 0.2350 - val_acc: 0.9276 - val_auROC: 0.9734\n",
      "Epoch 124/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2237 - acc: 0.9540 - auROC: 0.9696 - val_loss: 0.2345 - val_acc: 0.9310 - val_auROC: 0.9735\n",
      "Epoch 125/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2233 - acc: 0.9544 - auROC: 0.9698 - val_loss: 0.2341 - val_acc: 0.9310 - val_auROC: 0.9735\n",
      "Epoch 126/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2229 - acc: 0.9544 - auROC: 0.9699 - val_loss: 0.2335 - val_acc: 0.9310 - val_auROC: 0.9740\n",
      "Epoch 127/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2226 - acc: 0.9552 - auROC: 0.9701 - val_loss: 0.2331 - val_acc: 0.9310 - val_auROC: 0.9741\n",
      "Epoch 128/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2222 - acc: 0.9552 - auROC: 0.9702 - val_loss: 0.2326 - val_acc: 0.9310 - val_auROC: 0.9745\n",
      "Epoch 129/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2219 - acc: 0.9552 - auROC: 0.9701 - val_loss: 0.2318 - val_acc: 0.9345 - val_auROC: 0.9751\n",
      "Epoch 130/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2218 - acc: 0.9552 - auROC: 0.9701 - val_loss: 0.2318 - val_acc: 0.9345 - val_auROC: 0.9753\n",
      "Epoch 131/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2213 - acc: 0.9556 - auROC: 0.9703 - val_loss: 0.2316 - val_acc: 0.9345 - val_auROC: 0.9746\n",
      "Epoch 132/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2209 - acc: 0.9552 - auROC: 0.9706 - val_loss: 0.2310 - val_acc: 0.9345 - val_auROC: 0.9748\n",
      "Epoch 133/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2206 - acc: 0.9556 - auROC: 0.9708 - val_loss: 0.2305 - val_acc: 0.9345 - val_auROC: 0.9745\n",
      "Epoch 134/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2204 - acc: 0.9559 - auROC: 0.9708 - val_loss: 0.2304 - val_acc: 0.9345 - val_auROC: 0.9747\n",
      "Epoch 135/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2202 - acc: 0.9563 - auROC: 0.9709 - val_loss: 0.2314 - val_acc: 0.9345 - val_auROC: 0.9746\n",
      "Epoch 136/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2198 - acc: 0.9556 - auROC: 0.9705 - val_loss: 0.2298 - val_acc: 0.9345 - val_auROC: 0.9757\n",
      "Epoch 137/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2212 - acc: 0.9540 - auROC: 0.9700 - val_loss: 0.2292 - val_acc: 0.9345 - val_auROC: 0.9754\n",
      "Epoch 138/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2229 - acc: 0.9528 - auROC: 0.9696 - val_loss: 0.2292 - val_acc: 0.9345 - val_auROC: 0.9761\n",
      "Epoch 139/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2220 - acc: 0.9524 - auROC: 0.9702 - val_loss: 0.2285 - val_acc: 0.9345 - val_auROC: 0.9765\n",
      "Epoch 140/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2203 - acc: 0.9544 - auROC: 0.9706 - val_loss: 0.2284 - val_acc: 0.9345 - val_auROC: 0.9763\n",
      "Epoch 141/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2190 - acc: 0.9548 - auROC: 0.9713 - val_loss: 0.2279 - val_acc: 0.9310 - val_auROC: 0.9762\n",
      "Epoch 142/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2183 - acc: 0.9567 - auROC: 0.9715 - val_loss: 0.2273 - val_acc: 0.9379 - val_auROC: 0.9764\n",
      "Epoch 143/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2179 - acc: 0.9571 - auROC: 0.9716 - val_loss: 0.2269 - val_acc: 0.9448 - val_auROC: 0.9766\n",
      "Epoch 144/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2177 - acc: 0.9571 - auROC: 0.9716 - val_loss: 0.2261 - val_acc: 0.9448 - val_auROC: 0.9766\n",
      "Epoch 145/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2172 - acc: 0.9591 - auROC: 0.9719 - val_loss: 0.2257 - val_acc: 0.9448 - val_auROC: 0.9773\n",
      "Epoch 146/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2166 - acc: 0.9610 - auROC: 0.9723 - val_loss: 0.2254 - val_acc: 0.9448 - val_auROC: 0.9771\n",
      "Epoch 147/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2162 - acc: 0.9602 - auROC: 0.9725 - val_loss: 0.2250 - val_acc: 0.9448 - val_auROC: 0.9776\n",
      "Epoch 148/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2158 - acc: 0.9595 - auROC: 0.9726 - val_loss: 0.2249 - val_acc: 0.9414 - val_auROC: 0.9772\n",
      "Epoch 149/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2155 - acc: 0.9606 - auROC: 0.9730 - val_loss: 0.2247 - val_acc: 0.9448 - val_auROC: 0.9772\n",
      "Epoch 150/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2151 - acc: 0.9614 - auROC: 0.9731 - val_loss: 0.2243 - val_acc: 0.9483 - val_auROC: 0.9772\n",
      "Epoch 151/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2147 - acc: 0.9618 - auROC: 0.9733 - val_loss: 0.2240 - val_acc: 0.9448 - val_auROC: 0.9774\n",
      "Epoch 152/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2144 - acc: 0.9622 - auROC: 0.9733 - val_loss: 0.2237 - val_acc: 0.9448 - val_auROC: 0.9773\n",
      "Epoch 153/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2142 - acc: 0.9618 - auROC: 0.9733 - val_loss: 0.2236 - val_acc: 0.9448 - val_auROC: 0.9770\n",
      "Epoch 154/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2139 - acc: 0.9618 - auROC: 0.9735 - val_loss: 0.2231 - val_acc: 0.9414 - val_auROC: 0.9769\n",
      "Epoch 155/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2138 - acc: 0.9622 - auROC: 0.9733 - val_loss: 0.2222 - val_acc: 0.9414 - val_auROC: 0.9772\n",
      "Epoch 156/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2135 - acc: 0.9626 - auROC: 0.9735 - val_loss: 0.2226 - val_acc: 0.9414 - val_auROC: 0.9774\n",
      "Epoch 157/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2132 - acc: 0.9630 - auROC: 0.9738 - val_loss: 0.2225 - val_acc: 0.9483 - val_auROC: 0.9773\n",
      "Epoch 158/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2127 - acc: 0.9630 - auROC: 0.9738 - val_loss: 0.2219 - val_acc: 0.9448 - val_auROC: 0.9778\n",
      "Epoch 159/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2126 - acc: 0.9622 - auROC: 0.9736 - val_loss: 0.2203 - val_acc: 0.9379 - val_auROC: 0.9784\n",
      "Epoch 160/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2125 - acc: 0.9622 - auROC: 0.9735 - val_loss: 0.2196 - val_acc: 0.9414 - val_auROC: 0.9784\n",
      "Epoch 161/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2119 - acc: 0.9634 - auROC: 0.9738 - val_loss: 0.2194 - val_acc: 0.9414 - val_auROC: 0.9781\n",
      "Epoch 162/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2116 - acc: 0.9634 - auROC: 0.9741 - val_loss: 0.2192 - val_acc: 0.9448 - val_auROC: 0.9781\n",
      "Epoch 163/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2115 - acc: 0.9637 - auROC: 0.9742 - val_loss: 0.2187 - val_acc: 0.9483 - val_auROC: 0.9780\n",
      "Epoch 164/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2117 - acc: 0.9653 - auROC: 0.9741 - val_loss: 0.2188 - val_acc: 0.9483 - val_auROC: 0.9798\n",
      "Epoch 165/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2122 - acc: 0.9657 - auROC: 0.9744 - val_loss: 0.2187 - val_acc: 0.9483 - val_auROC: 0.9800\n",
      "Epoch 166/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2120 - acc: 0.9649 - auROC: 0.9744 - val_loss: 0.2179 - val_acc: 0.9483 - val_auROC: 0.9785\n",
      "Epoch 167/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2110 - acc: 0.9630 - auROC: 0.9745 - val_loss: 0.2179 - val_acc: 0.9448 - val_auROC: 0.9785\n",
      "Epoch 168/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2106 - acc: 0.9622 - auROC: 0.9746 - val_loss: 0.2178 - val_acc: 0.9448 - val_auROC: 0.9784\n",
      "Epoch 169/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2102 - acc: 0.9630 - auROC: 0.9747 - val_loss: 0.2176 - val_acc: 0.9448 - val_auROC: 0.9782\n",
      "Epoch 170/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2099 - acc: 0.9630 - auROC: 0.9746 - val_loss: 0.2177 - val_acc: 0.9483 - val_auROC: 0.9781\n",
      "Epoch 171/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2096 - acc: 0.9634 - auROC: 0.9746 - val_loss: 0.2177 - val_acc: 0.9483 - val_auROC: 0.9777\n",
      "Epoch 172/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2093 - acc: 0.9630 - auROC: 0.9746 - val_loss: 0.2178 - val_acc: 0.9483 - val_auROC: 0.9777\n",
      "Epoch 173/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2091 - acc: 0.9634 - auROC: 0.9747 - val_loss: 0.2175 - val_acc: 0.9483 - val_auROC: 0.9779\n",
      "Epoch 174/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2089 - acc: 0.9634 - auROC: 0.9747 - val_loss: 0.2177 - val_acc: 0.9483 - val_auROC: 0.9778\n",
      "Epoch 175/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2087 - acc: 0.9634 - auROC: 0.9748 - val_loss: 0.2175 - val_acc: 0.9483 - val_auROC: 0.9791\n",
      "Epoch 176/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2085 - acc: 0.9634 - auROC: 0.9747 - val_loss: 0.2172 - val_acc: 0.9483 - val_auROC: 0.9785\n",
      "Epoch 177/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2083 - acc: 0.9630 - auROC: 0.9747 - val_loss: 0.2166 - val_acc: 0.9483 - val_auROC: 0.9784\n",
      "Epoch 178/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2081 - acc: 0.9637 - auROC: 0.9750 - val_loss: 0.2158 - val_acc: 0.9517 - val_auROC: 0.9791\n",
      "Epoch 179/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2080 - acc: 0.9637 - auROC: 0.9750 - val_loss: 0.2155 - val_acc: 0.9517 - val_auROC: 0.9790\n",
      "Epoch 180/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2078 - acc: 0.9637 - auROC: 0.9750 - val_loss: 0.2158 - val_acc: 0.9483 - val_auROC: 0.9776\n",
      "Epoch 181/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2076 - acc: 0.9637 - auROC: 0.9749 - val_loss: 0.2160 - val_acc: 0.9483 - val_auROC: 0.9774\n",
      "Epoch 182/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2073 - acc: 0.9634 - auROC: 0.9750 - val_loss: 0.2160 - val_acc: 0.9483 - val_auROC: 0.9774\n",
      "Epoch 183/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2071 - acc: 0.9649 - auROC: 0.9751 - val_loss: 0.2158 - val_acc: 0.9483 - val_auROC: 0.9776\n",
      "Epoch 184/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2069 - acc: 0.9645 - auROC: 0.9753 - val_loss: 0.2156 - val_acc: 0.9483 - val_auROC: 0.9782\n",
      "Epoch 185/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2067 - acc: 0.9641 - auROC: 0.9753 - val_loss: 0.2153 - val_acc: 0.9483 - val_auROC: 0.9785\n",
      "Epoch 186/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2066 - acc: 0.9649 - auROC: 0.9754 - val_loss: 0.2148 - val_acc: 0.9483 - val_auROC: 0.9789\n",
      "Epoch 187/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2068 - acc: 0.9649 - auROC: 0.9754 - val_loss: 0.2148 - val_acc: 0.9483 - val_auROC: 0.9787\n",
      "Epoch 188/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2067 - acc: 0.9653 - auROC: 0.9754 - val_loss: 0.2158 - val_acc: 0.9517 - val_auROC: 0.9795\n",
      "Epoch 189/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2065 - acc: 0.9653 - auROC: 0.9754 - val_loss: 0.2153 - val_acc: 0.9552 - val_auROC: 0.9795\n",
      "Epoch 190/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2061 - acc: 0.9653 - auROC: 0.9755 - val_loss: 0.2146 - val_acc: 0.9483 - val_auROC: 0.9785\n",
      "Epoch 191/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2058 - acc: 0.9653 - auROC: 0.9755 - val_loss: 0.2141 - val_acc: 0.9483 - val_auROC: 0.9787\n",
      "Epoch 192/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2055 - acc: 0.9669 - auROC: 0.9758 - val_loss: 0.2138 - val_acc: 0.9552 - val_auROC: 0.9787\n",
      "Epoch 193/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2054 - acc: 0.9661 - auROC: 0.9759 - val_loss: 0.2142 - val_acc: 0.9448 - val_auROC: 0.9784\n",
      "Epoch 194/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2050 - acc: 0.9657 - auROC: 0.9761 - val_loss: 0.2145 - val_acc: 0.9448 - val_auROC: 0.9785\n",
      "Epoch 195/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2048 - acc: 0.9661 - auROC: 0.9767 - val_loss: 0.2145 - val_acc: 0.9517 - val_auROC: 0.9784\n",
      "Epoch 196/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2046 - acc: 0.9661 - auROC: 0.9769 - val_loss: 0.2141 - val_acc: 0.9483 - val_auROC: 0.9785\n",
      "Epoch 197/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2042 - acc: 0.9665 - auROC: 0.9769 - val_loss: 0.2135 - val_acc: 0.9517 - val_auROC: 0.9793\n",
      "Epoch 198/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2040 - acc: 0.9669 - auROC: 0.9768 - val_loss: 0.2132 - val_acc: 0.9517 - val_auROC: 0.9803\n",
      "Epoch 199/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2038 - acc: 0.9669 - auROC: 0.9770 - val_loss: 0.2131 - val_acc: 0.9552 - val_auROC: 0.9801\n",
      "Epoch 200/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2036 - acc: 0.9661 - auROC: 0.9769 - val_loss: 0.2122 - val_acc: 0.9517 - val_auROC: 0.9804\n",
      "Epoch 201/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2035 - acc: 0.9661 - auROC: 0.9768 - val_loss: 0.2119 - val_acc: 0.9552 - val_auROC: 0.9806\n",
      "Epoch 202/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2033 - acc: 0.9673 - auROC: 0.9769 - val_loss: 0.2125 - val_acc: 0.9586 - val_auROC: 0.9805\n",
      "Epoch 203/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2032 - acc: 0.9676 - auROC: 0.9774 - val_loss: 0.2135 - val_acc: 0.9586 - val_auROC: 0.9800\n",
      "Epoch 204/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2031 - acc: 0.9665 - auROC: 0.9773 - val_loss: 0.2121 - val_acc: 0.9552 - val_auROC: 0.9803\n",
      "Epoch 205/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2031 - acc: 0.9645 - auROC: 0.9772 - val_loss: 0.2116 - val_acc: 0.9552 - val_auROC: 0.9805\n",
      "Epoch 206/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2029 - acc: 0.9641 - auROC: 0.9772 - val_loss: 0.2112 - val_acc: 0.9552 - val_auROC: 0.9807\n",
      "Epoch 207/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2026 - acc: 0.9653 - auROC: 0.9772 - val_loss: 0.2116 - val_acc: 0.9552 - val_auROC: 0.9807\n",
      "Epoch 208/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2024 - acc: 0.9657 - auROC: 0.9776 - val_loss: 0.2120 - val_acc: 0.9621 - val_auROC: 0.9805\n",
      "Epoch 209/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2022 - acc: 0.9665 - auROC: 0.9777 - val_loss: 0.2119 - val_acc: 0.9621 - val_auROC: 0.9804\n",
      "Epoch 210/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2020 - acc: 0.9665 - auROC: 0.9777 - val_loss: 0.2117 - val_acc: 0.9517 - val_auROC: 0.9796\n",
      "Epoch 211/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2018 - acc: 0.9665 - auROC: 0.9778 - val_loss: 0.2119 - val_acc: 0.9517 - val_auROC: 0.9796\n",
      "Epoch 212/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2016 - acc: 0.9665 - auROC: 0.9779 - val_loss: 0.2131 - val_acc: 0.9517 - val_auROC: 0.9802\n",
      "Epoch 213/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2010 - acc: 0.9665 - auROC: 0.9781 - val_loss: 0.2121 - val_acc: 0.9517 - val_auROC: 0.9804\n",
      "Epoch 214/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2007 - acc: 0.9665 - auROC: 0.9783 - val_loss: 0.2114 - val_acc: 0.9586 - val_auROC: 0.9804\n",
      "Epoch 215/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2006 - acc: 0.9669 - auROC: 0.9783 - val_loss: 0.2120 - val_acc: 0.9586 - val_auROC: 0.9801\n",
      "Epoch 216/361\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.2006 - acc: 0.9669 - auROC: 0.9783 - val_loss: 0.2112 - val_acc: 0.9586 - val_auROC: 0.9804\n",
      "Epoch 217/361\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2002 - acc: 0.9676 - auROC: 0.9784 - val_loss: 0.2107 - val_acc: 0.9586 - val_auROC: 0.9804\n",
      "Epoch 218/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2000 - acc: 0.9680 - auROC: 0.9785 - val_loss: 0.2107 - val_acc: 0.9586 - val_auROC: 0.9805\n",
      "Epoch 219/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1999 - acc: 0.9684 - auROC: 0.9786 - val_loss: 0.2104 - val_acc: 0.9586 - val_auROC: 0.9805\n",
      "Epoch 220/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1997 - acc: 0.9684 - auROC: 0.9787 - val_loss: 0.2103 - val_acc: 0.9586 - val_auROC: 0.9808\n",
      "Epoch 221/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1997 - acc: 0.9688 - auROC: 0.9787 - val_loss: 0.2095 - val_acc: 0.9655 - val_auROC: 0.9810\n",
      "Epoch 222/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1997 - acc: 0.9684 - auROC: 0.9787 - val_loss: 0.2088 - val_acc: 0.9586 - val_auROC: 0.9810\n",
      "Epoch 223/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1996 - acc: 0.9673 - auROC: 0.9787 - val_loss: 0.2085 - val_acc: 0.9586 - val_auROC: 0.9809\n",
      "Epoch 224/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1992 - acc: 0.9684 - auROC: 0.9786 - val_loss: 0.2087 - val_acc: 0.9621 - val_auROC: 0.9809\n",
      "Epoch 225/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1990 - acc: 0.9684 - auROC: 0.9789 - val_loss: 0.2084 - val_acc: 0.9621 - val_auROC: 0.9810\n",
      "Epoch 226/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1988 - acc: 0.9680 - auROC: 0.9788 - val_loss: 0.2081 - val_acc: 0.9621 - val_auROC: 0.9810\n",
      "Epoch 227/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1987 - acc: 0.9684 - auROC: 0.9789 - val_loss: 0.2083 - val_acc: 0.9621 - val_auROC: 0.9811\n",
      "Epoch 228/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1986 - acc: 0.9688 - auROC: 0.9791 - val_loss: 0.2082 - val_acc: 0.9621 - val_auROC: 0.9802\n",
      "Epoch 229/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1983 - acc: 0.9688 - auROC: 0.9791 - val_loss: 0.2078 - val_acc: 0.9621 - val_auROC: 0.9806\n",
      "Epoch 230/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1982 - acc: 0.9676 - auROC: 0.9791 - val_loss: 0.2075 - val_acc: 0.9621 - val_auROC: 0.9807\n",
      "Epoch 231/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1981 - acc: 0.9696 - auROC: 0.9791 - val_loss: 0.2076 - val_acc: 0.9655 - val_auROC: 0.9809\n",
      "Epoch 232/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1981 - acc: 0.9719 - auROC: 0.9793 - val_loss: 0.2076 - val_acc: 0.9655 - val_auROC: 0.9811\n",
      "Epoch 233/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1979 - acc: 0.9712 - auROC: 0.9794 - val_loss: 0.2078 - val_acc: 0.9655 - val_auROC: 0.9816\n",
      "Epoch 234/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1977 - acc: 0.9704 - auROC: 0.9795 - val_loss: 0.2078 - val_acc: 0.9655 - val_auROC: 0.9814\n",
      "Epoch 235/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1975 - acc: 0.9696 - auROC: 0.9794 - val_loss: 0.2074 - val_acc: 0.9655 - val_auROC: 0.9806\n",
      "Epoch 236/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1973 - acc: 0.9696 - auROC: 0.9794 - val_loss: 0.2073 - val_acc: 0.9655 - val_auROC: 0.9807\n",
      "Epoch 237/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1972 - acc: 0.9696 - auROC: 0.9795 - val_loss: 0.2071 - val_acc: 0.9655 - val_auROC: 0.9810\n",
      "Epoch 238/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1970 - acc: 0.9696 - auROC: 0.9796 - val_loss: 0.2069 - val_acc: 0.9655 - val_auROC: 0.9810\n",
      "Epoch 239/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1968 - acc: 0.9688 - auROC: 0.9797 - val_loss: 0.2068 - val_acc: 0.9621 - val_auROC: 0.9809\n",
      "Epoch 240/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1966 - acc: 0.9688 - auROC: 0.9798 - val_loss: 0.2067 - val_acc: 0.9621 - val_auROC: 0.9809\n",
      "Epoch 241/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1965 - acc: 0.9688 - auROC: 0.9798 - val_loss: 0.2066 - val_acc: 0.9621 - val_auROC: 0.9810\n",
      "Epoch 242/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1963 - acc: 0.9692 - auROC: 0.9799 - val_loss: 0.2066 - val_acc: 0.9621 - val_auROC: 0.9811\n",
      "Epoch 243/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1962 - acc: 0.9692 - auROC: 0.9801 - val_loss: 0.2066 - val_acc: 0.9621 - val_auROC: 0.9813\n",
      "Epoch 244/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1960 - acc: 0.9692 - auROC: 0.9801 - val_loss: 0.2063 - val_acc: 0.9655 - val_auROC: 0.9814\n",
      "Epoch 245/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1959 - acc: 0.9692 - auROC: 0.9802 - val_loss: 0.2062 - val_acc: 0.9655 - val_auROC: 0.9813\n",
      "Epoch 246/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1957 - acc: 0.9692 - auROC: 0.9803 - val_loss: 0.2061 - val_acc: 0.9621 - val_auROC: 0.9812\n",
      "Epoch 247/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1956 - acc: 0.9692 - auROC: 0.9803 - val_loss: 0.2057 - val_acc: 0.9655 - val_auROC: 0.9813\n",
      "Epoch 248/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1955 - acc: 0.9700 - auROC: 0.9801 - val_loss: 0.2052 - val_acc: 0.9655 - val_auROC: 0.9813\n",
      "Epoch 249/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1953 - acc: 0.9692 - auROC: 0.9802 - val_loss: 0.2051 - val_acc: 0.9655 - val_auROC: 0.9812\n",
      "Epoch 250/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1952 - acc: 0.9692 - auROC: 0.9802 - val_loss: 0.2052 - val_acc: 0.9690 - val_auROC: 0.9803\n",
      "Epoch 251/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1950 - acc: 0.9704 - auROC: 0.9803 - val_loss: 0.2056 - val_acc: 0.9690 - val_auROC: 0.9799\n",
      "Epoch 252/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1947 - acc: 0.9708 - auROC: 0.9806 - val_loss: 0.2054 - val_acc: 0.9690 - val_auROC: 0.9799\n",
      "Epoch 253/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1946 - acc: 0.9708 - auROC: 0.9807 - val_loss: 0.2051 - val_acc: 0.9690 - val_auROC: 0.9799\n",
      "Epoch 254/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1945 - acc: 0.9700 - auROC: 0.9807 - val_loss: 0.2053 - val_acc: 0.9690 - val_auROC: 0.9798\n",
      "Epoch 255/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1943 - acc: 0.9696 - auROC: 0.9807 - val_loss: 0.2052 - val_acc: 0.9690 - val_auROC: 0.9798\n",
      "Epoch 256/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1942 - acc: 0.9696 - auROC: 0.9807 - val_loss: 0.2045 - val_acc: 0.9690 - val_auROC: 0.9799\n",
      "Epoch 257/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1940 - acc: 0.9696 - auROC: 0.9807 - val_loss: 0.2043 - val_acc: 0.9690 - val_auROC: 0.9812\n",
      "Epoch 258/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1938 - acc: 0.9700 - auROC: 0.9808 - val_loss: 0.2046 - val_acc: 0.9690 - val_auROC: 0.9814\n",
      "Epoch 259/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1940 - acc: 0.9692 - auROC: 0.9809 - val_loss: 0.2040 - val_acc: 0.9655 - val_auROC: 0.9815\n",
      "Epoch 260/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1942 - acc: 0.9680 - auROC: 0.9808 - val_loss: 0.2037 - val_acc: 0.9655 - val_auROC: 0.9813\n",
      "Epoch 261/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1939 - acc: 0.9692 - auROC: 0.9808 - val_loss: 0.2034 - val_acc: 0.9655 - val_auROC: 0.9806\n",
      "Epoch 262/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1935 - acc: 0.9712 - auROC: 0.9808 - val_loss: 0.2029 - val_acc: 0.9690 - val_auROC: 0.9818\n",
      "Epoch 263/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1935 - acc: 0.9715 - auROC: 0.9807 - val_loss: 0.2025 - val_acc: 0.9690 - val_auROC: 0.9825\n",
      "Epoch 264/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1934 - acc: 0.9715 - auROC: 0.9804 - val_loss: 0.2023 - val_acc: 0.9690 - val_auROC: 0.9824\n",
      "Epoch 265/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1931 - acc: 0.9712 - auROC: 0.9806 - val_loss: 0.2026 - val_acc: 0.9690 - val_auROC: 0.9815\n",
      "Epoch 266/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1929 - acc: 0.9712 - auROC: 0.9808 - val_loss: 0.2030 - val_acc: 0.9690 - val_auROC: 0.9821\n",
      "Epoch 267/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1927 - acc: 0.9719 - auROC: 0.9809 - val_loss: 0.2032 - val_acc: 0.9690 - val_auROC: 0.9821\n",
      "Epoch 268/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1926 - acc: 0.9719 - auROC: 0.9809 - val_loss: 0.2029 - val_acc: 0.9690 - val_auROC: 0.9822\n",
      "Epoch 269/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1925 - acc: 0.9723 - auROC: 0.9808 - val_loss: 0.2024 - val_acc: 0.9690 - val_auROC: 0.9823\n",
      "Epoch 270/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1923 - acc: 0.9727 - auROC: 0.9809 - val_loss: 0.2020 - val_acc: 0.9690 - val_auROC: 0.9825\n",
      "Epoch 271/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1921 - acc: 0.9712 - auROC: 0.9810 - val_loss: 0.2018 - val_acc: 0.9690 - val_auROC: 0.9826\n",
      "Epoch 272/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1920 - acc: 0.9727 - auROC: 0.9809 - val_loss: 0.2014 - val_acc: 0.9690 - val_auROC: 0.9827\n",
      "Epoch 273/361\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.1919 - acc: 0.9727 - auROC: 0.9809 - val_loss: 0.2013 - val_acc: 0.9690 - val_auROC: 0.9827\n",
      "Epoch 274/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1917 - acc: 0.9723 - auROC: 0.9809 - val_loss: 0.2011 - val_acc: 0.9690 - val_auROC: 0.9827\n",
      "Epoch 275/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1916 - acc: 0.9723 - auROC: 0.9809 - val_loss: 0.2009 - val_acc: 0.9690 - val_auROC: 0.9827\n",
      "Epoch 276/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1918 - acc: 0.9692 - auROC: 0.9809 - val_loss: 0.2008 - val_acc: 0.9655 - val_auROC: 0.9826\n",
      "Epoch 277/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1919 - acc: 0.9688 - auROC: 0.9807 - val_loss: 0.2008 - val_acc: 0.9655 - val_auROC: 0.9829\n",
      "Epoch 278/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1914 - acc: 0.9712 - auROC: 0.9807 - val_loss: 0.2010 - val_acc: 0.9690 - val_auROC: 0.9829\n",
      "Epoch 279/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1911 - acc: 0.9723 - auROC: 0.9810 - val_loss: 0.2008 - val_acc: 0.9690 - val_auROC: 0.9819\n",
      "Epoch 280/361\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.1909 - acc: 0.9723 - auROC: 0.9812 - val_loss: 0.2006 - val_acc: 0.9724 - val_auROC: 0.9820\n",
      "Epoch 281/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1907 - acc: 0.9727 - auROC: 0.9813 - val_loss: 0.2006 - val_acc: 0.9724 - val_auROC: 0.9828\n",
      "Epoch 282/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1907 - acc: 0.9723 - auROC: 0.9815 - val_loss: 0.2014 - val_acc: 0.9655 - val_auROC: 0.9825\n",
      "Epoch 283/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1908 - acc: 0.9723 - auROC: 0.9817 - val_loss: 0.2008 - val_acc: 0.9690 - val_auROC: 0.9823\n",
      "Epoch 284/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1905 - acc: 0.9727 - auROC: 0.9816 - val_loss: 0.2004 - val_acc: 0.9690 - val_auROC: 0.9824\n",
      "Epoch 285/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1902 - acc: 0.9727 - auROC: 0.9817 - val_loss: 0.2002 - val_acc: 0.9690 - val_auROC: 0.9826\n",
      "Epoch 286/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1900 - acc: 0.9727 - auROC: 0.9818 - val_loss: 0.1997 - val_acc: 0.9690 - val_auROC: 0.9828\n",
      "Epoch 287/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1897 - acc: 0.9735 - auROC: 0.9819 - val_loss: 0.1991 - val_acc: 0.9724 - val_auROC: 0.9828\n",
      "Epoch 288/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1896 - acc: 0.9739 - auROC: 0.9818 - val_loss: 0.1988 - val_acc: 0.9724 - val_auROC: 0.9830\n",
      "Epoch 289/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1895 - acc: 0.9747 - auROC: 0.9820 - val_loss: 0.1981 - val_acc: 0.9724 - val_auROC: 0.9831\n",
      "Epoch 290/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1893 - acc: 0.9739 - auROC: 0.9822 - val_loss: 0.1980 - val_acc: 0.9724 - val_auROC: 0.9831\n",
      "Epoch 291/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1890 - acc: 0.9739 - auROC: 0.9822 - val_loss: 0.1979 - val_acc: 0.9724 - val_auROC: 0.9831\n",
      "Epoch 292/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1887 - acc: 0.9735 - auROC: 0.9822 - val_loss: 0.1980 - val_acc: 0.9759 - val_auROC: 0.9830\n",
      "Epoch 293/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1883 - acc: 0.9743 - auROC: 0.9820 - val_loss: 0.1980 - val_acc: 0.9759 - val_auROC: 0.9830\n",
      "Epoch 294/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1879 - acc: 0.9750 - auROC: 0.9822 - val_loss: 0.1979 - val_acc: 0.9759 - val_auROC: 0.9830\n",
      "Epoch 295/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1874 - acc: 0.9766 - auROC: 0.9824 - val_loss: 0.1984 - val_acc: 0.9759 - val_auROC: 0.9829\n",
      "Epoch 296/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1878 - acc: 0.9747 - auROC: 0.9827 - val_loss: 0.2055 - val_acc: 0.9621 - val_auROC: 0.9826\n",
      "Epoch 297/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1889 - acc: 0.9727 - auROC: 0.9824 - val_loss: 0.2055 - val_acc: 0.9621 - val_auROC: 0.9827\n",
      "Epoch 298/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1876 - acc: 0.9750 - auROC: 0.9832 - val_loss: 0.2022 - val_acc: 0.9621 - val_auROC: 0.9834\n",
      "Epoch 299/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1862 - acc: 0.9782 - auROC: 0.9833 - val_loss: 0.2004 - val_acc: 0.9759 - val_auROC: 0.9830\n",
      "Epoch 300/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1856 - acc: 0.9782 - auROC: 0.9832 - val_loss: 0.1982 - val_acc: 0.9759 - val_auROC: 0.9831\n",
      "Epoch 301/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1858 - acc: 0.9758 - auROC: 0.9828 - val_loss: 0.1957 - val_acc: 0.9690 - val_auROC: 0.9818\n",
      "Epoch 302/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1859 - acc: 0.9758 - auROC: 0.9824 - val_loss: 0.1948 - val_acc: 0.9690 - val_auROC: 0.9827\n",
      "Epoch 303/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1849 - acc: 0.9782 - auROC: 0.9826 - val_loss: 0.1938 - val_acc: 0.9793 - val_auROC: 0.9848\n",
      "Epoch 304/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1844 - acc: 0.9789 - auROC: 0.9827 - val_loss: 0.1937 - val_acc: 0.9793 - val_auROC: 0.9848\n",
      "Epoch 305/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1840 - acc: 0.9786 - auROC: 0.9829 - val_loss: 0.1939 - val_acc: 0.9759 - val_auROC: 0.9841\n",
      "Epoch 306/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1835 - acc: 0.9789 - auROC: 0.9832 - val_loss: 0.1947 - val_acc: 0.9724 - val_auROC: 0.9840\n",
      "Epoch 307/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1834 - acc: 0.9797 - auROC: 0.9832 - val_loss: 0.1945 - val_acc: 0.9759 - val_auROC: 0.9829\n",
      "Epoch 308/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1831 - acc: 0.9797 - auROC: 0.9834 - val_loss: 0.1945 - val_acc: 0.9759 - val_auROC: 0.9822\n",
      "Epoch 309/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1829 - acc: 0.9797 - auROC: 0.9836 - val_loss: 0.1943 - val_acc: 0.9793 - val_auROC: 0.9823\n",
      "Epoch 310/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1827 - acc: 0.9801 - auROC: 0.9836 - val_loss: 0.1940 - val_acc: 0.9793 - val_auROC: 0.9822\n",
      "Epoch 311/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1825 - acc: 0.9797 - auROC: 0.9836 - val_loss: 0.1938 - val_acc: 0.9793 - val_auROC: 0.9822\n",
      "Epoch 312/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1823 - acc: 0.9797 - auROC: 0.9836 - val_loss: 0.1940 - val_acc: 0.9759 - val_auROC: 0.9823\n",
      "Epoch 313/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1822 - acc: 0.9797 - auROC: 0.9837 - val_loss: 0.1939 - val_acc: 0.9759 - val_auROC: 0.9823\n",
      "Epoch 314/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1820 - acc: 0.9797 - auROC: 0.9837 - val_loss: 0.1936 - val_acc: 0.9793 - val_auROC: 0.9826\n",
      "Epoch 315/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1818 - acc: 0.9797 - auROC: 0.9837 - val_loss: 0.1933 - val_acc: 0.9793 - val_auROC: 0.9834\n",
      "Epoch 316/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1817 - acc: 0.9801 - auROC: 0.9837 - val_loss: 0.1930 - val_acc: 0.9793 - val_auROC: 0.9833\n",
      "Epoch 317/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1816 - acc: 0.9801 - auROC: 0.9837 - val_loss: 0.1929 - val_acc: 0.9793 - val_auROC: 0.9833\n",
      "Epoch 318/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1814 - acc: 0.9801 - auROC: 0.9837 - val_loss: 0.1927 - val_acc: 0.9793 - val_auROC: 0.9837\n",
      "Epoch 319/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1814 - acc: 0.9797 - auROC: 0.9837 - val_loss: 0.1930 - val_acc: 0.9759 - val_auROC: 0.9828\n",
      "Epoch 320/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1814 - acc: 0.9801 - auROC: 0.9836 - val_loss: 0.1929 - val_acc: 0.9793 - val_auROC: 0.9829\n",
      "Epoch 321/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1812 - acc: 0.9801 - auROC: 0.9837 - val_loss: 0.1927 - val_acc: 0.9793 - val_auROC: 0.9835\n",
      "Epoch 322/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1811 - acc: 0.9797 - auROC: 0.9838 - val_loss: 0.1926 - val_acc: 0.9793 - val_auROC: 0.9839\n",
      "Epoch 323/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1810 - acc: 0.9801 - auROC: 0.9836 - val_loss: 0.1921 - val_acc: 0.9793 - val_auROC: 0.9831\n",
      "Epoch 324/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1809 - acc: 0.9801 - auROC: 0.9838 - val_loss: 0.1921 - val_acc: 0.9793 - val_auROC: 0.9831\n",
      "Epoch 325/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1807 - acc: 0.9805 - auROC: 0.9839 - val_loss: 0.1920 - val_acc: 0.9793 - val_auROC: 0.9831\n",
      "Epoch 326/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1807 - acc: 0.9789 - auROC: 0.9839 - val_loss: 0.1925 - val_acc: 0.9724 - val_auROC: 0.9827\n",
      "Epoch 327/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1807 - acc: 0.9778 - auROC: 0.9838 - val_loss: 0.1924 - val_acc: 0.9724 - val_auROC: 0.9837\n",
      "Epoch 328/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1804 - acc: 0.9789 - auROC: 0.9839 - val_loss: 0.1922 - val_acc: 0.9793 - val_auROC: 0.9841\n",
      "Epoch 329/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1802 - acc: 0.9793 - auROC: 0.9840 - val_loss: 0.1920 - val_acc: 0.9793 - val_auROC: 0.9831\n",
      "Epoch 330/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1801 - acc: 0.9801 - auROC: 0.9841 - val_loss: 0.1922 - val_acc: 0.9793 - val_auROC: 0.9833\n",
      "Epoch 331/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1800 - acc: 0.9805 - auROC: 0.9841 - val_loss: 0.1920 - val_acc: 0.9793 - val_auROC: 0.9832\n",
      "Epoch 332/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1798 - acc: 0.9805 - auROC: 0.9841 - val_loss: 0.1916 - val_acc: 0.9793 - val_auROC: 0.9839\n",
      "Epoch 333/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1797 - acc: 0.9805 - auROC: 0.9841 - val_loss: 0.1914 - val_acc: 0.9793 - val_auROC: 0.9847\n",
      "Epoch 334/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1796 - acc: 0.9805 - auROC: 0.9842 - val_loss: 0.1912 - val_acc: 0.9793 - val_auROC: 0.9848\n",
      "Epoch 335/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1795 - acc: 0.9805 - auROC: 0.9842 - val_loss: 0.1910 - val_acc: 0.9793 - val_auROC: 0.9848\n",
      "Epoch 336/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1794 - acc: 0.9805 - auROC: 0.9842 - val_loss: 0.1909 - val_acc: 0.9793 - val_auROC: 0.9849\n",
      "Epoch 337/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1793 - acc: 0.9805 - auROC: 0.9842 - val_loss: 0.1911 - val_acc: 0.9793 - val_auROC: 0.9850\n",
      "Epoch 338/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1791 - acc: 0.9805 - auROC: 0.9842 - val_loss: 0.1911 - val_acc: 0.9793 - val_auROC: 0.9850\n",
      "Epoch 339/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1790 - acc: 0.9805 - auROC: 0.9842 - val_loss: 0.1912 - val_acc: 0.9793 - val_auROC: 0.9834\n",
      "Epoch 340/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1789 - acc: 0.9809 - auROC: 0.9843 - val_loss: 0.1912 - val_acc: 0.9793 - val_auROC: 0.9834\n",
      "Epoch 341/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1788 - acc: 0.9809 - auROC: 0.9842 - val_loss: 0.1911 - val_acc: 0.9793 - val_auROC: 0.9834\n",
      "Epoch 342/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1786 - acc: 0.9813 - auROC: 0.9843 - val_loss: 0.1910 - val_acc: 0.9793 - val_auROC: 0.9834\n",
      "Epoch 343/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1785 - acc: 0.9813 - auROC: 0.9843 - val_loss: 0.1908 - val_acc: 0.9793 - val_auROC: 0.9834\n",
      "Epoch 344/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1784 - acc: 0.9813 - auROC: 0.9843 - val_loss: 0.1906 - val_acc: 0.9793 - val_auROC: 0.9834\n",
      "Epoch 345/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1783 - acc: 0.9813 - auROC: 0.9843 - val_loss: 0.1906 - val_acc: 0.9793 - val_auROC: 0.9841\n",
      "Epoch 346/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1782 - acc: 0.9813 - auROC: 0.9843 - val_loss: 0.1908 - val_acc: 0.9793 - val_auROC: 0.9842\n",
      "Epoch 347/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1781 - acc: 0.9813 - auROC: 0.9843 - val_loss: 0.1904 - val_acc: 0.9793 - val_auROC: 0.9844\n",
      "Epoch 348/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1780 - acc: 0.9809 - auROC: 0.9844 - val_loss: 0.1898 - val_acc: 0.9793 - val_auROC: 0.9844\n",
      "Epoch 349/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1779 - acc: 0.9801 - auROC: 0.9844 - val_loss: 0.1896 - val_acc: 0.9793 - val_auROC: 0.9845\n",
      "Epoch 350/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1778 - acc: 0.9801 - auROC: 0.9844 - val_loss: 0.1895 - val_acc: 0.9793 - val_auROC: 0.9846\n",
      "Epoch 351/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1777 - acc: 0.9805 - auROC: 0.9844 - val_loss: 0.1894 - val_acc: 0.9828 - val_auROC: 0.9845\n",
      "Epoch 352/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1776 - acc: 0.9805 - auROC: 0.9844 - val_loss: 0.1894 - val_acc: 0.9828 - val_auROC: 0.9844\n",
      "Epoch 353/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1774 - acc: 0.9817 - auROC: 0.9844 - val_loss: 0.1894 - val_acc: 0.9828 - val_auROC: 0.9844\n",
      "Epoch 354/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1773 - acc: 0.9817 - auROC: 0.9844 - val_loss: 0.1892 - val_acc: 0.9828 - val_auROC: 0.9845\n",
      "Epoch 355/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1772 - acc: 0.9821 - auROC: 0.9844 - val_loss: 0.1889 - val_acc: 0.9828 - val_auROC: 0.9847\n",
      "Epoch 356/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1771 - acc: 0.9821 - auROC: 0.9845 - val_loss: 0.1887 - val_acc: 0.9828 - val_auROC: 0.9845\n",
      "Epoch 357/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1770 - acc: 0.9825 - auROC: 0.9844 - val_loss: 0.1884 - val_acc: 0.9828 - val_auROC: 0.9848\n",
      "Epoch 358/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1769 - acc: 0.9825 - auROC: 0.9845 - val_loss: 0.1879 - val_acc: 0.9828 - val_auROC: 0.9856\n",
      "Epoch 359/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1768 - acc: 0.9825 - auROC: 0.9845 - val_loss: 0.1874 - val_acc: 0.9828 - val_auROC: 0.9855\n",
      "Epoch 360/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1766 - acc: 0.9825 - auROC: 0.9844 - val_loss: 0.1872 - val_acc: 0.9828 - val_auROC: 0.9847\n",
      "Epoch 361/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1765 - acc: 0.9825 - auROC: 0.9844 - val_loss: 0.1872 - val_acc: 0.9828 - val_auROC: 0.9847\n",
      "    0      1      2         3      ...  18014     18015     18016  18017\n",
      "0     0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196532    0.0\n",
      "1     0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196532    0.0\n",
      "2     0.0    0.0    0.0 -0.003108  ...    0.0 -0.198135 -0.196532    0.0\n",
      "3     0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196532    0.0\n",
      "4     0.0    0.0    0.0  0.568505  ...    0.0 -0.198135 -0.196532    0.0\n",
      "..    ...    ...    ...       ...  ...    ...       ...       ...    ...\n",
      "59    0.0    0.0    0.0  3.113146  ...    0.0 -0.198135 -0.196532    0.0\n",
      "60    0.0    0.0    0.0 -0.350212  ...    0.0 -0.198135 -0.196532    0.0\n",
      "61    0.0    0.0    0.0 -0.350911  ...    0.0 -0.198135 -0.196532    0.0\n",
      "62    0.0    0.0    0.0 -0.139348  ...    0.0 -0.198135 -0.196532    0.0\n",
      "63    0.0    0.0    0.0 -0.350679  ...    0.0 -0.198135 -0.196532    0.0\n",
      "\n",
      "[64 rows x 18018 columns]\n",
      "Total NANs in input samples: 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "18013    0\n",
      "18014    0\n",
      "18015    0\n",
      "18016    0\n",
      "18017    0\n",
      "Length: 18018, dtype: int64\n",
      "Reordering labels and prediction result\n",
      "Reordering labels and prediction result for samples\n",
      "Running evaluation...\n",
      "Evaluating biome source: root:CRC (stage 0)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  61   0   1  0.0161  1.0  ...  1.0000  1.0  0.0161  0.0317      1.0    1.0\n",
      "0.01   0  61   0   1  0.0161  1.0  ...  1.0000  1.0  0.0161  0.0317      1.0    1.0\n",
      "0.02   1  59   0   1  0.0328  1.0  ...  0.9833  1.0  0.0167  0.0328      1.0    1.0\n",
      "0.03  17  43   0   1  0.2951  1.0  ...  0.7167  1.0  0.0227  0.0444      1.0    1.0\n",
      "0.04  39  21   0   1  0.6557  1.0  ...  0.3500  1.0  0.0455  0.0870      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  61   0   1   0  0.9839  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  61   0   1   0  0.9839  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  61   0   1   0  0.9839  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  61   0   1   0  0.9839  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  61   0   1   0  0.9839  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage I)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                          \n",
      "0.00   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896      1.0    1.0\n",
      "0.01   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896      1.0    1.0\n",
      "0.02   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896      1.0    1.0\n",
      "0.03   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896      1.0    1.0\n",
      "0.04   0  47   0  15  0.2419  1.0  ...  1.0  1.0  0.2419  0.3896      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...    ...\n",
      "0.97  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  47   0  15   0  0.7581  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage II)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                          \n",
      "0.00   0  54   0   8  0.1290  1.0  ...  1.0  1.0  0.1290  0.2286      1.0    1.0\n",
      "0.01   0  54   0   8  0.1290  1.0  ...  1.0  1.0  0.1290  0.2286      1.0    1.0\n",
      "0.02   0  54   0   8  0.1290  1.0  ...  1.0  1.0  0.1290  0.2286      1.0    1.0\n",
      "0.03   0  54   0   8  0.1290  1.0  ...  1.0  1.0  0.1290  0.2286      1.0    1.0\n",
      "0.04   0  53   0   8  0.1311  1.0  ...  1.0  1.0  0.1311  0.2319      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...    ...\n",
      "0.97  54   0   8   0  0.8710  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  54   0   8   0  0.8710  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  54   0   8   0  0.8710  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  54   0   8   0  0.8710  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  54   0   8   0  0.8710  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage III)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  54   0   8  0.1290  1.0  ...  1.0000  1.0  0.1290  0.2286      1.0    1.0\n",
      "0.01   0  54   0   8  0.1290  1.0  ...  1.0000  1.0  0.1290  0.2286      1.0    1.0\n",
      "0.02   0  53   0   8  0.1311  1.0  ...  1.0000  1.0  0.1311  0.2319      1.0    1.0\n",
      "0.03  26  27   0   8  0.5574  1.0  ...  0.5094  1.0  0.2286  0.3721      1.0    1.0\n",
      "0.04  27  26   0   8  0.5738  1.0  ...  0.4906  1.0  0.2353  0.3810      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  54   0   8   0  0.8710  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage IV)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                           \n",
      "0.00   0  35   0  27  0.4355  1.0  ...  1.0  1.0  0.4355  0.6067   0.9808  0.9804\n",
      "0.01   0  35   0  27  0.4355  1.0  ...  1.0  1.0  0.4355  0.6067   0.9808  0.9804\n",
      "0.02   0  35   0  27  0.4355  1.0  ...  1.0  1.0  0.4355  0.6067   0.9808  0.9804\n",
      "0.03   0  35   0  27  0.4355  1.0  ...  1.0  1.0  0.4355  0.6067   0.9808  0.9804\n",
      "0.04   0  35   0  27  0.4355  1.0  ...  1.0  1.0  0.4355  0.6067   0.9808  0.9804\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...     ...\n",
      "0.97  35   0  27   0  0.5645  0.0  ...  0.0  0.0  0.0000     NaN   0.9808  0.9804\n",
      "0.98  35   0  27   0  0.5645  0.0  ...  0.0  0.0  0.0000     NaN   0.9808  0.9804\n",
      "0.99  35   0  27   0  0.5645  0.0  ...  0.0  0.0  0.0000     NaN   0.9808  0.9804\n",
      "1.00  35   0  27   0  0.5645  0.0  ...  0.0  0.0  0.0000     NaN   0.9808  0.9804\n",
      "1.01  35   0  27   0  0.5645  0.0  ...  0.0  0.0  0.0000     NaN   0.9808  0.9804\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Saving evaluation results...\n",
      "Reordering labels and samples...\n",
      "Total matched samples: 571\n",
      "N. NaN in input features: 0\n",
      "           mean       std\n",
      "0      0.000000  0.000000\n",
      "1      0.000000  0.000000\n",
      "2      0.000000  0.000000\n",
      "3      0.015718  0.044470\n",
      "4      0.015697  0.044456\n",
      "...         ...       ...\n",
      "18013  0.000059  0.000240\n",
      "18014  0.000000  0.000000\n",
      "18015  0.002371  0.011928\n",
      "18016  0.002307  0.011699\n",
      "18017  0.000000  0.000000\n",
      "\n",
      "[18018 rows x 2 columns]\n",
      "Pre-training using Adam with lr=1e-05...\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.7041 - acc: 0.4862 - val_loss: 0.6993 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6933 - acc: 0.5041 - val_loss: 0.6908 - val_acc: 0.5069\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 18018)]           0         \n",
      "_________________________________________________________________\n",
      "base (Sequential)            (None, 512)               18976256  \n",
      "_________________________________________________________________\n",
      "l2_inter (Sequential)        (None, 10)                21550     \n",
      "_________________________________________________________________\n",
      "l2_integration (Sequential)  (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "l2o (Sequential)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 18,998,051\n",
      "Trainable params: 18,998,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training using Adam with lr=0.001...\n",
      "Epoch 3/1002\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 0.6843 - acc: 0.5220 - auROC: 0.4501 - val_loss: 0.6967 - val_acc: 0.6310 - val_auROC: 0.4801\n",
      "Epoch 4/1002\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6680 - acc: 0.6448 - auROC: 0.5211 - val_loss: 0.6494 - val_acc: 0.5690 - val_auROC: 0.5370\n",
      "Epoch 5/1002\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6270 - acc: 0.6023 - auROC: 0.5729 - val_loss: 0.6258 - val_acc: 0.6621 - val_auROC: 0.5268\n",
      "Epoch 6/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5980 - acc: 0.6749 - auROC: 0.5828 - val_loss: 0.5937 - val_acc: 0.7000 - val_auROC: 0.5862\n",
      "Epoch 7/1002\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5773 - acc: 0.7014 - auROC: 0.6262 - val_loss: 0.5726 - val_acc: 0.7207 - val_auROC: 0.5920\n",
      "Epoch 8/1002\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5479 - acc: 0.7306 - auROC: 0.6551 - val_loss: 0.5595 - val_acc: 0.7138 - val_auROC: 0.5912\n",
      "Epoch 9/1002\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5371 - acc: 0.7193 - auROC: 0.6670 - val_loss: 0.5684 - val_acc: 0.7069 - val_auROC: 0.5816\n",
      "Epoch 10/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5276 - acc: 0.7259 - auROC: 0.6706 - val_loss: 0.5422 - val_acc: 0.7448 - val_auROC: 0.6146\n",
      "Epoch 11/1002\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5044 - acc: 0.7618 - auROC: 0.7004 - val_loss: 0.5307 - val_acc: 0.7414 - val_auROC: 0.6394\n",
      "Epoch 12/1002\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4972 - acc: 0.7762 - auROC: 0.7279 - val_loss: 0.5289 - val_acc: 0.7793 - val_auROC: 0.6549\n",
      "Epoch 13/1002\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.4911 - acc: 0.7981 - auROC: 0.7585 - val_loss: 0.5204 - val_acc: 0.7828 - val_auROC: 0.6563\n",
      "Epoch 14/1002\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4817 - acc: 0.8136 - auROC: 0.7627 - val_loss: 0.5126 - val_acc: 0.7793 - val_auROC: 0.6665\n",
      "Epoch 15/1002\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4734 - acc: 0.8222 - auROC: 0.7629 - val_loss: 0.5074 - val_acc: 0.7724 - val_auROC: 0.6702\n",
      "Epoch 16/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4661 - acc: 0.8250 - auROC: 0.7692 - val_loss: 0.5029 - val_acc: 0.7690 - val_auROC: 0.6854\n",
      "Epoch 17/1002\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4605 - acc: 0.8191 - auROC: 0.7741 - val_loss: 0.4967 - val_acc: 0.7862 - val_auROC: 0.6974\n",
      "Epoch 18/1002\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4544 - acc: 0.8238 - auROC: 0.7903 - val_loss: 0.4892 - val_acc: 0.8000 - val_auROC: 0.7063\n",
      "Epoch 19/1002\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4474 - acc: 0.8464 - auROC: 0.8086 - val_loss: 0.4850 - val_acc: 0.8103 - val_auROC: 0.7109\n",
      "Epoch 20/1002\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4415 - acc: 0.8519 - auROC: 0.8145 - val_loss: 0.4783 - val_acc: 0.8103 - val_auROC: 0.7237\n",
      "Epoch 21/1002\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4392 - acc: 0.8499 - auROC: 0.8151 - val_loss: 0.4800 - val_acc: 0.7966 - val_auROC: 0.7163\n",
      "Epoch 22/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4344 - acc: 0.8487 - auROC: 0.8168 - val_loss: 0.4785 - val_acc: 0.7897 - val_auROC: 0.7178\n",
      "Epoch 23/1002\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4289 - acc: 0.8522 - auROC: 0.8228 - val_loss: 0.4773 - val_acc: 0.7931 - val_auROC: 0.7224\n",
      "Epoch 24/1002\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4254 - acc: 0.8589 - auROC: 0.8297 - val_loss: 0.4744 - val_acc: 0.7862 - val_auROC: 0.7252\n",
      "Epoch 25/1002\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4218 - acc: 0.8624 - auROC: 0.8342 - val_loss: 0.4663 - val_acc: 0.7931 - val_auROC: 0.7359\n",
      "Epoch 26/1002\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4179 - acc: 0.8620 - auROC: 0.8377 - val_loss: 0.4660 - val_acc: 0.8000 - val_auROC: 0.7405\n",
      "Epoch 27/1002\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4156 - acc: 0.8593 - auROC: 0.8374 - val_loss: 0.4618 - val_acc: 0.7897 - val_auROC: 0.7462\n",
      "Epoch 28/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4123 - acc: 0.8585 - auROC: 0.8420 - val_loss: 0.4587 - val_acc: 0.8034 - val_auROC: 0.7555\n",
      "Epoch 29/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4082 - acc: 0.8690 - auROC: 0.8505 - val_loss: 0.4512 - val_acc: 0.8241 - val_auROC: 0.7652\n",
      "Epoch 30/1002\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4047 - acc: 0.8667 - auROC: 0.8566 - val_loss: 0.4479 - val_acc: 0.8138 - val_auROC: 0.7663\n",
      "Epoch 31/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4021 - acc: 0.8608 - auROC: 0.8565 - val_loss: 0.4482 - val_acc: 0.8138 - val_auROC: 0.7705\n",
      "Epoch 32/1002\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3985 - acc: 0.8655 - auROC: 0.8622 - val_loss: 0.4463 - val_acc: 0.8241 - val_auROC: 0.7659\n",
      "Epoch 33/1002\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3968 - acc: 0.8698 - auROC: 0.8623 - val_loss: 0.4431 - val_acc: 0.8172 - val_auROC: 0.7691\n",
      "Epoch 34/1002\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3939 - acc: 0.8632 - auROC: 0.8643 - val_loss: 0.4413 - val_acc: 0.8172 - val_auROC: 0.7720\n",
      "Epoch 35/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3901 - acc: 0.8671 - auROC: 0.8687 - val_loss: 0.4421 - val_acc: 0.8276 - val_auROC: 0.7683\n",
      "Epoch 36/1002\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.3881 - acc: 0.8784 - auROC: 0.8721 - val_loss: 0.4362 - val_acc: 0.8172 - val_auROC: 0.7798\n",
      "Epoch 37/1002\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.3848 - acc: 0.8791 - auROC: 0.8756 - val_loss: 0.4319 - val_acc: 0.8138 - val_auROC: 0.7891\n",
      "Epoch 38/1002\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.3829 - acc: 0.8752 - auROC: 0.8754 - val_loss: 0.4286 - val_acc: 0.8310 - val_auROC: 0.7944\n",
      "Epoch 39/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3792 - acc: 0.8854 - auROC: 0.8804 - val_loss: 0.4293 - val_acc: 0.8379 - val_auROC: 0.7924\n",
      "Epoch 40/1002\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.3775 - acc: 0.8904 - auROC: 0.8831 - val_loss: 0.4265 - val_acc: 0.8276 - val_auROC: 0.7936\n",
      "Epoch 41/1002\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.3739 - acc: 0.8873 - auROC: 0.8840 - val_loss: 0.4198 - val_acc: 0.8207 - val_auROC: 0.8041\n",
      "Epoch 42/1002\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.3715 - acc: 0.8881 - auROC: 0.8847 - val_loss: 0.4148 - val_acc: 0.8345 - val_auROC: 0.8198\n",
      "Epoch 43/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3689 - acc: 0.8963 - auROC: 0.8919 - val_loss: 0.4185 - val_acc: 0.8483 - val_auROC: 0.8076\n",
      "Epoch 44/1002\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.3665 - acc: 0.9025 - auROC: 0.8926 - val_loss: 0.4142 - val_acc: 0.8483 - val_auROC: 0.8135\n",
      "Epoch 45/1002\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3647 - acc: 0.9006 - auROC: 0.8929 - val_loss: 0.4104 - val_acc: 0.8483 - val_auROC: 0.8185\n",
      "Epoch 46/1002\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3615 - acc: 0.8990 - auROC: 0.8945 - val_loss: 0.4081 - val_acc: 0.8379 - val_auROC: 0.8195\n",
      "Epoch 47/1002\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3587 - acc: 0.8904 - auROC: 0.8952 - val_loss: 0.3970 - val_acc: 0.8414 - val_auROC: 0.8464\n",
      "Epoch 48/1002\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3545 - acc: 0.8943 - auROC: 0.9006 - val_loss: 0.3947 - val_acc: 0.8483 - val_auROC: 0.8488\n",
      "Epoch 49/1002\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3519 - acc: 0.8975 - auROC: 0.9015 - val_loss: 0.4002 - val_acc: 0.8552 - val_auROC: 0.8354\n",
      "Epoch 50/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3497 - acc: 0.8955 - auROC: 0.9050 - val_loss: 0.4039 - val_acc: 0.8483 - val_auROC: 0.8291\n",
      "Epoch 51/1002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3477 - acc: 0.8943 - auROC: 0.9049 - val_loss: 0.4051 - val_acc: 0.8448 - val_auROC: 0.8245\n",
      "Epoch 52/1002\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3453 - acc: 0.8959 - auROC: 0.9056 - val_loss: 0.4022 - val_acc: 0.8483 - val_auROC: 0.8328\n",
      "Epoch 53/1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3435 - acc: 0.8971 - auROC: 0.9102\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3435 - acc: 0.8971 - auROC: 0.9102 - val_loss: 0.3949 - val_acc: 0.8517 - val_auROC: 0.8466\n",
      "Epoch 54/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3425 - acc: 0.9018 - auROC: 0.9103 - val_loss: 0.3950 - val_acc: 0.8517 - val_auROC: 0.8458\n",
      "Epoch 55/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3410 - acc: 0.9025 - auROC: 0.9116 - val_loss: 0.3986 - val_acc: 0.8552 - val_auROC: 0.8385\n",
      "Epoch 56/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3396 - acc: 0.9025 - auROC: 0.9130 - val_loss: 0.3994 - val_acc: 0.8552 - val_auROC: 0.8374\n",
      "Epoch 57/1002\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3393 - acc: 0.9010 - auROC: 0.9130 - val_loss: 0.3992 - val_acc: 0.8552 - val_auROC: 0.8372\n",
      "Epoch 58/1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3393 - acc: 0.9006 - auROC: 0.9122\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3393 - acc: 0.9006 - auROC: 0.9122 - val_loss: 0.3988 - val_acc: 0.8586 - val_auROC: 0.8368\n",
      "Epoch 59/1002\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3390 - acc: 0.9010 - auROC: 0.9123 - val_loss: 0.3988 - val_acc: 0.8586 - val_auROC: 0.8372\n",
      "Epoch 60/1002\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3389 - acc: 0.9010 - auROC: 0.9123 - val_loss: 0.3987 - val_acc: 0.8586 - val_auROC: 0.8374\n",
      "Epoch 61/1002\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3388 - acc: 0.9014 - auROC: 0.9126 - val_loss: 0.3986 - val_acc: 0.8586 - val_auROC: 0.8378\n",
      "Epoch 62/1002\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3387 - acc: 0.9014 - auROC: 0.9128 - val_loss: 0.3985 - val_acc: 0.8586 - val_auROC: 0.8381\n",
      "Epoch 63/1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3385 - acc: 0.9018 - auROC: 0.9129\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3385 - acc: 0.9018 - auROC: 0.9129 - val_loss: 0.3984 - val_acc: 0.8586 - val_auROC: 0.8383\n",
      "Epoch 00063: early stopping\n",
      "    0      1      2         3      ...  18014     18015   18016  18017\n",
      "0     0.0    0.0    0.0 -0.353447  ...    0.0 -0.198786 -0.1972    0.0\n",
      "1     0.0    0.0    0.0 -0.353447  ...    0.0 -0.198786 -0.1972    0.0\n",
      "2     0.0    0.0    0.0  0.042439  ...    0.0 -0.198786 -0.1972    0.0\n",
      "3     0.0    0.0    0.0 -0.353447  ...    0.0 -0.198786 -0.1972    0.0\n",
      "4     0.0    0.0    0.0 -0.353447  ...    0.0 -0.198786 -0.1972    0.0\n",
      "..    ...    ...    ...       ...  ...    ...       ...     ...    ...\n",
      "59    0.0    0.0    0.0 -0.353447  ...    0.0 -0.198786 -0.1972    0.0\n",
      "60    0.0    0.0    0.0 -0.353447  ...    0.0 -0.198786 -0.1972    0.0\n",
      "61    0.0    0.0    0.0 -0.353447  ...    0.0 -0.198786 -0.1972    0.0\n",
      "62    0.0    0.0    0.0  1.044470  ...    0.0 -0.198786 -0.1972    0.0\n",
      "63    0.0    0.0    0.0 -0.353447  ...    0.0 -0.198786 -0.1972    0.0\n",
      "\n",
      "[64 rows x 18018 columns]\n",
      "Total NANs in input samples: 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "18013    0\n",
      "18014    0\n",
      "18015    0\n",
      "18016    0\n",
      "18017    0\n",
      "Length: 18018, dtype: int64\n",
      "Reordering labels and prediction result\n",
      "Reordering labels and prediction result for samples\n",
      "Running evaluation...\n",
      "Evaluating biome source: root:CRC (stage 0)\n",
      "      TN  FP  FN  TP  Acc   Sn   Sp  TPR  FPR   Rc   Pr  F1  ROC-AUC  F-max\n",
      "t                                                                          \n",
      "0.00   0  62   0   0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.01   0  62   0   0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.02   0  62   0   0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.03   0  62   0   0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.04   0  62   0   0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 NaN      0.0    NaN\n",
      "...   ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...  ..      ...    ...\n",
      "0.97  62   0   0   0  1.0  0.0  1.0  0.0  0.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.98  62   0   0   0  1.0  0.0  1.0  0.0  0.0  0.0  0.0 NaN      0.0    NaN\n",
      "0.99  62   0   0   0  1.0  0.0  1.0  0.0  0.0  0.0  0.0 NaN      0.0    NaN\n",
      "1.00  62   0   0   0  1.0  0.0  1.0  0.0  0.0  0.0  0.0 NaN      0.0    NaN\n",
      "1.01  62   0   0   0  1.0  0.0  1.0  0.0  0.0  0.0  0.0 NaN      0.0    NaN\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage I)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr     F1  ROC-AUC   F-max\n",
      "t                                  ...                                          \n",
      "0.00   0  41   0  21  0.3387  1.0  ...  1.0  1.0  0.3387  0.506   0.8863  0.8333\n",
      "0.01   0  41   0  21  0.3387  1.0  ...  1.0  1.0  0.3387  0.506   0.8863  0.8333\n",
      "0.02   0  41   0  21  0.3387  1.0  ...  1.0  1.0  0.3387  0.506   0.8863  0.8333\n",
      "0.03   0  41   0  21  0.3387  1.0  ...  1.0  1.0  0.3387  0.506   0.8863  0.8333\n",
      "0.04   0  41   0  21  0.3387  1.0  ...  1.0  1.0  0.3387  0.506   0.8863  0.8333\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...    ...      ...     ...\n",
      "0.97  41   0  21   0  0.6613  0.0  ...  0.0  0.0  0.0000    NaN   0.8863  0.8333\n",
      "0.98  41   0  21   0  0.6613  0.0  ...  0.0  0.0  0.0000    NaN   0.8863  0.8333\n",
      "0.99  41   0  21   0  0.6613  0.0  ...  0.0  0.0  0.0000    NaN   0.8863  0.8333\n",
      "1.00  41   0  21   0  0.6613  0.0  ...  0.0  0.0  0.0000    NaN   0.8863  0.8333\n",
      "1.01  41   0  21   0  0.6613  0.0  ...  0.0  0.0  0.0000    NaN   0.8863  0.8333\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage II)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                          \n",
      "0.00   0  49   0  13  0.2097  1.0  ...  1.0  1.0  0.2097  0.3467   0.9618   0.88\n",
      "0.01   0  49   0  13  0.2097  1.0  ...  1.0  1.0  0.2097  0.3467   0.9618   0.88\n",
      "0.02   0  49   0  13  0.2097  1.0  ...  1.0  1.0  0.2097  0.3467   0.9618   0.88\n",
      "0.03   0  49   0  13  0.2097  1.0  ...  1.0  1.0  0.2097  0.3467   0.9618   0.88\n",
      "0.04   0  49   0  13  0.2097  1.0  ...  1.0  1.0  0.2097  0.3467   0.9618   0.88\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...    ...\n",
      "0.97  49   0  13   0  0.7903  0.0  ...  0.0  0.0  0.0000     NaN   0.9618   0.88\n",
      "0.98  49   0  13   0  0.7903  0.0  ...  0.0  0.0  0.0000     NaN   0.9618   0.88\n",
      "0.99  49   0  13   0  0.7903  0.0  ...  0.0  0.0  0.0000     NaN   0.9618   0.88\n",
      "1.00  49   0  13   0  0.7903  0.0  ...  0.0  0.0  0.0000     NaN   0.9618   0.88\n",
      "1.01  49   0  13   0  0.7903  0.0  ...  0.0  0.0  0.0000     NaN   0.9618   0.88\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage III)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765   0.9873    0.8\n",
      "0.01   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765   0.9873    0.8\n",
      "0.02   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765   0.9873    0.8\n",
      "0.03   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765   0.9873    0.8\n",
      "0.04   8  47   0   6  0.2295  1.0  ...  0.8545  1.0  0.1132  0.2034   0.9873    0.8\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN   0.9873    0.8\n",
      "0.98  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN   0.9873    0.8\n",
      "0.99  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN   0.9873    0.8\n",
      "1.00  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN   0.9873    0.8\n",
      "1.01  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN   0.9873    0.8\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage IV)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                           \n",
      "0.00   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9504  0.8485\n",
      "0.01   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9504  0.8485\n",
      "0.02   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9504  0.8485\n",
      "0.03   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9504  0.8485\n",
      "0.04   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9504  0.8485\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...     ...\n",
      "0.97  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9504  0.8485\n",
      "0.98  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9504  0.8485\n",
      "0.99  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9504  0.8485\n",
      "1.00  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9504  0.8485\n",
      "1.01  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9504  0.8485\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Saving evaluation results...\n",
      "Reordering labels and samples...\n",
      "Total matched samples: 571\n",
      "Total correct samples: 571?571\n",
      "           mean       std\n",
      "0      0.000000  0.000000\n",
      "1      0.000000  0.000000\n",
      "2      0.000000  0.000000\n",
      "3      0.015718  0.044470\n",
      "4      0.015697  0.044456\n",
      "...         ...       ...\n",
      "18013  0.000059  0.000240\n",
      "18014  0.000000  0.000000\n",
      "18015  0.002371  0.011928\n",
      "18016  0.002307  0.011699\n",
      "18017  0.000000  0.000000\n",
      "\n",
      "[18018 rows x 2 columns]\n",
      "Training using optimizer with lr=0.001...\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6843 - acc: 0.5930 - auROC: 0.4701 - val_loss: 0.5995 - val_acc: 0.6793 - val_auROC: 0.5532\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.5967 - acc: 0.6893 - auROC: 0.5522 - val_loss: 0.5533 - val_acc: 0.7655 - val_auROC: 0.6192\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.5382 - acc: 0.7524 - auROC: 0.6371 - val_loss: 0.5257 - val_acc: 0.7724 - val_auROC: 0.6513\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.5119 - acc: 0.7758 - auROC: 0.6826 - val_loss: 0.5103 - val_acc: 0.7828 - val_auROC: 0.6541\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4921 - acc: 0.7910 - auROC: 0.7032 - val_loss: 0.4828 - val_acc: 0.8034 - val_auROC: 0.7050\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4721 - acc: 0.7793 - auROC: 0.7528 - val_loss: 0.4790 - val_acc: 0.7966 - val_auROC: 0.6911\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4618 - acc: 0.8047 - auROC: 0.7480 - val_loss: 0.4629 - val_acc: 0.7966 - val_auROC: 0.7355\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4499 - acc: 0.8074 - auROC: 0.7807 - val_loss: 0.4515 - val_acc: 0.8103 - val_auROC: 0.7440\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4349 - acc: 0.8148 - auROC: 0.7938 - val_loss: 0.4333 - val_acc: 0.8172 - val_auROC: 0.7711\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4186 - acc: 0.8234 - auROC: 0.8173 - val_loss: 0.4231 - val_acc: 0.8207 - val_auROC: 0.7956\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4071 - acc: 0.8261 - auROC: 0.8395 - val_loss: 0.4074 - val_acc: 0.8310 - val_auROC: 0.8182\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3980 - acc: 0.8253 - auROC: 0.8502 - val_loss: 0.4002 - val_acc: 0.8345 - val_auROC: 0.8306\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3869 - acc: 0.8413 - auROC: 0.8691 - val_loss: 0.4053 - val_acc: 0.8310 - val_auROC: 0.8159\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3750 - acc: 0.8476 - auROC: 0.8846 - val_loss: 0.3979 - val_acc: 0.8276 - val_auROC: 0.8284\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3766 - acc: 0.8417 - auROC: 0.8753 - val_loss: 0.4038 - val_acc: 0.8310 - val_auROC: 0.8156\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3671 - acc: 0.8526 - auROC: 0.8878 - val_loss: 0.3967 - val_acc: 0.8310 - val_auROC: 0.8289\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3621 - acc: 0.8667 - auROC: 0.8923 - val_loss: 0.3967 - val_acc: 0.8345 - val_auROC: 0.8220\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3613 - acc: 0.8608 - auROC: 0.8893 - val_loss: 0.3882 - val_acc: 0.8379 - val_auROC: 0.8321\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3526 - acc: 0.8655 - auROC: 0.9010 - val_loss: 0.3854 - val_acc: 0.8448 - val_auROC: 0.8364\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3533 - acc: 0.8686 - auROC: 0.8955 - val_loss: 0.3886 - val_acc: 0.8379 - val_auROC: 0.8207\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3538 - acc: 0.8643 - auROC: 0.8887 - val_loss: 0.3970 - val_acc: 0.8345 - val_auROC: 0.8082\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3475 - acc: 0.8686 - auROC: 0.8982 - val_loss: 0.3987 - val_acc: 0.8483 - val_auROC: 0.7996\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3447 - acc: 0.8698 - auROC: 0.8960 - val_loss: 0.3882 - val_acc: 0.8448 - val_auROC: 0.8218\n",
      "Epoch 24/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.3760 - acc: 0.8590 - auROC: 0.8574\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3757 - acc: 0.8593 - auROC: 0.8578 - val_loss: 0.3970 - val_acc: 0.8517 - val_auROC: 0.8112\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3736 - acc: 0.8604 - auROC: 0.8592 - val_loss: 0.3957 - val_acc: 0.8448 - val_auROC: 0.8113\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3705 - acc: 0.8647 - auROC: 0.8629 - val_loss: 0.3886 - val_acc: 0.8483 - val_auROC: 0.8248\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3664 - acc: 0.8694 - auROC: 0.8676 - val_loss: 0.3848 - val_acc: 0.8517 - val_auROC: 0.8317\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3641 - acc: 0.8725 - auROC: 0.8701 - val_loss: 0.3826 - val_acc: 0.8448 - val_auROC: 0.8343\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3610 - acc: 0.8710 - auROC: 0.8736 - val_loss: 0.3798 - val_acc: 0.8483 - val_auROC: 0.8361\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3588 - acc: 0.8698 - auROC: 0.8771 - val_loss: 0.3788 - val_acc: 0.8483 - val_auROC: 0.8367\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3570 - acc: 0.8702 - auROC: 0.8790 - val_loss: 0.3778 - val_acc: 0.8483 - val_auROC: 0.8381\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3551 - acc: 0.8690 - auROC: 0.8813 - val_loss: 0.3770 - val_acc: 0.8483 - val_auROC: 0.8384\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3536 - acc: 0.8702 - auROC: 0.8831 - val_loss: 0.3764 - val_acc: 0.8483 - val_auROC: 0.8387\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3524 - acc: 0.8706 - auROC: 0.8841 - val_loss: 0.3760 - val_acc: 0.8448 - val_auROC: 0.8384\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3509 - acc: 0.8694 - auROC: 0.8858 - val_loss: 0.3760 - val_acc: 0.8448 - val_auROC: 0.8368\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3494 - acc: 0.8682 - auROC: 0.8872 - val_loss: 0.3753 - val_acc: 0.8483 - val_auROC: 0.8372\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3484 - acc: 0.8690 - auROC: 0.8882 - val_loss: 0.3745 - val_acc: 0.8483 - val_auROC: 0.8370\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3474 - acc: 0.8686 - auROC: 0.8893 - val_loss: 0.3735 - val_acc: 0.8483 - val_auROC: 0.8381\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3465 - acc: 0.8725 - auROC: 0.8905 - val_loss: 0.3726 - val_acc: 0.8483 - val_auROC: 0.8385\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3454 - acc: 0.8729 - auROC: 0.8908 - val_loss: 0.3724 - val_acc: 0.8448 - val_auROC: 0.8384\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3447 - acc: 0.8733 - auROC: 0.8908 - val_loss: 0.3728 - val_acc: 0.8448 - val_auROC: 0.8372\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3435 - acc: 0.8752 - auROC: 0.8922 - val_loss: 0.3725 - val_acc: 0.8483 - val_auROC: 0.8377\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3421 - acc: 0.8760 - auROC: 0.8943 - val_loss: 0.3708 - val_acc: 0.8483 - val_auROC: 0.8402\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3407 - acc: 0.8784 - auROC: 0.8961 - val_loss: 0.3685 - val_acc: 0.8483 - val_auROC: 0.8414\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3390 - acc: 0.8776 - auROC: 0.8982 - val_loss: 0.3683 - val_acc: 0.8483 - val_auROC: 0.8417\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3373 - acc: 0.8768 - auROC: 0.9000 - val_loss: 0.3680 - val_acc: 0.8483 - val_auROC: 0.8433\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3357 - acc: 0.8772 - auROC: 0.9019 - val_loss: 0.3666 - val_acc: 0.8448 - val_auROC: 0.8435\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3340 - acc: 0.8772 - auROC: 0.9041 - val_loss: 0.3679 - val_acc: 0.8483 - val_auROC: 0.8407\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3331 - acc: 0.8795 - auROC: 0.9051 - val_loss: 0.3695 - val_acc: 0.8483 - val_auROC: 0.8388\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3324 - acc: 0.8780 - auROC: 0.9057 - val_loss: 0.3678 - val_acc: 0.8414 - val_auROC: 0.8410\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3324 - acc: 0.8803 - auROC: 0.9045 - val_loss: 0.3677 - val_acc: 0.8414 - val_auROC: 0.8418\n",
      "Epoch 52/300\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.3299 - acc: 0.8830 - auROC: 0.9076\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3306 - acc: 0.8823 - auROC: 0.9065 - val_loss: 0.3702 - val_acc: 0.8414 - val_auROC: 0.8373\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3289 - acc: 0.8834 - auROC: 0.9093 - val_loss: 0.3701 - val_acc: 0.8448 - val_auROC: 0.8372\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3288 - acc: 0.8834 - auROC: 0.9095 - val_loss: 0.3699 - val_acc: 0.8448 - val_auROC: 0.8372\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3287 - acc: 0.8834 - auROC: 0.9097 - val_loss: 0.3696 - val_acc: 0.8448 - val_auROC: 0.8374\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3285 - acc: 0.8834 - auROC: 0.9098 - val_loss: 0.3695 - val_acc: 0.8448 - val_auROC: 0.8374\n",
      "Epoch 57/300\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.3284 - acc: 0.8826 - auROC: 0.9092\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3284 - acc: 0.8830 - auROC: 0.9099 - val_loss: 0.3692 - val_acc: 0.8448 - val_auROC: 0.8378\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3283 - acc: 0.8830 - auROC: 0.9101 - val_loss: 0.3690 - val_acc: 0.8448 - val_auROC: 0.8378\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3282 - acc: 0.8830 - auROC: 0.9103 - val_loss: 0.3688 - val_acc: 0.8448 - val_auROC: 0.8386\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3280 - acc: 0.8830 - auROC: 0.9103 - val_loss: 0.3687 - val_acc: 0.8448 - val_auROC: 0.8385\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3279 - acc: 0.8830 - auROC: 0.9106 - val_loss: 0.3685 - val_acc: 0.8448 - val_auROC: 0.8383\n",
      "Epoch 62/300\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.3262 - acc: 0.8853 - auROC: 0.9124Restoring model weights from the end of the best epoch.\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3278 - acc: 0.8834 - auROC: 0.9107 - val_loss: 0.3680 - val_acc: 0.8448 - val_auROC: 0.8388\n",
      "Epoch 00062: early stopping\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 18018)]           0         \n",
      "_________________________________________________________________\n",
      "base (Sequential)            (None, 512)               18976256  \n",
      "_________________________________________________________________\n",
      "l2_inter (Sequential)        (None, 10)                21550     \n",
      "_________________________________________________________________\n",
      "l2_integration (Sequential)  (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "l2o (Sequential)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 18,998,051\n",
      "Trainable params: 21,795\n",
      "Non-trainable params: 18,976,256\n",
      "_________________________________________________________________\n",
      "Fine-tuning using optimizer with lr=1e-05...\n",
      "Epoch 62/361\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.3340 - acc: 0.8776 - auROC: 0.9037 - val_loss: 0.3674 - val_acc: 0.8448 - val_auROC: 0.8420\n",
      "Epoch 63/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3316 - acc: 0.8795 - auROC: 0.9075 - val_loss: 0.3668 - val_acc: 0.8448 - val_auROC: 0.8424\n",
      "Epoch 64/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3299 - acc: 0.8795 - auROC: 0.9097 - val_loss: 0.3650 - val_acc: 0.8483 - val_auROC: 0.8447\n",
      "Epoch 65/361\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.3279 - acc: 0.8811 - auROC: 0.9124 - val_loss: 0.3636 - val_acc: 0.8483 - val_auROC: 0.8471\n",
      "Epoch 66/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3269 - acc: 0.8827 - auROC: 0.9134 - val_loss: 0.3619 - val_acc: 0.8483 - val_auROC: 0.8490\n",
      "Epoch 67/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3260 - acc: 0.8830 - auROC: 0.9146 - val_loss: 0.3623 - val_acc: 0.8517 - val_auROC: 0.8494\n",
      "Epoch 68/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3252 - acc: 0.8823 - auROC: 0.9154 - val_loss: 0.3622 - val_acc: 0.8517 - val_auROC: 0.8481\n",
      "Epoch 69/361\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.3243 - acc: 0.8854 - auROC: 0.9163 - val_loss: 0.3614 - val_acc: 0.8552 - val_auROC: 0.8488\n",
      "Epoch 70/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3234 - acc: 0.8862 - auROC: 0.9170 - val_loss: 0.3607 - val_acc: 0.8552 - val_auROC: 0.8491\n",
      "Epoch 71/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3226 - acc: 0.8885 - auROC: 0.9176 - val_loss: 0.3599 - val_acc: 0.8552 - val_auROC: 0.8505\n",
      "Epoch 72/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3220 - acc: 0.8893 - auROC: 0.9182 - val_loss: 0.3592 - val_acc: 0.8483 - val_auROC: 0.8520\n",
      "Epoch 73/361\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3213 - acc: 0.8897 - auROC: 0.9188 - val_loss: 0.3585 - val_acc: 0.8483 - val_auROC: 0.8528\n",
      "Epoch 74/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3207 - acc: 0.8897 - auROC: 0.9192 - val_loss: 0.3577 - val_acc: 0.8483 - val_auROC: 0.8528\n",
      "Epoch 75/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3197 - acc: 0.8908 - auROC: 0.9204 - val_loss: 0.3573 - val_acc: 0.8483 - val_auROC: 0.8536\n",
      "Epoch 76/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3191 - acc: 0.8916 - auROC: 0.9208 - val_loss: 0.3570 - val_acc: 0.8483 - val_auROC: 0.8533\n",
      "Epoch 77/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3185 - acc: 0.8924 - auROC: 0.9212 - val_loss: 0.3560 - val_acc: 0.8517 - val_auROC: 0.8538\n",
      "Epoch 78/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3171 - acc: 0.8940 - auROC: 0.9228 - val_loss: 0.3544 - val_acc: 0.8552 - val_auROC: 0.8562\n",
      "Epoch 79/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3161 - acc: 0.8947 - auROC: 0.9230 - val_loss: 0.3539 - val_acc: 0.8552 - val_auROC: 0.8571\n",
      "Epoch 80/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3137 - acc: 0.8967 - auROC: 0.9255 - val_loss: 0.3522 - val_acc: 0.8552 - val_auROC: 0.8585\n",
      "Epoch 81/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3121 - acc: 0.8975 - auROC: 0.9273 - val_loss: 0.3505 - val_acc: 0.8552 - val_auROC: 0.8603\n",
      "Epoch 82/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3110 - acc: 0.8986 - auROC: 0.9283 - val_loss: 0.3502 - val_acc: 0.8552 - val_auROC: 0.8594\n",
      "Epoch 83/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3103 - acc: 0.8990 - auROC: 0.9289 - val_loss: 0.3499 - val_acc: 0.8552 - val_auROC: 0.8596\n",
      "Epoch 84/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3098 - acc: 0.8994 - auROC: 0.9292 - val_loss: 0.3496 - val_acc: 0.8552 - val_auROC: 0.8602\n",
      "Epoch 85/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3094 - acc: 0.9010 - auROC: 0.9292 - val_loss: 0.3499 - val_acc: 0.8552 - val_auROC: 0.8584\n",
      "Epoch 86/361\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3089 - acc: 0.9021 - auROC: 0.9296 - val_loss: 0.3497 - val_acc: 0.8552 - val_auROC: 0.8592\n",
      "Epoch 87/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3084 - acc: 0.9018 - auROC: 0.9303 - val_loss: 0.3496 - val_acc: 0.8552 - val_auROC: 0.8594\n",
      "Epoch 88/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3078 - acc: 0.9025 - auROC: 0.9307 - val_loss: 0.3490 - val_acc: 0.8552 - val_auROC: 0.8610\n",
      "Epoch 89/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3070 - acc: 0.9033 - auROC: 0.9315 - val_loss: 0.3486 - val_acc: 0.8552 - val_auROC: 0.8619\n",
      "Epoch 90/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3064 - acc: 0.9021 - auROC: 0.9322 - val_loss: 0.3484 - val_acc: 0.8517 - val_auROC: 0.8615\n",
      "Epoch 91/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3059 - acc: 0.9021 - auROC: 0.9328 - val_loss: 0.3479 - val_acc: 0.8552 - val_auROC: 0.8623\n",
      "Epoch 92/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3057 - acc: 0.9014 - auROC: 0.9332 - val_loss: 0.3475 - val_acc: 0.8552 - val_auROC: 0.8623\n",
      "Epoch 93/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3055 - acc: 0.9014 - auROC: 0.9335 - val_loss: 0.3474 - val_acc: 0.8552 - val_auROC: 0.8628\n",
      "Epoch 94/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3047 - acc: 0.9014 - auROC: 0.9344 - val_loss: 0.3473 - val_acc: 0.8517 - val_auROC: 0.8633\n",
      "Epoch 95/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3038 - acc: 0.9025 - auROC: 0.9351 - val_loss: 0.3466 - val_acc: 0.8448 - val_auROC: 0.8646\n",
      "Epoch 96/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3032 - acc: 0.9041 - auROC: 0.9358 - val_loss: 0.3459 - val_acc: 0.8483 - val_auROC: 0.8659\n",
      "Epoch 97/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3028 - acc: 0.9037 - auROC: 0.9362 - val_loss: 0.3459 - val_acc: 0.8483 - val_auROC: 0.8653\n",
      "Epoch 98/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3025 - acc: 0.9029 - auROC: 0.9366 - val_loss: 0.3459 - val_acc: 0.8483 - val_auROC: 0.8652\n",
      "Epoch 99/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3019 - acc: 0.9021 - auROC: 0.9373 - val_loss: 0.3455 - val_acc: 0.8483 - val_auROC: 0.8650\n",
      "Epoch 100/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3014 - acc: 0.9021 - auROC: 0.9379 - val_loss: 0.3445 - val_acc: 0.8483 - val_auROC: 0.8684\n",
      "Epoch 101/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3009 - acc: 0.9037 - auROC: 0.9383 - val_loss: 0.3439 - val_acc: 0.8483 - val_auROC: 0.8685\n",
      "Epoch 102/361\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3006 - acc: 0.9041 - auROC: 0.9386 - val_loss: 0.3445 - val_acc: 0.8483 - val_auROC: 0.8654\n",
      "Epoch 103/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3003 - acc: 0.9045 - auROC: 0.9389 - val_loss: 0.3452 - val_acc: 0.8517 - val_auROC: 0.8641\n",
      "Epoch 104/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3000 - acc: 0.9041 - auROC: 0.9391 - val_loss: 0.3440 - val_acc: 0.8517 - val_auROC: 0.8646\n",
      "Epoch 105/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2994 - acc: 0.9053 - auROC: 0.9398 - val_loss: 0.3431 - val_acc: 0.8483 - val_auROC: 0.8673\n",
      "Epoch 106/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2988 - acc: 0.9076 - auROC: 0.9408 - val_loss: 0.3421 - val_acc: 0.8517 - val_auROC: 0.8698\n",
      "Epoch 107/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2979 - acc: 0.9072 - auROC: 0.9427 - val_loss: 0.3411 - val_acc: 0.8517 - val_auROC: 0.8719\n",
      "Epoch 108/361\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.2971 - acc: 0.9057 - auROC: 0.9441 - val_loss: 0.3405 - val_acc: 0.8483 - val_auROC: 0.8749\n",
      "Epoch 109/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2966 - acc: 0.9057 - auROC: 0.9450 - val_loss: 0.3397 - val_acc: 0.8483 - val_auROC: 0.8760\n",
      "Epoch 110/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2960 - acc: 0.9049 - auROC: 0.9455 - val_loss: 0.3382 - val_acc: 0.8483 - val_auROC: 0.8775\n",
      "Epoch 111/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2953 - acc: 0.9045 - auROC: 0.9464 - val_loss: 0.3377 - val_acc: 0.8483 - val_auROC: 0.8780\n",
      "Epoch 112/361\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.2940 - acc: 0.9057 - auROC: 0.9481 - val_loss: 0.3370 - val_acc: 0.8483 - val_auROC: 0.8795\n",
      "Epoch 113/361\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.2932 - acc: 0.9068 - auROC: 0.9490 - val_loss: 0.3350 - val_acc: 0.8586 - val_auROC: 0.8816\n",
      "Epoch 114/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2926 - acc: 0.9076 - auROC: 0.9496 - val_loss: 0.3343 - val_acc: 0.8586 - val_auROC: 0.8840\n",
      "Epoch 115/361\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.2918 - acc: 0.9076 - auROC: 0.9499 - val_loss: 0.3341 - val_acc: 0.8586 - val_auROC: 0.8833\n",
      "Epoch 116/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2915 - acc: 0.9080 - auROC: 0.9503 - val_loss: 0.3329 - val_acc: 0.8621 - val_auROC: 0.8855\n",
      "Epoch 117/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2911 - acc: 0.9068 - auROC: 0.9507 - val_loss: 0.3323 - val_acc: 0.8586 - val_auROC: 0.8843\n",
      "Epoch 118/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2909 - acc: 0.9072 - auROC: 0.9507 - val_loss: 0.3325 - val_acc: 0.8621 - val_auROC: 0.8856\n",
      "Epoch 119/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2907 - acc: 0.9072 - auROC: 0.9508 - val_loss: 0.3331 - val_acc: 0.8655 - val_auROC: 0.8852\n",
      "Epoch 120/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2904 - acc: 0.9072 - auROC: 0.9510 - val_loss: 0.3330 - val_acc: 0.8655 - val_auROC: 0.8851\n",
      "Epoch 121/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2902 - acc: 0.9068 - auROC: 0.9511 - val_loss: 0.3321 - val_acc: 0.8621 - val_auROC: 0.8861\n",
      "Epoch 122/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2904 - acc: 0.9072 - auROC: 0.9508 - val_loss: 0.3343 - val_acc: 0.8621 - val_auROC: 0.8831\n",
      "Epoch 123/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2902 - acc: 0.9068 - auROC: 0.9511 - val_loss: 0.3336 - val_acc: 0.8621 - val_auROC: 0.8845\n",
      "Epoch 124/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2895 - acc: 0.9060 - auROC: 0.9519 - val_loss: 0.3318 - val_acc: 0.8655 - val_auROC: 0.8857\n",
      "Epoch 125/361\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2892 - acc: 0.9072 - auROC: 0.9521 - val_loss: 0.3322 - val_acc: 0.8621 - val_auROC: 0.8840\n",
      "Epoch 126/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2893 - acc: 0.9080 - auROC: 0.9518 - val_loss: 0.3326 - val_acc: 0.8621 - val_auROC: 0.8834\n",
      "Epoch 127/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2889 - acc: 0.9072 - auROC: 0.9519 - val_loss: 0.3327 - val_acc: 0.8621 - val_auROC: 0.8828\n",
      "Epoch 128/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2883 - acc: 0.9064 - auROC: 0.9523 - val_loss: 0.3328 - val_acc: 0.8621 - val_auROC: 0.8834\n",
      "Epoch 129/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2883 - acc: 0.9045 - auROC: 0.9520 - val_loss: 0.3330 - val_acc: 0.8655 - val_auROC: 0.8841\n",
      "Epoch 130/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2880 - acc: 0.9060 - auROC: 0.9521 - val_loss: 0.3325 - val_acc: 0.8690 - val_auROC: 0.8840\n",
      "Epoch 131/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2874 - acc: 0.9076 - auROC: 0.9528 - val_loss: 0.3325 - val_acc: 0.8655 - val_auROC: 0.8847\n",
      "Epoch 132/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2871 - acc: 0.9080 - auROC: 0.9531 - val_loss: 0.3322 - val_acc: 0.8690 - val_auROC: 0.8854\n",
      "Epoch 133/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2869 - acc: 0.9099 - auROC: 0.9534 - val_loss: 0.3320 - val_acc: 0.8655 - val_auROC: 0.8859\n",
      "Epoch 134/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2866 - acc: 0.9103 - auROC: 0.9536 - val_loss: 0.3319 - val_acc: 0.8655 - val_auROC: 0.8865\n",
      "Epoch 135/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2864 - acc: 0.9092 - auROC: 0.9537 - val_loss: 0.3321 - val_acc: 0.8655 - val_auROC: 0.8853\n",
      "Epoch 136/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2862 - acc: 0.9099 - auROC: 0.9538 - val_loss: 0.3315 - val_acc: 0.8690 - val_auROC: 0.8864\n",
      "Epoch 137/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2861 - acc: 0.9103 - auROC: 0.9538 - val_loss: 0.3312 - val_acc: 0.8690 - val_auROC: 0.8868\n",
      "Epoch 138/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2859 - acc: 0.9103 - auROC: 0.9539 - val_loss: 0.3312 - val_acc: 0.8690 - val_auROC: 0.8872\n",
      "Epoch 139/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2856 - acc: 0.9099 - auROC: 0.9542 - val_loss: 0.3310 - val_acc: 0.8690 - val_auROC: 0.8868\n",
      "Epoch 140/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2854 - acc: 0.9096 - auROC: 0.9545 - val_loss: 0.3310 - val_acc: 0.8655 - val_auROC: 0.8873\n",
      "Epoch 141/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2851 - acc: 0.9103 - auROC: 0.9548 - val_loss: 0.3315 - val_acc: 0.8690 - val_auROC: 0.8863\n",
      "Epoch 142/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2847 - acc: 0.9107 - auROC: 0.9554 - val_loss: 0.3315 - val_acc: 0.8690 - val_auROC: 0.8863\n",
      "Epoch 143/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2843 - acc: 0.9107 - auROC: 0.9556 - val_loss: 0.3311 - val_acc: 0.8655 - val_auROC: 0.8873\n",
      "Epoch 144/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2839 - acc: 0.9111 - auROC: 0.9560 - val_loss: 0.3302 - val_acc: 0.8690 - val_auROC: 0.8871\n",
      "Epoch 145/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2838 - acc: 0.9119 - auROC: 0.9560 - val_loss: 0.3296 - val_acc: 0.8724 - val_auROC: 0.8867\n",
      "Epoch 146/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2834 - acc: 0.9119 - auROC: 0.9564 - val_loss: 0.3296 - val_acc: 0.8724 - val_auROC: 0.8873\n",
      "Epoch 147/361\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.2831 - acc: 0.9115 - auROC: 0.9566 - val_loss: 0.3295 - val_acc: 0.8724 - val_auROC: 0.8874\n",
      "Epoch 148/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2829 - acc: 0.9115 - auROC: 0.9568 - val_loss: 0.3292 - val_acc: 0.8724 - val_auROC: 0.8886\n",
      "Epoch 149/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2826 - acc: 0.9127 - auROC: 0.9570 - val_loss: 0.3289 - val_acc: 0.8724 - val_auROC: 0.8888\n",
      "Epoch 150/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2826 - acc: 0.9131 - auROC: 0.9570 - val_loss: 0.3271 - val_acc: 0.8724 - val_auROC: 0.8930\n",
      "Epoch 151/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2827 - acc: 0.9135 - auROC: 0.9575 - val_loss: 0.3273 - val_acc: 0.8724 - val_auROC: 0.8921\n",
      "Epoch 152/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2818 - acc: 0.9138 - auROC: 0.9585 - val_loss: 0.3282 - val_acc: 0.8724 - val_auROC: 0.8911\n",
      "Epoch 153/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2813 - acc: 0.9138 - auROC: 0.9591 - val_loss: 0.3270 - val_acc: 0.8724 - val_auROC: 0.8941\n",
      "Epoch 154/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2808 - acc: 0.9138 - auROC: 0.9597 - val_loss: 0.3258 - val_acc: 0.8690 - val_auROC: 0.8951\n",
      "Epoch 155/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2805 - acc: 0.9142 - auROC: 0.9601 - val_loss: 0.3246 - val_acc: 0.8724 - val_auROC: 0.8967\n",
      "Epoch 156/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2803 - acc: 0.9135 - auROC: 0.9602 - val_loss: 0.3237 - val_acc: 0.8724 - val_auROC: 0.8984\n",
      "Epoch 157/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2800 - acc: 0.9135 - auROC: 0.9604 - val_loss: 0.3233 - val_acc: 0.8690 - val_auROC: 0.8990\n",
      "Epoch 158/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2799 - acc: 0.9135 - auROC: 0.9604 - val_loss: 0.3230 - val_acc: 0.8690 - val_auROC: 0.8992\n",
      "Epoch 159/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2797 - acc: 0.9135 - auROC: 0.9606 - val_loss: 0.3226 - val_acc: 0.8724 - val_auROC: 0.9002\n",
      "Epoch 160/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2796 - acc: 0.9123 - auROC: 0.9606 - val_loss: 0.3225 - val_acc: 0.8724 - val_auROC: 0.9008\n",
      "Epoch 161/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2798 - acc: 0.9123 - auROC: 0.9605 - val_loss: 0.3231 - val_acc: 0.8724 - val_auROC: 0.8993\n",
      "Epoch 162/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2799 - acc: 0.9131 - auROC: 0.9604 - val_loss: 0.3231 - val_acc: 0.8690 - val_auROC: 0.9001\n",
      "Epoch 163/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2798 - acc: 0.9138 - auROC: 0.9605 - val_loss: 0.3229 - val_acc: 0.8690 - val_auROC: 0.9001\n",
      "Epoch 164/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2796 - acc: 0.9138 - auROC: 0.9606 - val_loss: 0.3225 - val_acc: 0.8690 - val_auROC: 0.9002\n",
      "Epoch 165/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2795 - acc: 0.9135 - auROC: 0.9607 - val_loss: 0.3220 - val_acc: 0.8690 - val_auROC: 0.9006\n",
      "Epoch 166/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2793 - acc: 0.9138 - auROC: 0.9608 - val_loss: 0.3219 - val_acc: 0.8724 - val_auROC: 0.9007\n",
      "Epoch 167/361\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2792 - acc: 0.9142 - auROC: 0.9608 - val_loss: 0.3218 - val_acc: 0.8724 - val_auROC: 0.9017\n",
      "Epoch 168/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2790 - acc: 0.9142 - auROC: 0.9609 - val_loss: 0.3215 - val_acc: 0.8724 - val_auROC: 0.9018\n",
      "Epoch 169/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2788 - acc: 0.9146 - auROC: 0.9610 - val_loss: 0.3213 - val_acc: 0.8724 - val_auROC: 0.9006\n",
      "Epoch 170/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2786 - acc: 0.9154 - auROC: 0.9612 - val_loss: 0.3213 - val_acc: 0.8724 - val_auROC: 0.9010\n",
      "Epoch 171/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2785 - acc: 0.9154 - auROC: 0.9613 - val_loss: 0.3207 - val_acc: 0.8724 - val_auROC: 0.9022\n",
      "Epoch 172/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2784 - acc: 0.9150 - auROC: 0.9613 - val_loss: 0.3200 - val_acc: 0.8759 - val_auROC: 0.9036\n",
      "Epoch 173/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2785 - acc: 0.9150 - auROC: 0.9611 - val_loss: 0.3205 - val_acc: 0.8759 - val_auROC: 0.9035\n",
      "Epoch 174/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2784 - acc: 0.9146 - auROC: 0.9612 - val_loss: 0.3210 - val_acc: 0.8724 - val_auROC: 0.9020\n",
      "Epoch 175/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2781 - acc: 0.9154 - auROC: 0.9612 - val_loss: 0.3210 - val_acc: 0.8724 - val_auROC: 0.9019\n",
      "Epoch 176/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2778 - acc: 0.9150 - auROC: 0.9615 - val_loss: 0.3207 - val_acc: 0.8724 - val_auROC: 0.9021\n",
      "Epoch 177/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2776 - acc: 0.9150 - auROC: 0.9616 - val_loss: 0.3202 - val_acc: 0.8690 - val_auROC: 0.9033\n",
      "Epoch 178/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2774 - acc: 0.9146 - auROC: 0.9616 - val_loss: 0.3202 - val_acc: 0.8690 - val_auROC: 0.9034\n",
      "Epoch 179/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2773 - acc: 0.9150 - auROC: 0.9617 - val_loss: 0.3199 - val_acc: 0.8690 - val_auROC: 0.9041\n",
      "Epoch 180/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2773 - acc: 0.9150 - auROC: 0.9618 - val_loss: 0.3198 - val_acc: 0.8724 - val_auROC: 0.9044\n",
      "Epoch 181/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2771 - acc: 0.9162 - auROC: 0.9618 - val_loss: 0.3199 - val_acc: 0.8759 - val_auROC: 0.9026\n",
      "Epoch 182/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2770 - acc: 0.9158 - auROC: 0.9618 - val_loss: 0.3199 - val_acc: 0.8724 - val_auROC: 0.9021\n",
      "Epoch 183/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2769 - acc: 0.9170 - auROC: 0.9618 - val_loss: 0.3200 - val_acc: 0.8724 - val_auROC: 0.9012\n",
      "Epoch 184/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2768 - acc: 0.9166 - auROC: 0.9619 - val_loss: 0.3203 - val_acc: 0.8724 - val_auROC: 0.9015\n",
      "Epoch 185/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2767 - acc: 0.9170 - auROC: 0.9619 - val_loss: 0.3196 - val_acc: 0.8724 - val_auROC: 0.9038\n",
      "Epoch 186/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2765 - acc: 0.9166 - auROC: 0.9620 - val_loss: 0.3190 - val_acc: 0.8759 - val_auROC: 0.9036\n",
      "Epoch 187/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2764 - acc: 0.9162 - auROC: 0.9620 - val_loss: 0.3189 - val_acc: 0.8759 - val_auROC: 0.9040\n",
      "Epoch 188/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2762 - acc: 0.9162 - auROC: 0.9621 - val_loss: 0.3187 - val_acc: 0.8724 - val_auROC: 0.9036\n",
      "Epoch 189/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2761 - acc: 0.9154 - auROC: 0.9620 - val_loss: 0.3185 - val_acc: 0.8724 - val_auROC: 0.9037\n",
      "Epoch 190/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2759 - acc: 0.9154 - auROC: 0.9620 - val_loss: 0.3183 - val_acc: 0.8724 - val_auROC: 0.9042\n",
      "Epoch 191/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2758 - acc: 0.9158 - auROC: 0.9620 - val_loss: 0.3180 - val_acc: 0.8724 - val_auROC: 0.9044\n",
      "Epoch 192/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2757 - acc: 0.9162 - auROC: 0.9619 - val_loss: 0.3177 - val_acc: 0.8759 - val_auROC: 0.9043\n",
      "Epoch 193/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2756 - acc: 0.9162 - auROC: 0.9619 - val_loss: 0.3176 - val_acc: 0.8759 - val_auROC: 0.9042\n",
      "Epoch 194/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2755 - acc: 0.9162 - auROC: 0.9619 - val_loss: 0.3175 - val_acc: 0.8724 - val_auROC: 0.9045\n",
      "Epoch 195/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2754 - acc: 0.9166 - auROC: 0.9619 - val_loss: 0.3173 - val_acc: 0.8724 - val_auROC: 0.9055\n",
      "Epoch 196/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2753 - acc: 0.9166 - auROC: 0.9619 - val_loss: 0.3167 - val_acc: 0.8724 - val_auROC: 0.9059\n",
      "Epoch 197/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2752 - acc: 0.9166 - auROC: 0.9619 - val_loss: 0.3166 - val_acc: 0.8724 - val_auROC: 0.9070\n",
      "Epoch 198/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2751 - acc: 0.9166 - auROC: 0.9619 - val_loss: 0.3169 - val_acc: 0.8724 - val_auROC: 0.9073\n",
      "Epoch 199/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2752 - acc: 0.9177 - auROC: 0.9621 - val_loss: 0.3176 - val_acc: 0.8724 - val_auROC: 0.9057\n",
      "Epoch 200/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2752 - acc: 0.9177 - auROC: 0.9618 - val_loss: 0.3174 - val_acc: 0.8724 - val_auROC: 0.9061\n",
      "Epoch 201/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2749 - acc: 0.9177 - auROC: 0.9618 - val_loss: 0.3180 - val_acc: 0.8655 - val_auROC: 0.9050\n",
      "Epoch 202/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2747 - acc: 0.9162 - auROC: 0.9622 - val_loss: 0.3173 - val_acc: 0.8655 - val_auROC: 0.9052\n",
      "Epoch 203/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2746 - acc: 0.9170 - auROC: 0.9622 - val_loss: 0.3164 - val_acc: 0.8655 - val_auROC: 0.9063\n",
      "Epoch 204/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2745 - acc: 0.9177 - auROC: 0.9622 - val_loss: 0.3159 - val_acc: 0.8724 - val_auROC: 0.9074\n",
      "Epoch 205/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2744 - acc: 0.9201 - auROC: 0.9623 - val_loss: 0.3157 - val_acc: 0.8793 - val_auROC: 0.9062\n",
      "Epoch 206/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2744 - acc: 0.9201 - auROC: 0.9623 - val_loss: 0.3155 - val_acc: 0.8828 - val_auROC: 0.9063\n",
      "Epoch 207/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2742 - acc: 0.9201 - auROC: 0.9623 - val_loss: 0.3155 - val_acc: 0.8793 - val_auROC: 0.9062\n",
      "Epoch 208/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2741 - acc: 0.9181 - auROC: 0.9623 - val_loss: 0.3154 - val_acc: 0.8793 - val_auROC: 0.9065\n",
      "Epoch 209/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2739 - acc: 0.9181 - auROC: 0.9624 - val_loss: 0.3154 - val_acc: 0.8793 - val_auROC: 0.9061\n",
      "Epoch 210/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2738 - acc: 0.9177 - auROC: 0.9624 - val_loss: 0.3154 - val_acc: 0.8793 - val_auROC: 0.9059\n",
      "Epoch 211/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2738 - acc: 0.9177 - auROC: 0.9624 - val_loss: 0.3153 - val_acc: 0.8793 - val_auROC: 0.9060\n",
      "Epoch 212/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2736 - acc: 0.9181 - auROC: 0.9625 - val_loss: 0.3153 - val_acc: 0.8793 - val_auROC: 0.9058\n",
      "Epoch 213/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2735 - acc: 0.9185 - auROC: 0.9625 - val_loss: 0.3153 - val_acc: 0.8793 - val_auROC: 0.9053\n",
      "Epoch 214/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2736 - acc: 0.9181 - auROC: 0.9625 - val_loss: 0.3155 - val_acc: 0.8793 - val_auROC: 0.9054\n",
      "Epoch 215/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2737 - acc: 0.9181 - auROC: 0.9625 - val_loss: 0.3155 - val_acc: 0.8793 - val_auROC: 0.9056\n",
      "Epoch 216/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2738 - acc: 0.9181 - auROC: 0.9624 - val_loss: 0.3173 - val_acc: 0.8759 - val_auROC: 0.9039\n",
      "Epoch 217/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2740 - acc: 0.9185 - auROC: 0.9622 - val_loss: 0.3159 - val_acc: 0.8759 - val_auROC: 0.9057\n",
      "Epoch 218/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2733 - acc: 0.9189 - auROC: 0.9627 - val_loss: 0.3146 - val_acc: 0.8793 - val_auROC: 0.9058\n",
      "Epoch 219/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2730 - acc: 0.9205 - auROC: 0.9626 - val_loss: 0.3141 - val_acc: 0.8828 - val_auROC: 0.9062\n",
      "Epoch 220/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2728 - acc: 0.9197 - auROC: 0.9627 - val_loss: 0.3142 - val_acc: 0.8793 - val_auROC: 0.9071\n",
      "Epoch 221/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2727 - acc: 0.9189 - auROC: 0.9628 - val_loss: 0.3143 - val_acc: 0.8793 - val_auROC: 0.9071\n",
      "Epoch 222/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2727 - acc: 0.9193 - auROC: 0.9629 - val_loss: 0.3143 - val_acc: 0.8828 - val_auROC: 0.9076\n",
      "Epoch 223/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2726 - acc: 0.9201 - auROC: 0.9629 - val_loss: 0.3140 - val_acc: 0.8828 - val_auROC: 0.9078\n",
      "Epoch 224/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2727 - acc: 0.9205 - auROC: 0.9629 - val_loss: 0.3135 - val_acc: 0.8828 - val_auROC: 0.9085\n",
      "Epoch 225/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2729 - acc: 0.9209 - auROC: 0.9627 - val_loss: 0.3134 - val_acc: 0.8828 - val_auROC: 0.9084\n",
      "Epoch 226/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2726 - acc: 0.9224 - auROC: 0.9629 - val_loss: 0.3132 - val_acc: 0.8828 - val_auROC: 0.9081\n",
      "Epoch 227/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2725 - acc: 0.9209 - auROC: 0.9630 - val_loss: 0.3131 - val_acc: 0.8828 - val_auROC: 0.9078\n",
      "Epoch 228/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2724 - acc: 0.9209 - auROC: 0.9631 - val_loss: 0.3133 - val_acc: 0.8828 - val_auROC: 0.9084\n",
      "Epoch 229/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2722 - acc: 0.9224 - auROC: 0.9632 - val_loss: 0.3137 - val_acc: 0.8828 - val_auROC: 0.9071\n",
      "Epoch 230/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2722 - acc: 0.9232 - auROC: 0.9632 - val_loss: 0.3136 - val_acc: 0.8828 - val_auROC: 0.9070\n",
      "Epoch 231/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2720 - acc: 0.9228 - auROC: 0.9633 - val_loss: 0.3135 - val_acc: 0.8828 - val_auROC: 0.9084\n",
      "Epoch 232/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2717 - acc: 0.9232 - auROC: 0.9632 - val_loss: 0.3135 - val_acc: 0.8828 - val_auROC: 0.9083\n",
      "Epoch 233/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2716 - acc: 0.9248 - auROC: 0.9631 - val_loss: 0.3134 - val_acc: 0.8828 - val_auROC: 0.9079\n",
      "Epoch 234/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2714 - acc: 0.9240 - auROC: 0.9632 - val_loss: 0.3134 - val_acc: 0.8828 - val_auROC: 0.9079\n",
      "Epoch 235/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2714 - acc: 0.9244 - auROC: 0.9631 - val_loss: 0.3135 - val_acc: 0.8828 - val_auROC: 0.9077\n",
      "Epoch 236/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2713 - acc: 0.9240 - auROC: 0.9630 - val_loss: 0.3134 - val_acc: 0.8828 - val_auROC: 0.9080\n",
      "Epoch 237/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2712 - acc: 0.9232 - auROC: 0.9631 - val_loss: 0.3135 - val_acc: 0.8759 - val_auROC: 0.9080\n",
      "Epoch 238/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2711 - acc: 0.9224 - auROC: 0.9632 - val_loss: 0.3134 - val_acc: 0.8759 - val_auROC: 0.9079\n",
      "Epoch 239/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2710 - acc: 0.9232 - auROC: 0.9632 - val_loss: 0.3133 - val_acc: 0.8793 - val_auROC: 0.9081\n",
      "Epoch 240/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2710 - acc: 0.9240 - auROC: 0.9633 - val_loss: 0.3132 - val_acc: 0.8828 - val_auROC: 0.9081\n",
      "Epoch 241/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2710 - acc: 0.9220 - auROC: 0.9633 - val_loss: 0.3130 - val_acc: 0.8828 - val_auROC: 0.9083\n",
      "Epoch 242/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2711 - acc: 0.9220 - auROC: 0.9633 - val_loss: 0.3131 - val_acc: 0.8828 - val_auROC: 0.9083\n",
      "Epoch 243/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2709 - acc: 0.9228 - auROC: 0.9633 - val_loss: 0.3131 - val_acc: 0.8828 - val_auROC: 0.9088\n",
      "Epoch 244/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2708 - acc: 0.9232 - auROC: 0.9633 - val_loss: 0.3131 - val_acc: 0.8828 - val_auROC: 0.9088\n",
      "Epoch 245/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2707 - acc: 0.9248 - auROC: 0.9633 - val_loss: 0.3129 - val_acc: 0.8828 - val_auROC: 0.9089\n",
      "Epoch 246/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2706 - acc: 0.9255 - auROC: 0.9633 - val_loss: 0.3128 - val_acc: 0.8828 - val_auROC: 0.9086\n",
      "Epoch 247/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2705 - acc: 0.9255 - auROC: 0.9633 - val_loss: 0.3131 - val_acc: 0.8793 - val_auROC: 0.9086\n",
      "Epoch 248/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2704 - acc: 0.9248 - auROC: 0.9633 - val_loss: 0.3132 - val_acc: 0.8793 - val_auROC: 0.9090\n",
      "Epoch 249/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2704 - acc: 0.9240 - auROC: 0.9633 - val_loss: 0.3130 - val_acc: 0.8793 - val_auROC: 0.9085\n",
      "Epoch 250/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2703 - acc: 0.9244 - auROC: 0.9633 - val_loss: 0.3130 - val_acc: 0.8793 - val_auROC: 0.9085\n",
      "Epoch 251/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2703 - acc: 0.9244 - auROC: 0.9633 - val_loss: 0.3129 - val_acc: 0.8793 - val_auROC: 0.9080\n",
      "Epoch 252/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2702 - acc: 0.9232 - auROC: 0.9634 - val_loss: 0.3127 - val_acc: 0.8759 - val_auROC: 0.9082\n",
      "Epoch 253/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2701 - acc: 0.9228 - auROC: 0.9635 - val_loss: 0.3126 - val_acc: 0.8793 - val_auROC: 0.9078\n",
      "Epoch 254/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2700 - acc: 0.9232 - auROC: 0.9636 - val_loss: 0.3126 - val_acc: 0.8793 - val_auROC: 0.9080\n",
      "Epoch 255/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2700 - acc: 0.9240 - auROC: 0.9636 - val_loss: 0.3131 - val_acc: 0.8828 - val_auROC: 0.9073\n",
      "Epoch 256/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2700 - acc: 0.9248 - auROC: 0.9635 - val_loss: 0.3130 - val_acc: 0.8828 - val_auROC: 0.9064\n",
      "Epoch 257/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2700 - acc: 0.9255 - auROC: 0.9635 - val_loss: 0.3137 - val_acc: 0.8793 - val_auROC: 0.9059\n",
      "Epoch 258/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2704 - acc: 0.9244 - auROC: 0.9634 - val_loss: 0.3140 - val_acc: 0.8759 - val_auROC: 0.9052\n",
      "Epoch 259/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2702 - acc: 0.9236 - auROC: 0.9635 - val_loss: 0.3132 - val_acc: 0.8759 - val_auROC: 0.9062\n",
      "Epoch 260/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2700 - acc: 0.9236 - auROC: 0.9636 - val_loss: 0.3129 - val_acc: 0.8759 - val_auROC: 0.9063\n",
      "Epoch 261/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2698 - acc: 0.9240 - auROC: 0.9636 - val_loss: 0.3126 - val_acc: 0.8759 - val_auROC: 0.9071\n",
      "Epoch 262/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2697 - acc: 0.9240 - auROC: 0.9636 - val_loss: 0.3121 - val_acc: 0.8759 - val_auROC: 0.9071\n",
      "Epoch 263/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2697 - acc: 0.9244 - auROC: 0.9636 - val_loss: 0.3120 - val_acc: 0.8759 - val_auROC: 0.9070\n",
      "Epoch 264/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2696 - acc: 0.9251 - auROC: 0.9636 - val_loss: 0.3122 - val_acc: 0.8793 - val_auROC: 0.9073\n",
      "Epoch 265/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2695 - acc: 0.9259 - auROC: 0.9636 - val_loss: 0.3123 - val_acc: 0.8793 - val_auROC: 0.9075\n",
      "Epoch 266/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2694 - acc: 0.9255 - auROC: 0.9636 - val_loss: 0.3122 - val_acc: 0.8793 - val_auROC: 0.9074\n",
      "Epoch 267/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2694 - acc: 0.9255 - auROC: 0.9636 - val_loss: 0.3118 - val_acc: 0.8793 - val_auROC: 0.9081\n",
      "Epoch 268/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2695 - acc: 0.9251 - auROC: 0.9636 - val_loss: 0.3117 - val_acc: 0.8793 - val_auROC: 0.9083\n",
      "Epoch 269/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2694 - acc: 0.9259 - auROC: 0.9636 - val_loss: 0.3117 - val_acc: 0.8793 - val_auROC: 0.9083\n",
      "Epoch 270/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2693 - acc: 0.9259 - auROC: 0.9637 - val_loss: 0.3116 - val_acc: 0.8793 - val_auROC: 0.9084\n",
      "Epoch 271/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2692 - acc: 0.9259 - auROC: 0.9637 - val_loss: 0.3116 - val_acc: 0.8793 - val_auROC: 0.9081\n",
      "Epoch 272/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2691 - acc: 0.9263 - auROC: 0.9637 - val_loss: 0.3115 - val_acc: 0.8793 - val_auROC: 0.9083\n",
      "Epoch 273/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2690 - acc: 0.9263 - auROC: 0.9637 - val_loss: 0.3114 - val_acc: 0.8793 - val_auROC: 0.9082\n",
      "Epoch 274/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2689 - acc: 0.9263 - auROC: 0.9638 - val_loss: 0.3109 - val_acc: 0.8828 - val_auROC: 0.9110\n",
      "Epoch 275/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2687 - acc: 0.9263 - auROC: 0.9640 - val_loss: 0.3109 - val_acc: 0.8828 - val_auROC: 0.9111\n",
      "Epoch 276/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2686 - acc: 0.9263 - auROC: 0.9640 - val_loss: 0.3109 - val_acc: 0.8828 - val_auROC: 0.9108\n",
      "Epoch 277/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2685 - acc: 0.9263 - auROC: 0.9640 - val_loss: 0.3111 - val_acc: 0.8828 - val_auROC: 0.9101\n",
      "Epoch 278/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2685 - acc: 0.9251 - auROC: 0.9640 - val_loss: 0.3120 - val_acc: 0.8793 - val_auROC: 0.9078\n",
      "Epoch 279/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2685 - acc: 0.9236 - auROC: 0.9641 - val_loss: 0.3117 - val_acc: 0.8759 - val_auROC: 0.9080\n",
      "Epoch 280/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2684 - acc: 0.9236 - auROC: 0.9642 - val_loss: 0.3114 - val_acc: 0.8793 - val_auROC: 0.9088\n",
      "Epoch 281/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2683 - acc: 0.9255 - auROC: 0.9641 - val_loss: 0.3114 - val_acc: 0.8793 - val_auROC: 0.9091\n",
      "Epoch 282/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2683 - acc: 0.9251 - auROC: 0.9640 - val_loss: 0.3115 - val_acc: 0.8793 - val_auROC: 0.9087\n",
      "Epoch 283/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2682 - acc: 0.9251 - auROC: 0.9641 - val_loss: 0.3109 - val_acc: 0.8828 - val_auROC: 0.9096\n",
      "Epoch 284/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2679 - acc: 0.9240 - auROC: 0.9644 - val_loss: 0.3104 - val_acc: 0.8828 - val_auROC: 0.9097\n",
      "Epoch 285/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2679 - acc: 0.9224 - auROC: 0.9645 - val_loss: 0.3103 - val_acc: 0.8828 - val_auROC: 0.9103\n",
      "Epoch 286/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2677 - acc: 0.9236 - auROC: 0.9646 - val_loss: 0.3103 - val_acc: 0.8828 - val_auROC: 0.9097\n",
      "Epoch 287/361\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2676 - acc: 0.9248 - auROC: 0.9646 - val_loss: 0.3102 - val_acc: 0.8828 - val_auROC: 0.9089\n",
      "Epoch 288/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2675 - acc: 0.9251 - auROC: 0.9647 - val_loss: 0.3102 - val_acc: 0.8828 - val_auROC: 0.9094\n",
      "Epoch 289/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2674 - acc: 0.9251 - auROC: 0.9647 - val_loss: 0.3104 - val_acc: 0.8828 - val_auROC: 0.9099\n",
      "Epoch 290/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2672 - acc: 0.9251 - auROC: 0.9649 - val_loss: 0.3102 - val_acc: 0.8828 - val_auROC: 0.9091\n",
      "Epoch 291/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2671 - acc: 0.9251 - auROC: 0.9649 - val_loss: 0.3102 - val_acc: 0.8828 - val_auROC: 0.9089\n",
      "Epoch 292/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2670 - acc: 0.9248 - auROC: 0.9649 - val_loss: 0.3104 - val_acc: 0.8793 - val_auROC: 0.9084\n",
      "Epoch 293/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2669 - acc: 0.9240 - auROC: 0.9649 - val_loss: 0.3106 - val_acc: 0.8793 - val_auROC: 0.9079\n",
      "Epoch 294/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2668 - acc: 0.9244 - auROC: 0.9649 - val_loss: 0.3106 - val_acc: 0.8828 - val_auROC: 0.9077\n",
      "Epoch 295/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2667 - acc: 0.9259 - auROC: 0.9649 - val_loss: 0.3108 - val_acc: 0.8828 - val_auROC: 0.9071\n",
      "Epoch 296/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2667 - acc: 0.9263 - auROC: 0.9650 - val_loss: 0.3108 - val_acc: 0.8828 - val_auROC: 0.9067\n",
      "Epoch 297/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2666 - acc: 0.9259 - auROC: 0.9650 - val_loss: 0.3109 - val_acc: 0.8828 - val_auROC: 0.9061\n",
      "Epoch 298/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2665 - acc: 0.9259 - auROC: 0.9651 - val_loss: 0.3105 - val_acc: 0.8828 - val_auROC: 0.9070\n",
      "Epoch 299/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2664 - acc: 0.9267 - auROC: 0.9651 - val_loss: 0.3103 - val_acc: 0.8828 - val_auROC: 0.9076\n",
      "Epoch 300/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2664 - acc: 0.9267 - auROC: 0.9651 - val_loss: 0.3101 - val_acc: 0.8828 - val_auROC: 0.9085\n",
      "Epoch 301/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2663 - acc: 0.9267 - auROC: 0.9651 - val_loss: 0.3098 - val_acc: 0.8828 - val_auROC: 0.9088\n",
      "Epoch 302/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2662 - acc: 0.9267 - auROC: 0.9651 - val_loss: 0.3097 - val_acc: 0.8828 - val_auROC: 0.9090\n",
      "Epoch 303/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2662 - acc: 0.9271 - auROC: 0.9650 - val_loss: 0.3097 - val_acc: 0.8828 - val_auROC: 0.9093\n",
      "Epoch 304/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2661 - acc: 0.9267 - auROC: 0.9651 - val_loss: 0.3097 - val_acc: 0.8828 - val_auROC: 0.9078\n",
      "Epoch 305/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2659 - acc: 0.9263 - auROC: 0.9652 - val_loss: 0.3092 - val_acc: 0.8828 - val_auROC: 0.9088\n",
      "Epoch 306/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2659 - acc: 0.9267 - auROC: 0.9652 - val_loss: 0.3089 - val_acc: 0.8828 - val_auROC: 0.9090\n",
      "Epoch 307/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2658 - acc: 0.9267 - auROC: 0.9652 - val_loss: 0.3087 - val_acc: 0.8828 - val_auROC: 0.9093\n",
      "Epoch 308/361\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2657 - acc: 0.9267 - auROC: 0.9652 - val_loss: 0.3089 - val_acc: 0.8828 - val_auROC: 0.9084\n",
      "Epoch 309/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2657 - acc: 0.9271 - auROC: 0.9653 - val_loss: 0.3089 - val_acc: 0.8828 - val_auROC: 0.9084\n",
      "Epoch 310/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2656 - acc: 0.9271 - auROC: 0.9653 - val_loss: 0.3089 - val_acc: 0.8828 - val_auROC: 0.9086\n",
      "Epoch 311/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2655 - acc: 0.9267 - auROC: 0.9652 - val_loss: 0.3093 - val_acc: 0.8793 - val_auROC: 0.9084\n",
      "Epoch 312/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2655 - acc: 0.9267 - auROC: 0.9652 - val_loss: 0.3091 - val_acc: 0.8793 - val_auROC: 0.9083\n",
      "Epoch 313/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2654 - acc: 0.9271 - auROC: 0.9653 - val_loss: 0.3092 - val_acc: 0.8828 - val_auROC: 0.9083\n",
      "Epoch 314/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2654 - acc: 0.9275 - auROC: 0.9652 - val_loss: 0.3091 - val_acc: 0.8828 - val_auROC: 0.9082\n",
      "Epoch 315/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2653 - acc: 0.9275 - auROC: 0.9652 - val_loss: 0.3092 - val_acc: 0.8828 - val_auROC: 0.9076\n",
      "Epoch 316/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2653 - acc: 0.9267 - auROC: 0.9653 - val_loss: 0.3091 - val_acc: 0.8828 - val_auROC: 0.9074\n",
      "Epoch 317/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2652 - acc: 0.9267 - auROC: 0.9653 - val_loss: 0.3089 - val_acc: 0.8828 - val_auROC: 0.9084\n",
      "Epoch 318/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2651 - acc: 0.9271 - auROC: 0.9653 - val_loss: 0.3087 - val_acc: 0.8828 - val_auROC: 0.9086\n",
      "Epoch 319/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2651 - acc: 0.9267 - auROC: 0.9653 - val_loss: 0.3084 - val_acc: 0.8759 - val_auROC: 0.9087\n",
      "Epoch 320/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2650 - acc: 0.9259 - auROC: 0.9653 - val_loss: 0.3084 - val_acc: 0.8828 - val_auROC: 0.9089\n",
      "Epoch 321/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2650 - acc: 0.9263 - auROC: 0.9654 - val_loss: 0.3083 - val_acc: 0.8828 - val_auROC: 0.9090\n",
      "Epoch 322/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2649 - acc: 0.9275 - auROC: 0.9654 - val_loss: 0.3082 - val_acc: 0.8828 - val_auROC: 0.9086\n",
      "Epoch 323/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2649 - acc: 0.9275 - auROC: 0.9653 - val_loss: 0.3082 - val_acc: 0.8828 - val_auROC: 0.9088\n",
      "Epoch 324/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2648 - acc: 0.9275 - auROC: 0.9653 - val_loss: 0.3081 - val_acc: 0.8828 - val_auROC: 0.9091\n",
      "Epoch 325/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2647 - acc: 0.9275 - auROC: 0.9654 - val_loss: 0.3079 - val_acc: 0.8828 - val_auROC: 0.9090\n",
      "Epoch 326/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2647 - acc: 0.9279 - auROC: 0.9654 - val_loss: 0.3079 - val_acc: 0.8828 - val_auROC: 0.9091\n",
      "Epoch 327/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2646 - acc: 0.9279 - auROC: 0.9654 - val_loss: 0.3078 - val_acc: 0.8828 - val_auROC: 0.9093\n",
      "Epoch 328/361\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2646 - acc: 0.9275 - auROC: 0.9653 - val_loss: 0.3078 - val_acc: 0.8828 - val_auROC: 0.9091\n",
      "Epoch 329/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2646 - acc: 0.9275 - auROC: 0.9654 - val_loss: 0.3081 - val_acc: 0.8828 - val_auROC: 0.9089\n",
      "Epoch 330/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2645 - acc: 0.9275 - auROC: 0.9654 - val_loss: 0.3077 - val_acc: 0.8828 - val_auROC: 0.9096\n",
      "Epoch 331/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2644 - acc: 0.9279 - auROC: 0.9653 - val_loss: 0.3073 - val_acc: 0.8828 - val_auROC: 0.9095\n",
      "Epoch 332/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2644 - acc: 0.9279 - auROC: 0.9653 - val_loss: 0.3071 - val_acc: 0.8828 - val_auROC: 0.9102\n",
      "Epoch 333/361\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2644 - acc: 0.9279 - auROC: 0.9653 - val_loss: 0.3069 - val_acc: 0.8862 - val_auROC: 0.9122\n",
      "Epoch 334/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2644 - acc: 0.9287 - auROC: 0.9652 - val_loss: 0.3055 - val_acc: 0.8862 - val_auROC: 0.9133\n",
      "Epoch 335/361\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2642 - acc: 0.9283 - auROC: 0.9651 - val_loss: 0.3047 - val_acc: 0.8828 - val_auROC: 0.9138\n",
      "Epoch 336/361\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2641 - acc: 0.9275 - auROC: 0.9651 - val_loss: 0.3045 - val_acc: 0.8828 - val_auROC: 0.9145\n",
      "Epoch 337/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2640 - acc: 0.9275 - auROC: 0.9651 - val_loss: 0.3046 - val_acc: 0.8828 - val_auROC: 0.9147\n",
      "Epoch 338/361\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2639 - acc: 0.9283 - auROC: 0.9650 - val_loss: 0.3042 - val_acc: 0.8828 - val_auROC: 0.9142\n",
      "Epoch 339/361\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2638 - acc: 0.9283 - auROC: 0.9650 - val_loss: 0.3041 - val_acc: 0.8828 - val_auROC: 0.9145\n",
      "Epoch 340/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2637 - acc: 0.9283 - auROC: 0.9650 - val_loss: 0.3040 - val_acc: 0.8828 - val_auROC: 0.9146\n",
      "Epoch 341/361\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2636 - acc: 0.9290 - auROC: 0.9650 - val_loss: 0.3039 - val_acc: 0.8828 - val_auROC: 0.9146\n",
      "Epoch 342/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2636 - acc: 0.9283 - auROC: 0.9650 - val_loss: 0.3049 - val_acc: 0.8793 - val_auROC: 0.9134\n",
      "Epoch 343/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2637 - acc: 0.9279 - auROC: 0.9650 - val_loss: 0.3044 - val_acc: 0.8828 - val_auROC: 0.9138\n",
      "Epoch 344/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2635 - acc: 0.9294 - auROC: 0.9650 - val_loss: 0.3042 - val_acc: 0.8828 - val_auROC: 0.9139\n",
      "Epoch 345/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2634 - acc: 0.9294 - auROC: 0.9650 - val_loss: 0.3048 - val_acc: 0.8828 - val_auROC: 0.9122\n",
      "Epoch 346/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2632 - acc: 0.9287 - auROC: 0.9651 - val_loss: 0.3054 - val_acc: 0.8793 - val_auROC: 0.9116\n",
      "Epoch 347/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2630 - acc: 0.9271 - auROC: 0.9652 - val_loss: 0.3054 - val_acc: 0.8793 - val_auROC: 0.9116\n",
      "Epoch 348/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2629 - acc: 0.9283 - auROC: 0.9652 - val_loss: 0.3051 - val_acc: 0.8828 - val_auROC: 0.9117\n",
      "Epoch 349/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2628 - acc: 0.9287 - auROC: 0.9652 - val_loss: 0.3055 - val_acc: 0.8828 - val_auROC: 0.9109\n",
      "Epoch 350/361\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2627 - acc: 0.9275 - auROC: 0.9652 - val_loss: 0.3054 - val_acc: 0.8793 - val_auROC: 0.9104\n",
      "Epoch 351/361\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2626 - acc: 0.9271 - auROC: 0.9652 - val_loss: 0.3051 - val_acc: 0.8793 - val_auROC: 0.9107\n",
      "Epoch 352/361\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2626 - acc: 0.9271 - auROC: 0.9652 - val_loss: 0.3049 - val_acc: 0.8828 - val_auROC: 0.9113\n",
      "Epoch 353/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2625 - acc: 0.9279 - auROC: 0.9652 - val_loss: 0.3049 - val_acc: 0.8828 - val_auROC: 0.9117\n",
      "Epoch 354/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2624 - acc: 0.9283 - auROC: 0.9652 - val_loss: 0.3050 - val_acc: 0.8793 - val_auROC: 0.9116\n",
      "Epoch 355/361\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2624 - acc: 0.9275 - auROC: 0.9653 - val_loss: 0.3052 - val_acc: 0.8793 - val_auROC: 0.9110\n",
      "Epoch 356/361\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2623 - acc: 0.9275 - auROC: 0.9653Restoring model weights from the end of the best epoch.\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.2623 - acc: 0.9275 - auROC: 0.9653 - val_loss: 0.3054 - val_acc: 0.8793 - val_auROC: 0.9107\n",
      "Epoch 00356: early stopping\n",
      "    0      1      2         3      ...  18014     18015     18016  18017\n",
      "0     0.0    0.0    0.0 -0.353448  ...    0.0 -0.198785 -0.197201    0.0\n",
      "1     0.0    0.0    0.0 -0.353448  ...    0.0 -0.198785 -0.197201    0.0\n",
      "2     0.0    0.0    0.0  0.042440  ...    0.0 -0.198785 -0.197201    0.0\n",
      "3     0.0    0.0    0.0 -0.353448  ...    0.0 -0.198785 -0.197201    0.0\n",
      "4     0.0    0.0    0.0 -0.353448  ...    0.0 -0.198785 -0.197201    0.0\n",
      "..    ...    ...    ...       ...  ...    ...       ...       ...    ...\n",
      "59    0.0    0.0    0.0 -0.353448  ...    0.0 -0.198785 -0.197201    0.0\n",
      "60    0.0    0.0    0.0 -0.353448  ...    0.0 -0.198785 -0.197201    0.0\n",
      "61    0.0    0.0    0.0 -0.353448  ...    0.0 -0.198785 -0.197201    0.0\n",
      "62    0.0    0.0    0.0  1.044472  ...    0.0 -0.198785 -0.197201    0.0\n",
      "63    0.0    0.0    0.0 -0.353448  ...    0.0 -0.198785 -0.197201    0.0\n",
      "\n",
      "[64 rows x 18018 columns]\n",
      "Total NANs in input samples: 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "18013    0\n",
      "18014    0\n",
      "18015    0\n",
      "18016    0\n",
      "18017    0\n",
      "Length: 18018, dtype: int64\n",
      "Reordering labels and prediction result\n",
      "Reordering labels and prediction result for samples\n",
      "Running evaluation...\n",
      "Evaluating biome source: root:CRC (stage 0)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc   Pr  F1  ROC-AUC  F-max\n",
      "t                                  ...                                      \n",
      "0.00   0  62   0   0  0.0000  0.0  ...  1.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.01   0  62   0   0  0.0000  0.0  ...  1.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.02   0  62   0   0  0.0000  0.0  ...  1.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.03   3  58   0   0  0.0492  0.0  ...  0.9508  0.0  0.0 NaN      0.0    NaN\n",
      "0.04  18  43   0   0  0.2951  0.0  ...  0.7049  0.0  0.0 NaN      0.0    NaN\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...  ...  ..      ...    ...\n",
      "0.97  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.98  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.99  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "1.00  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "1.01  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage I)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr     F1  ROC-AUC   F-max\n",
      "t                                  ...                                          \n",
      "0.00   0  41   0  21  0.3387  1.0  ...  1.0  1.0  0.3387  0.506   0.9394  0.8718\n",
      "0.01   0  41   0  21  0.3387  1.0  ...  1.0  1.0  0.3387  0.506   0.9394  0.8718\n",
      "0.02   0  41   0  21  0.3387  1.0  ...  1.0  1.0  0.3387  0.506   0.9394  0.8718\n",
      "0.03   0  41   0  21  0.3387  1.0  ...  1.0  1.0  0.3387  0.506   0.9394  0.8718\n",
      "0.04   0  41   0  21  0.3387  1.0  ...  1.0  1.0  0.3387  0.506   0.9394  0.8718\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...    ...      ...     ...\n",
      "0.97  41   0  21   0  0.6613  0.0  ...  0.0  0.0  0.0000    NaN   0.9394  0.8718\n",
      "0.98  41   0  21   0  0.6613  0.0  ...  0.0  0.0  0.0000    NaN   0.9394  0.8718\n",
      "0.99  41   0  21   0  0.6613  0.0  ...  0.0  0.0  0.0000    NaN   0.9394  0.8718\n",
      "1.00  41   0  21   0  0.6613  0.0  ...  0.0  0.0  0.0000    NaN   0.9394  0.8718\n",
      "1.01  41   0  21   0  0.6613  0.0  ...  0.0  0.0  0.0000    NaN   0.9394  0.8718\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage II)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                           \n",
      "0.00   0  49   0  13  0.2097  1.0  ...  1.0  1.0  0.2097  0.3467   0.8863  0.7368\n",
      "0.01   0  49   0  13  0.2097  1.0  ...  1.0  1.0  0.2097  0.3467   0.8863  0.7368\n",
      "0.02   0  49   0  13  0.2097  1.0  ...  1.0  1.0  0.2097  0.3467   0.8863  0.7368\n",
      "0.03   0  49   0  13  0.2097  1.0  ...  1.0  1.0  0.2097  0.3467   0.8863  0.7368\n",
      "0.04   0  48   0  13  0.2131  1.0  ...  1.0  1.0  0.2131  0.3514   0.8863  0.7368\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...     ...\n",
      "0.97  49   0  13   0  0.7903  0.0  ...  0.0  0.0  0.0000     NaN   0.8863  0.7368\n",
      "0.98  49   0  13   0  0.7903  0.0  ...  0.0  0.0  0.0000     NaN   0.8863  0.7368\n",
      "0.99  49   0  13   0  0.7903  0.0  ...  0.0  0.0  0.0000     NaN   0.8863  0.7368\n",
      "1.00  49   0  13   0  0.7903  0.0  ...  0.0  0.0  0.0000     NaN   0.8863  0.7368\n",
      "1.01  49   0  13   0  0.7903  0.0  ...  0.0  0.0  0.0000     NaN   0.8863  0.7368\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage III)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                          \n",
      "0.00   0  56   0   6  0.0968  1.0  ...  1.0  1.0  0.0968  0.1765      1.0    1.0\n",
      "0.01   0  56   0   6  0.0968  1.0  ...  1.0  1.0  0.0968  0.1765      1.0    1.0\n",
      "0.02   0  56   0   6  0.0968  1.0  ...  1.0  1.0  0.0968  0.1765      1.0    1.0\n",
      "0.03   0  55   0   6  0.0984  1.0  ...  1.0  1.0  0.0984  0.1791      1.0    1.0\n",
      "0.04   0  55   0   6  0.0984  1.0  ...  1.0  1.0  0.0984  0.1791      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...    ...\n",
      "0.97  56   0   6   0  0.9032  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  56   0   6   0  0.9032  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  56   0   6   0  0.9032  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  56   0   6   0  0.9032  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  56   0   6   0  0.9032  0.0  ...  0.0  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage IV)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...  FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                           \n",
      "0.00   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9848  0.9231\n",
      "0.01   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9848  0.9231\n",
      "0.02   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9848  0.9231\n",
      "0.03   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9848  0.9231\n",
      "0.04   0  43   0  19  0.3065  1.0  ...  1.0  1.0  0.3065  0.4691   0.9848  0.9231\n",
      "...   ..  ..  ..  ..     ...  ...  ...  ...  ...     ...     ...      ...     ...\n",
      "0.97  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9848  0.9231\n",
      "0.98  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9848  0.9231\n",
      "0.99  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9848  0.9231\n",
      "1.00  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9848  0.9231\n",
      "1.01  43   0  19   0  0.6935  0.0  ...  0.0  0.0  0.0000     NaN   0.9848  0.9231\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Saving evaluation results...\n",
      "Reordering labels and samples...\n",
      "Total matched samples: 571\n",
      "Total correct samples: 571?571\n",
      "           mean       std\n",
      "0      0.000000  0.000000\n",
      "1      0.000000  0.000000\n",
      "2      0.000000  0.000000\n",
      "3      0.015718  0.044470\n",
      "4      0.015697  0.044456\n",
      "...         ...       ...\n",
      "18013  0.000059  0.000240\n",
      "18014  0.000000  0.000000\n",
      "18015  0.002371  0.011928\n",
      "18016  0.002307  0.011699\n",
      "18017  0.000000  0.000000\n",
      "\n",
      "[18018 rows x 2 columns]\n",
      "Training using optimizer with lr=0.001...\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6473 - acc: 0.6339 - auROC: 0.5087 - val_loss: 0.5916 - val_acc: 0.6724 - val_auROC: 0.5473\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.5659 - acc: 0.7185 - auROC: 0.5642 - val_loss: 0.5459 - val_acc: 0.7103 - val_auROC: 0.6066\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.5235 - acc: 0.7665 - auROC: 0.6353 - val_loss: 0.5003 - val_acc: 0.7862 - val_auROC: 0.6861\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4935 - acc: 0.7852 - auROC: 0.6948 - val_loss: 0.4730 - val_acc: 0.7793 - val_auROC: 0.7402\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4735 - acc: 0.7895 - auROC: 0.7296 - val_loss: 0.4636 - val_acc: 0.7828 - val_auROC: 0.7618\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4617 - acc: 0.7992 - auROC: 0.7694 - val_loss: 0.4470 - val_acc: 0.7931 - val_auROC: 0.7847\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4501 - acc: 0.7988 - auROC: 0.7726 - val_loss: 0.4383 - val_acc: 0.7966 - val_auROC: 0.7953\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4439 - acc: 0.8043 - auROC: 0.7725 - val_loss: 0.4345 - val_acc: 0.8034 - val_auROC: 0.7935\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4399 - acc: 0.8117 - auROC: 0.7658 - val_loss: 0.4321 - val_acc: 0.7931 - val_auROC: 0.8077\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4331 - acc: 0.8109 - auROC: 0.7934 - val_loss: 0.4193 - val_acc: 0.8069 - val_auROC: 0.8372\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4263 - acc: 0.8121 - auROC: 0.8043 - val_loss: 0.4130 - val_acc: 0.8138 - val_auROC: 0.8393\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4184 - acc: 0.8164 - auROC: 0.8196 - val_loss: 0.4047 - val_acc: 0.8241 - val_auROC: 0.8472\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4127 - acc: 0.8183 - auROC: 0.8237 - val_loss: 0.4009 - val_acc: 0.8103 - val_auROC: 0.8539\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.4088 - acc: 0.8214 - auROC: 0.8304 - val_loss: 0.3986 - val_acc: 0.8069 - val_auROC: 0.8494\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4026 - acc: 0.8211 - auROC: 0.8347 - val_loss: 0.3945 - val_acc: 0.8345 - val_auROC: 0.8534\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.4040 - acc: 0.8324 - auROC: 0.8137 - val_loss: 0.3925 - val_acc: 0.8172 - val_auROC: 0.8600\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3997 - acc: 0.8257 - auROC: 0.8333 - val_loss: 0.3938 - val_acc: 0.8138 - val_auROC: 0.8412\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.4017 - acc: 0.8347 - auROC: 0.8119 - val_loss: 0.3858 - val_acc: 0.8241 - val_auROC: 0.8598\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3901 - acc: 0.8343 - auROC: 0.8374 - val_loss: 0.3744 - val_acc: 0.8379 - val_auROC: 0.8775\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3908 - acc: 0.8398 - auROC: 0.8355 - val_loss: 0.3718 - val_acc: 0.8276 - val_auROC: 0.8783\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3839 - acc: 0.8382 - auROC: 0.8445 - val_loss: 0.3736 - val_acc: 0.8310 - val_auROC: 0.8714\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3875 - acc: 0.8366 - auROC: 0.8346 - val_loss: 0.3788 - val_acc: 0.8276 - val_auROC: 0.8722\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3811 - acc: 0.8398 - auROC: 0.8479 - val_loss: 0.3605 - val_acc: 0.8483 - val_auROC: 0.8947\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3748 - acc: 0.8444 - auROC: 0.8634 - val_loss: 0.3618 - val_acc: 0.8379 - val_auROC: 0.8896\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3677 - acc: 0.8464 - auROC: 0.8683 - val_loss: 0.3542 - val_acc: 0.8586 - val_auROC: 0.8922\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3723 - acc: 0.8417 - auROC: 0.8588 - val_loss: 0.3540 - val_acc: 0.8483 - val_auROC: 0.8976\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3676 - acc: 0.8480 - auROC: 0.8681 - val_loss: 0.3556 - val_acc: 0.8586 - val_auROC: 0.8803\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3684 - acc: 0.8503 - auROC: 0.8543 - val_loss: 0.3508 - val_acc: 0.8517 - val_auROC: 0.8814\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3610 - acc: 0.8515 - auROC: 0.8696 - val_loss: 0.3471 - val_acc: 0.8517 - val_auROC: 0.9013\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3529 - acc: 0.8616 - auROC: 0.8776 - val_loss: 0.3511 - val_acc: 0.8621 - val_auROC: 0.8811\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3597 - acc: 0.8671 - auROC: 0.8602 - val_loss: 0.3480 - val_acc: 0.8655 - val_auROC: 0.8782\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3477 - acc: 0.8671 - auROC: 0.8781 - val_loss: 0.3335 - val_acc: 0.8828 - val_auROC: 0.9016\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3387 - acc: 0.8678 - auROC: 0.8895 - val_loss: 0.3271 - val_acc: 0.8759 - val_auROC: 0.9111\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3312 - acc: 0.8756 - auROC: 0.8989 - val_loss: 0.3306 - val_acc: 0.8655 - val_auROC: 0.9019\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3400 - acc: 0.8706 - auROC: 0.8856 - val_loss: 0.3340 - val_acc: 0.8621 - val_auROC: 0.9032\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3344 - acc: 0.8710 - auROC: 0.8908 - val_loss: 0.3142 - val_acc: 0.8586 - val_auROC: 0.9193\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3311 - acc: 0.8694 - auROC: 0.8912 - val_loss: 0.3443 - val_acc: 0.8552 - val_auROC: 0.8773\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3465 - acc: 0.8554 - auROC: 0.8736 - val_loss: 0.3149 - val_acc: 0.8724 - val_auROC: 0.9245\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3574 - acc: 0.8558 - auROC: 0.8576 - val_loss: 0.3690 - val_acc: 0.8517 - val_auROC: 0.8413\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3574 - acc: 0.8561 - auROC: 0.8571 - val_loss: 0.3428 - val_acc: 0.8310 - val_auROC: 0.8809\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3298 - acc: 0.8721 - auROC: 0.8882 - val_loss: 0.3139 - val_acc: 0.8828 - val_auROC: 0.9076\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3139 - acc: 0.8869 - auROC: 0.9017 - val_loss: 0.3074 - val_acc: 0.8759 - val_auROC: 0.9199\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3146 - acc: 0.8834 - auROC: 0.9056 - val_loss: 0.3015 - val_acc: 0.8759 - val_auROC: 0.9278\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3083 - acc: 0.8924 - auROC: 0.9090 - val_loss: 0.2929 - val_acc: 0.9000 - val_auROC: 0.9253\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3018 - acc: 0.8947 - auROC: 0.9113 - val_loss: 0.2824 - val_acc: 0.9000 - val_auROC: 0.9394\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2921 - acc: 0.9033 - auROC: 0.9198 - val_loss: 0.2874 - val_acc: 0.9000 - val_auROC: 0.9318\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2855 - acc: 0.9099 - auROC: 0.9242 - val_loss: 0.2782 - val_acc: 0.9000 - val_auROC: 0.9389\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2800 - acc: 0.9146 - auROC: 0.9288 - val_loss: 0.2942 - val_acc: 0.8862 - val_auROC: 0.9210\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2870 - acc: 0.9018 - auROC: 0.9189 - val_loss: 0.2854 - val_acc: 0.9172 - val_auROC: 0.9321\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2894 - acc: 0.9146 - auROC: 0.9167 - val_loss: 0.2691 - val_acc: 0.9241 - val_auROC: 0.9460\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2893 - acc: 0.9029 - auROC: 0.9178 - val_loss: 0.2972 - val_acc: 0.8931 - val_auROC: 0.9156\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3034 - acc: 0.8897 - auROC: 0.9032 - val_loss: 0.2529 - val_acc: 0.9345 - val_auROC: 0.9641\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2774 - acc: 0.9076 - auROC: 0.9252 - val_loss: 0.2525 - val_acc: 0.9310 - val_auROC: 0.9589\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2777 - acc: 0.9135 - auROC: 0.9251 - val_loss: 0.2562 - val_acc: 0.9103 - val_auROC: 0.9605\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2608 - acc: 0.9212 - auROC: 0.9417 - val_loss: 0.2381 - val_acc: 0.9414 - val_auROC: 0.9744\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2504 - acc: 0.9267 - auROC: 0.9449 - val_loss: 0.2301 - val_acc: 0.9414 - val_auROC: 0.9783\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2406 - acc: 0.9372 - auROC: 0.9526 - val_loss: 0.2464 - val_acc: 0.9310 - val_auROC: 0.9668\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2797 - acc: 0.9150 - auROC: 0.9185 - val_loss: 0.2715 - val_acc: 0.9138 - val_auROC: 0.9332\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2569 - acc: 0.9220 - auROC: 0.9369 - val_loss: 0.2600 - val_acc: 0.8966 - val_auROC: 0.9511\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2401 - acc: 0.9326 - auROC: 0.9526 - val_loss: 0.2312 - val_acc: 0.9276 - val_auROC: 0.9760\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2312 - acc: 0.9361 - auROC: 0.9560 - val_loss: 0.2255 - val_acc: 0.9414 - val_auROC: 0.9741\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2220 - acc: 0.9493 - auROC: 0.9578 - val_loss: 0.2217 - val_acc: 0.9379 - val_auROC: 0.9789\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2176 - acc: 0.9509 - auROC: 0.9608 - val_loss: 0.2106 - val_acc: 0.9483 - val_auROC: 0.9802\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2117 - acc: 0.9524 - auROC: 0.9626 - val_loss: 0.2082 - val_acc: 0.9483 - val_auROC: 0.9827\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.2062 - acc: 0.9575 - auROC: 0.9636 - val_loss: 0.2022 - val_acc: 0.9517 - val_auROC: 0.9810\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.2034 - acc: 0.9583 - auROC: 0.9644 - val_loss: 0.1961 - val_acc: 0.9586 - val_auROC: 0.9819\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.1991 - acc: 0.9595 - auROC: 0.9656 - val_loss: 0.1941 - val_acc: 0.9586 - val_auROC: 0.9825\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.1925 - acc: 0.9626 - auROC: 0.9675 - val_loss: 0.1895 - val_acc: 0.9655 - val_auROC: 0.9851\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.1903 - acc: 0.9637 - auROC: 0.9675 - val_loss: 0.1861 - val_acc: 0.9586 - val_auROC: 0.9852\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.1865 - acc: 0.9649 - auROC: 0.9687 - val_loss: 0.1779 - val_acc: 0.9655 - val_auROC: 0.9877\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.1879 - acc: 0.9602 - auROC: 0.9656 - val_loss: 0.1753 - val_acc: 0.9690 - val_auROC: 0.9864\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.1850 - acc: 0.9622 - auROC: 0.9661 - val_loss: 0.1744 - val_acc: 0.9655 - val_auROC: 0.9878\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1906 - acc: 0.9556 - auROC: 0.9664 - val_loss: 0.1882 - val_acc: 0.9448 - val_auROC: 0.9806\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1845 - acc: 0.9653 - auROC: 0.9683 - val_loss: 0.1841 - val_acc: 0.9517 - val_auROC: 0.9823\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1854 - acc: 0.9622 - auROC: 0.9659 - val_loss: 0.1857 - val_acc: 0.9483 - val_auROC: 0.9820\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.1826 - acc: 0.9579 - auROC: 0.9690 - val_loss: 0.1691 - val_acc: 0.9655 - val_auROC: 0.9873\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.1728 - acc: 0.9661 - auROC: 0.9714 - val_loss: 0.1782 - val_acc: 0.9586 - val_auROC: 0.9824\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1705 - acc: 0.9665 - auROC: 0.9721 - val_loss: 0.1712 - val_acc: 0.9586 - val_auROC: 0.9829\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1761 - acc: 0.9630 - auROC: 0.9650 - val_loss: 0.2481 - val_acc: 0.9034 - val_auROC: 0.9354\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2780 - acc: 0.8982 - auROC: 0.9160 - val_loss: 0.2956 - val_acc: 0.8897 - val_auROC: 0.9022\n",
      "Epoch 81/300\n",
      "5/9 [===============>..............] - ETA: 0s - loss: 0.2495 - acc: 0.9044 - auROC: 0.9335\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2811 - acc: 0.8877 - auROC: 0.9107 - val_loss: 0.2855 - val_acc: 0.8897 - val_auROC: 0.9120\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2611 - acc: 0.9002 - auROC: 0.9261 - val_loss: 0.2736 - val_acc: 0.9034 - val_auROC: 0.9187\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2472 - acc: 0.9154 - auROC: 0.9344 - val_loss: 0.2587 - val_acc: 0.9172 - val_auROC: 0.9259\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2348 - acc: 0.9228 - auROC: 0.9418 - val_loss: 0.2413 - val_acc: 0.9276 - val_auROC: 0.9339\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2245 - acc: 0.9310 - auROC: 0.9471 - val_loss: 0.2339 - val_acc: 0.9310 - val_auROC: 0.9368\n",
      "Epoch 86/300\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.2192 - acc: 0.9366 - auROC: 0.9478\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2157 - acc: 0.9384 - auROC: 0.9510 - val_loss: 0.2220 - val_acc: 0.9414 - val_auROC: 0.9433\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2095 - acc: 0.9431 - auROC: 0.9548 - val_loss: 0.2211 - val_acc: 0.9414 - val_auROC: 0.9442\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2087 - acc: 0.9435 - auROC: 0.9554 - val_loss: 0.2207 - val_acc: 0.9448 - val_auROC: 0.9438\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2079 - acc: 0.9439 - auROC: 0.9555 - val_loss: 0.2204 - val_acc: 0.9448 - val_auROC: 0.9434\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.2072 - acc: 0.9435 - auROC: 0.9556 - val_loss: 0.2200 - val_acc: 0.9517 - val_auROC: 0.9431\n",
      "Epoch 91/300\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.2058 - acc: 0.9424 - auROC: 0.9583\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.2064 - acc: 0.9431 - auROC: 0.9562 - val_loss: 0.2194 - val_acc: 0.9517 - val_auROC: 0.9432\n",
      "Epoch 00091: early stopping\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 18018)]           0         \n",
      "_________________________________________________________________\n",
      "base (Sequential)            (None, 512)               18976256  \n",
      "_________________________________________________________________\n",
      "l2_inter (Sequential)        (None, 10)                21550     \n",
      "_________________________________________________________________\n",
      "l2_integration (Sequential)  (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "l2o (Sequential)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 18,998,051\n",
      "Trainable params: 21,795\n",
      "Non-trainable params: 18,976,256\n",
      "_________________________________________________________________\n",
      "Fine-tuning using optimizer with lr=1e-05...\n",
      "Epoch 91/390\n",
      "9/9 [==============================] - 1s 106ms/step - loss: 0.1700 - acc: 0.9676 - auROC: 0.9722 - val_loss: 0.1690 - val_acc: 0.9586 - val_auROC: 0.9867\n",
      "Epoch 92/390\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1664 - acc: 0.9696 - auROC: 0.9728 - val_loss: 0.1673 - val_acc: 0.9621 - val_auROC: 0.9865\n",
      "Epoch 93/390\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1640 - acc: 0.9696 - auROC: 0.9738 - val_loss: 0.1662 - val_acc: 0.9621 - val_auROC: 0.9867\n",
      "Epoch 94/390\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1624 - acc: 0.9708 - auROC: 0.9741 - val_loss: 0.1648 - val_acc: 0.9621 - val_auROC: 0.9871\n",
      "Epoch 95/390\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1613 - acc: 0.9712 - auROC: 0.9743 - val_loss: 0.1651 - val_acc: 0.9621 - val_auROC: 0.9871\n",
      "Epoch 96/390\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1600 - acc: 0.9715 - auROC: 0.9749 - val_loss: 0.1639 - val_acc: 0.9621 - val_auROC: 0.9874\n",
      "Epoch 97/390\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1591 - acc: 0.9719 - auROC: 0.9750 - val_loss: 0.1642 - val_acc: 0.9621 - val_auROC: 0.9868\n",
      "Epoch 98/390\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1584 - acc: 0.9727 - auROC: 0.9749 - val_loss: 0.1642 - val_acc: 0.9621 - val_auROC: 0.9870\n",
      "Epoch 99/390\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1577 - acc: 0.9731 - auROC: 0.9753 - val_loss: 0.1634 - val_acc: 0.9621 - val_auROC: 0.9871\n",
      "Epoch 100/390\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1572 - acc: 0.9735 - auROC: 0.9757 - val_loss: 0.1623 - val_acc: 0.9621 - val_auROC: 0.9874\n",
      "Epoch 101/390\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1566 - acc: 0.9735 - auROC: 0.9757 - val_loss: 0.1619 - val_acc: 0.9621 - val_auROC: 0.9872\n",
      "Epoch 102/390\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1561 - acc: 0.9739 - auROC: 0.9757 - val_loss: 0.1617 - val_acc: 0.9621 - val_auROC: 0.9872\n",
      "Epoch 103/390\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1562 - acc: 0.9743 - auROC: 0.9752 - val_loss: 0.1641 - val_acc: 0.9621 - val_auROC: 0.9860\n",
      "Epoch 104/390\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1561 - acc: 0.9743 - auROC: 0.9754 - val_loss: 0.1622 - val_acc: 0.9621 - val_auROC: 0.9866\n",
      "Epoch 105/390\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1555 - acc: 0.9743 - auROC: 0.9757 - val_loss: 0.1596 - val_acc: 0.9621 - val_auROC: 0.9879\n",
      "Epoch 106/390\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1550 - acc: 0.9743 - auROC: 0.9756 - val_loss: 0.1586 - val_acc: 0.9621 - val_auROC: 0.9880\n",
      "Epoch 107/390\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1545 - acc: 0.9750 - auROC: 0.9757 - val_loss: 0.1587 - val_acc: 0.9621 - val_auROC: 0.9881\n",
      "Epoch 108/390\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1540 - acc: 0.9750 - auROC: 0.9757 - val_loss: 0.1585 - val_acc: 0.9621 - val_auROC: 0.9880\n",
      "Epoch 109/390\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1535 - acc: 0.9747 - auROC: 0.9762 - val_loss: 0.1583 - val_acc: 0.9586 - val_auROC: 0.9881\n",
      "Epoch 110/390\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1527 - acc: 0.9754 - auROC: 0.9764 - val_loss: 0.1635 - val_acc: 0.9586 - val_auROC: 0.9810\n",
      "Epoch 111/390\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1524 - acc: 0.9762 - auROC: 0.9764 - val_loss: 0.1647 - val_acc: 0.9586 - val_auROC: 0.9796\n",
      "Epoch 112/390\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1521 - acc: 0.9766 - auROC: 0.9767 - val_loss: 0.1652 - val_acc: 0.9586 - val_auROC: 0.9785\n",
      "Epoch 113/390\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1523 - acc: 0.9758 - auROC: 0.9772 - val_loss: 0.1650 - val_acc: 0.9586 - val_auROC: 0.9777\n",
      "Epoch 114/390\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1532 - acc: 0.9750 - auROC: 0.9778 - val_loss: 0.1659 - val_acc: 0.9586 - val_auROC: 0.9770\n",
      "Epoch 115/390\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1517 - acc: 0.9762 - auROC: 0.9781 - val_loss: 0.1662 - val_acc: 0.9586 - val_auROC: 0.9771\n",
      "Epoch 116/390\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1509 - acc: 0.9770 - auROC: 0.9778 - val_loss: 0.1669 - val_acc: 0.9586 - val_auROC: 0.9770\n",
      "Epoch 117/390\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1505 - acc: 0.9774 - auROC: 0.9778 - val_loss: 0.1668 - val_acc: 0.9586 - val_auROC: 0.9766\n",
      "Epoch 118/390\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1502 - acc: 0.9774 - auROC: 0.9779 - val_loss: 0.1668 - val_acc: 0.9586 - val_auROC: 0.9767\n",
      "Epoch 119/390\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1499 - acc: 0.9774 - auROC: 0.9781 - val_loss: 0.1669 - val_acc: 0.9586 - val_auROC: 0.9767\n",
      "Epoch 120/390\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1496 - acc: 0.9774 - auROC: 0.9782 - val_loss: 0.1668 - val_acc: 0.9621 - val_auROC: 0.9767\n",
      "Epoch 121/390\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1494 - acc: 0.9774 - auROC: 0.9783 - val_loss: 0.1665 - val_acc: 0.9621 - val_auROC: 0.9767\n",
      "Epoch 122/390\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1492 - acc: 0.9778 - auROC: 0.9782 - val_loss: 0.1660 - val_acc: 0.9655 - val_auROC: 0.9765\n",
      "Epoch 123/390\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1489 - acc: 0.9782 - auROC: 0.9783 - val_loss: 0.1656 - val_acc: 0.9655 - val_auROC: 0.9768\n",
      "Epoch 124/390\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1487 - acc: 0.9778 - auROC: 0.9787Restoring model weights from the end of the best epoch.\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1487 - acc: 0.9778 - auROC: 0.9787 - val_loss: 0.1653 - val_acc: 0.9655 - val_auROC: 0.9767\n",
      "Epoch 00124: early stopping\n",
      "    0      1      2         3      ...  18014     18015     18016  18017\n",
      "0     0.0    0.0    0.0 -0.353447  ...    0.0 -0.198785 -0.197201    0.0\n",
      "1     0.0    0.0    0.0 -0.353447  ...    0.0 -0.198785 -0.197201    0.0\n",
      "2     0.0    0.0    0.0  0.042439  ...    0.0 -0.198785 -0.197201    0.0\n",
      "3     0.0    0.0    0.0 -0.353447  ...    0.0 -0.198785 -0.197201    0.0\n",
      "4     0.0    0.0    0.0 -0.353447  ...    0.0 -0.198785 -0.197201    0.0\n",
      "..    ...    ...    ...       ...  ...    ...       ...       ...    ...\n",
      "59    0.0    0.0    0.0 -0.353447  ...    0.0 -0.198785 -0.197201    0.0\n",
      "60    0.0    0.0    0.0 -0.353447  ...    0.0 -0.198785 -0.197201    0.0\n",
      "61    0.0    0.0    0.0 -0.353447  ...    0.0 -0.198785 -0.197201    0.0\n",
      "62    0.0    0.0    0.0  1.044471  ...    0.0 -0.198785 -0.197201    0.0\n",
      "63    0.0    0.0    0.0 -0.353447  ...    0.0 -0.198785 -0.197201    0.0\n",
      "\n",
      "[64 rows x 18018 columns]\n",
      "Total NANs in input samples: 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "18013    0\n",
      "18014    0\n",
      "18015    0\n",
      "18016    0\n",
      "18017    0\n",
      "Length: 18018, dtype: int64\n",
      "Reordering labels and prediction result\n",
      "Reordering labels and prediction result for samples\n",
      "Running evaluation...\n",
      "Evaluating biome source: root:CRC (stage 0)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc   Pr  F1  ROC-AUC  F-max\n",
      "t                                  ...                                      \n",
      "0.00   0  62   0   0  0.0000  0.0  ...  1.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.01  15  46   0   0  0.2459  0.0  ...  0.7541  0.0  0.0 NaN      0.0    NaN\n",
      "0.02  26  35   0   0  0.4262  0.0  ...  0.5738  0.0  0.0 NaN      0.0    NaN\n",
      "0.03  37  24   0   0  0.6066  0.0  ...  0.3934  0.0  0.0 NaN      0.0    NaN\n",
      "0.04  43  18   0   0  0.7049  0.0  ...  0.2951  0.0  0.0 NaN      0.0    NaN\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...  ...  ..      ...    ...\n",
      "0.97  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.98  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "0.99  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "1.00  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "1.01  62   0   0   0  1.0000  0.0  ...  0.0000  0.0  0.0 NaN      0.0    NaN\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage I)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...    FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  41   0  21  0.3387  1.0  ...  1.000  1.0  0.3387  0.5060    0.975  0.9189\n",
      "0.01   0  41   0  21  0.3387  1.0  ...  1.000  1.0  0.3387  0.5060    0.975  0.9189\n",
      "0.02  11  29   0  21  0.5246  1.0  ...  0.725  1.0  0.4200  0.5915    0.975  0.9189\n",
      "0.03  11  29   0  21  0.5246  1.0  ...  0.725  1.0  0.4200  0.5915    0.975  0.9189\n",
      "0.04  13  27   0  21  0.5574  1.0  ...  0.675  1.0  0.4375  0.6087    0.975  0.9189\n",
      "...   ..  ..  ..  ..     ...  ...  ...    ...  ...     ...     ...      ...     ...\n",
      "0.97  41   0  21   0  0.6613  0.0  ...  0.000  0.0  0.0000     NaN    0.975  0.9189\n",
      "0.98  41   0  21   0  0.6613  0.0  ...  0.000  0.0  0.0000     NaN    0.975  0.9189\n",
      "0.99  41   0  21   0  0.6613  0.0  ...  0.000  0.0  0.0000     NaN    0.975  0.9189\n",
      "1.00  41   0  21   0  0.6613  0.0  ...  0.000  0.0  0.0000     NaN    0.975  0.9189\n",
      "1.01  41   0  21   0  0.6613  0.0  ...  0.000  0.0  0.0000     NaN    0.975  0.9189\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage II)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC  F-max\n",
      "t                                  ...                                             \n",
      "0.00   0  49   0  13  0.2097  1.0  ...  1.0000  1.0  0.2097  0.3467      1.0    1.0\n",
      "0.01   0  49   0  13  0.2097  1.0  ...  1.0000  1.0  0.2097  0.3467      1.0    1.0\n",
      "0.02  16  32   0  13  0.4754  1.0  ...  0.6667  1.0  0.2889  0.4483      1.0    1.0\n",
      "0.03  20  28   0  13  0.5410  1.0  ...  0.5833  1.0  0.3171  0.4815      1.0    1.0\n",
      "0.04  20  28   0  13  0.5410  1.0  ...  0.5833  1.0  0.3171  0.4815      1.0    1.0\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...    ...\n",
      "0.97  49   0  13   0  0.7903  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.98  49   0  13   0  0.7903  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "0.99  49   0  13   0  0.7903  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.00  49   0  13   0  0.7903  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "1.01  49   0  13   0  0.7903  0.0  ...  0.0000  0.0  0.0000     NaN      1.0    1.0\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage III)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                              \n",
      "0.00   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765   0.9964  0.9231\n",
      "0.01   0  56   0   6  0.0968  1.0  ...  1.0000  1.0  0.0968  0.1765   0.9964  0.9231\n",
      "0.02   2  53   0   6  0.1311  1.0  ...  0.9636  1.0  0.1017  0.1846   0.9964  0.9231\n",
      "0.03   4  51   0   6  0.1639  1.0  ...  0.9273  1.0  0.1053  0.1905   0.9964  0.9231\n",
      "0.04  20  35   0   6  0.4262  1.0  ...  0.6364  1.0  0.1463  0.2553   0.9964  0.9231\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...     ...\n",
      "0.97  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN   0.9964  0.9231\n",
      "0.98  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN   0.9964  0.9231\n",
      "0.99  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN   0.9964  0.9231\n",
      "1.00  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN   0.9964  0.9231\n",
      "1.01  56   0   6   0  0.9032  0.0  ...  0.0000  0.0  0.0000     NaN   0.9964  0.9231\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Evaluating biome source: root:CRC (stage IV)\n",
      "      TN  FP  FN  TP     Acc   Sn  ...     FPR   Rc      Pr      F1  ROC-AUC   F-max\n",
      "t                                  ...                                              \n",
      "0.00   0  43   0  19  0.3065  1.0  ...  1.0000  1.0  0.3065  0.4691   0.9921  0.9412\n",
      "0.01   0  43   0  19  0.3065  1.0  ...  1.0000  1.0  0.3065  0.4691   0.9921  0.9412\n",
      "0.02   0  43   0  19  0.3065  1.0  ...  1.0000  1.0  0.3065  0.4691   0.9921  0.9412\n",
      "0.03   1  41   0  19  0.3279  1.0  ...  0.9762  1.0  0.3167  0.4810   0.9921  0.9412\n",
      "0.04   5  37   0  19  0.3934  1.0  ...  0.8810  1.0  0.3393  0.5067   0.9921  0.9412\n",
      "...   ..  ..  ..  ..     ...  ...  ...     ...  ...     ...     ...      ...     ...\n",
      "0.97  43   0  19   0  0.6935  0.0  ...  0.0000  0.0  0.0000     NaN   0.9921  0.9412\n",
      "0.98  43   0  19   0  0.6935  0.0  ...  0.0000  0.0  0.0000     NaN   0.9921  0.9412\n",
      "0.99  43   0  19   0  0.6935  0.0  ...  0.0000  0.0  0.0000     NaN   0.9921  0.9412\n",
      "1.00  43   0  19   0  0.6935  0.0  ...  0.0000  0.0  0.0000     NaN   0.9921  0.9412\n",
      "1.01  43   0  19   0  0.6935  0.0  ...  0.0000  0.0  0.0000     NaN   0.9921  0.9412\n",
      "\n",
      "[102 rows x 14 columns]\n",
      "Saving evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘running_2’: File exists\n",
      "2020-11-26 13:23:18.622388: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-26 13:23:18.629832: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499960000 Hz\n",
      "2020-11-26 13:23:18.631653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563da94111d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-26 13:23:18.631681: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-11-26 13:23:19.640297: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 144288144 exceeds 10% of free system memory.\n",
      "2020-11-26 13:23:20.730600: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 144288144 exceeds 10% of free system memory.\n",
      "2020-11-26 13:23:20.861344: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 73801728 exceeds 10% of free system memory.\n",
      "2020-11-26 13:23:20.907472: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 73801728 exceeds 10% of free system memory.\n",
      "2020-11-26 13:23:20.914999: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 73801728 exceeds 10% of free system memory.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-11-26 13:23:44.560736: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "100%|██████████| 1/1 [00:00<00:00, 1044.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 419.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.25it/s]\n",
      "2020-11-26 13:24:03.228798: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-26 13:24:03.237522: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499960000 Hz\n",
      "2020-11-26 13:24:03.239466: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ec58afbfb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-26 13:24:03.239490: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-11-26 13:26:40.061431: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "100%|██████████| 1/1 [00:00<00:00, 832.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 434.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.56it/s]\n",
      "2020-11-26 13:27:02.995491: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-26 13:27:03.004693: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499960000 Hz\n",
      "2020-11-26 13:27:03.006648: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56168174e520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-26 13:27:03.006689: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-11-26 13:27:03.124088: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 73801728 exceeds 10% of free system memory.\n",
      "2020-11-26 13:27:03.136909: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 73801728 exceeds 10% of free system memory.\n",
      "2020-11-26 13:27:03.144422: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 73801728 exceeds 10% of free system memory.\n",
      "2020-11-26 13:27:03.303255: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 73801728 exceeds 10% of free system memory.\n",
      "2020-11-26 13:27:03.404579: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 73801728 exceeds 10% of free system memory.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-11-26 13:28:25.163168: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 477.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.00it/s]\n",
      "2020-11-26 13:28:49.887619: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-26 13:28:49.896185: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499960000 Hz\n",
      "2020-11-26 13:28:49.898579: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56229b3fef70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-26 13:28:49.898604: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-11-26 13:29:37.021212: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "100%|██████████| 1/1 [00:00<00:00, 1099.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 541.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.75it/s]\n",
      "2020-11-26 13:29:58.027595: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-26 13:29:58.035884: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499960000 Hz\n",
      "2020-11-26 13:29:58.038147: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556d50bbcf90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-26 13:29:58.038176: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-11-26 13:31:11.740723: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "100%|██████████| 1/1 [00:00<00:00, 1082.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 509.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.54it/s]\n",
      "2020-11-26 13:31:32.833933: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-26 13:31:32.842511: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499960000 Hz\n",
      "2020-11-26 13:31:32.844710: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5651a94a74f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-26 13:31:32.844737: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-11-26 13:33:55.870065: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "100%|██████████| 1/1 [00:00<00:00, 1081.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 544.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.37it/s]\n",
      "2020-11-26 13:34:20.632478: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-26 13:34:20.641218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499960000 Hz\n",
      "2020-11-26 13:34:20.643531: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56049cb911d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-26 13:34:20.643565: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-11-26 13:34:21.518990: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 144288144 exceeds 10% of free system memory.\n",
      "2020-11-26 13:34:22.437697: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 144288144 exceeds 10% of free system memory.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-11-26 13:34:38.838778: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "100%|██████████| 1/1 [00:00<00:00, 911.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 474.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.46it/s]\n",
      "2020-11-26 13:34:57.353248: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-26 13:34:57.361799: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499960000 Hz\n",
      "2020-11-26 13:34:57.363830: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f8d5ca1520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-26 13:34:57.363856: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-11-26 13:37:17.233905: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "100%|██████████| 1/1 [00:00<00:00, 1067.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 505.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.60it/s]\n",
      "2020-11-26 13:37:40.399928: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-26 13:37:40.408635: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499960000 Hz\n",
      "2020-11-26 13:37:40.410897: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5599ca7fa480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-26 13:37:40.410931: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "2020-11-26 13:37:44.333320: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 144288144 exceeds 10% of free system memory.\n",
      "2020-11-26 13:37:45.332555: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 144288144 exceeds 10% of free system memory.\n",
      "2020-11-26 13:37:46.556760: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 144288144 exceeds 10% of free system memory.\n",
      "2020-11-26 13:37:47.572620: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 144288144 exceeds 10% of free system memory.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-11-26 13:38:20.143749: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "100%|██████████| 1/1 [00:00<00:00, 834.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 387.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.54it/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "for i in {0,1,2,3,4}; do\n",
    "    mkdir running_$i;\n",
    "    expert train -i experiments/exp_$i/SourceCM.h5 -t ontology.pkl -l experiments/exp_$i/SourceLabels.h5 -o experiments/exp_$i/TrainModel;\n",
    "    expert search -i experiments/exp_$i/QueryCM.h5 -m experiments/exp_$i/TrainModel -o experiments/exp_$i/SearchResult_Train;\n",
    "    expert evaluate -i experiments/exp_$i/SearchResult_Train -l experiments/exp_$i/QueryLabels.h5 -o experiments/exp_$i/EvalResult_Train -S 0;\n",
    "\n",
    "    expert transfer -i experiments/exp_$i/SourceCM.h5 -t ontology.pkl -l experiments/exp_$i/SourceLabels.h5 -o experiments/exp_$i/AdaptModel_ft_HM \\\n",
    "            -m HumanModel/ --finetune --update-statistics;\n",
    "    expert search -i experiments/exp_$i/QueryCM.h5 -m experiments/exp_$i/AdaptModel_ft_HM -o experiments/exp_$i/SearchResult_Adapt_ft_HM;\n",
    "    expert evaluate -i experiments/exp_$i/SearchResult_Adapt_ft_HM -l experiments/exp_$i/QueryLabels.h5 -o experiments/exp_$i/EvalResult_Adapt_ft_HM -S 0;\n",
    "\n",
    "    expert transfer -i experiments/exp_$i/SourceCM.h5 -t ontology.pkl -l experiments/exp_$i/SourceLabels.h5 -o experiments/exp_$i/AdaptModel_ft_DM \\\n",
    "            -m ../Disease-diagnosis/experiments/exp_3/TrainModel/ --finetune --update-statistics;\n",
    "    expert search -i experiments/exp_$i/QueryCM.h5 -m experiments/exp_$i/AdaptModel_ft_DM -o experiments/exp_$i/SearchResult_Adapt_ft_DM;\n",
    "    expert evaluate -i experiments/exp_$i/SearchResult_Adapt_ft_DM -l experiments/exp_$i/QueryLabels.h5 -o experiments/exp_$i/EvalResult_Adapt_ft_DM -S 0;\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (8737394568509)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/plotnine/ggplot.py:727: PlotnineWarning: Saving 4 x 3 in image.\n",
      "/home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/plotnine/ggplot.py:730: PlotnineWarning: Filename: Figure.pdf\n",
      "/home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/plotnine/ggplot.py:727: PlotnineWarning: Saving 4 x 3 in image.\n",
      "/home/chonghui/envs/miniconda3/envs/expert/lib/python3.8/site-packages/plotnine/ggplot.py:730: PlotnineWarning: Filename: Figure.png\n"
     ]
    }
   ],
   "source": [
    "metrics =[pd.read_csv('experiments/exp_{}/EvalResult_{}/overall.csv'.format(i, suffix), index_col=0).rename(columns=lambda x: '{}-exp_{}-{}'.format(x, i, suffix)).dropna()\n",
    "        for i in range(5) for suffix in ['Train', 'Adapt_ft_DM', 'Adapt_ft_HM']]\n",
    "overall = pd.concat(metrics, axis=1)\n",
    "overall\n",
    "overall = overall.reset_index().melt(id_vars=['index'], value_vars=overall.columns.tolist(), var_name='metric').dropna()\n",
    "overall['Experiment'] = overall['metric'].str.split('-').apply(lambda x: '{}'.format( x[3])).map({'Adapt_ft_DM': 'Transfer (DM)', 'Adapt_ft_HM': 'Transfer (HM)', 'Train': 'Independent'})\n",
    "overall['Metric'] = overall['metric'].str.split('-').apply(lambda x: '{}-{}'.format(x[0], x[1]))\n",
    "\n",
    "from plotnine import *\n",
    "plot = (ggplot(overall, aes(x='Experiment', y='value', fill='Experiment'))\n",
    "         + geom_violin()\n",
    "         + geom_boxplot(width=0.1)\n",
    "         + scale_fill_manual(['#E64B35FF','#4DBBD5FF','#00A087FF','#3C5488FF','#F39B7FFF','#8491B4FF','#91D1C2FF'])\n",
    "         + theme(axis_title_x=element_blank(), axis_text_x=element_blank())\n",
    "         + xlab('Experiment')\n",
    "         + ylab('Value')\n",
    "         + facet_wrap('Metric'))\n",
    "print(plot)\n",
    "plot.save('Figure.pdf', dpi=120, width=4, height=3)\n",
    "plot.save('Figure.png', dpi=120, width=4, height=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
